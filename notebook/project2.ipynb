{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f4da8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import JAX to use\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, vmap, random\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pickle\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7223a1fc",
   "metadata": {},
   "source": [
    "1. Implement a dense feedforward neural network from scratch.\n",
    "\n",
    "   The implementation must be flexible with respect to:\n",
    "   - The input and output dimensions.\n",
    "   - The number of hidden layers.\n",
    "   - The number of neurons per hidden layer.\n",
    "   - The activation functions used.\n",
    "\n",
    "   This implementation will be used for the following two questions.\n",
    "\n",
    "   Choose a suitable initialization for the network parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5e84432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start with a function that initializes the network parameters.\n",
    "def init_net_params(layer_widths, key):\n",
    "    \"\"\"\n",
    "    Initialize the network parameters.\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    keys = random.split(key, len(layer_widths) - 1)\n",
    "\n",
    "    for i, (n_in, n_out) in enumerate(zip(layer_widths[:-1], layer_widths[1:])):\n",
    "        w_key = keys[i]\n",
    "        scale = jnp.sqrt(2.0 / n_in) # xavier initialization\n",
    "        w = random.normal(w_key, shape=(n_in, n_out)) * scale\n",
    "        b = jnp.zeros((n_out,))\n",
    "        params.append({'w': w, 'b': b})\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "27ef9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we define a forward pass function that computes the output of the network for a given input.\n",
    "def forward(params, x, activation):\n",
    "    \"\"\"\n",
    "    Forward pass of the network.\n",
    "    \"\"\"\n",
    "\n",
    "    activations = {\n",
    "        'relu': jax.nn.relu,\n",
    "        'sigmoid': jax.nn.sigmoid,\n",
    "        'tanh': jax.nn.tanh,\n",
    "        'softmax': jax.nn.softmax\n",
    "    }\n",
    "    activation = activations[activation]\n",
    "\n",
    "    for layer in params[:-1]:\n",
    "        x = x @ layer['w'] + layer['b']\n",
    "        x = activation(x)\n",
    "\n",
    "    # output layer, no activation function\n",
    "    final_layer = params[-1]\n",
    "    return jnp.dot(x, final_layer['w']) + final_layer['b']\n",
    "\n",
    "def get_batches(x, y, batch_size=256):\n",
    "    \"\"\"\n",
    "    Returns a list of tuples (x_batch, y_batch), each of size batch_size\n",
    "    (last batch may be smaller).\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    \n",
    "    # Make key\n",
    "    key = random.PRNGKey(0)\n",
    "    perm = jax.random.permutation(key, n)\n",
    "    x_shuffled = x[perm]\n",
    "    y_shuffled = y[perm]\n",
    "\n",
    "    batches = []\n",
    "    for i in range(0, n, batch_size):\n",
    "        x_batch = x_shuffled[i:i+batch_size]\n",
    "        y_batch = y_shuffled[i:i+batch_size]\n",
    "        batches.append((x_batch, y_batch))\n",
    "\n",
    "    return batches\n",
    "\n",
    "def get_splits(x, y, train=0.8, classification=True):\n",
    "    \"\"\"\n",
    "    This return a jax array of the training, validation, and test splits\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    x = jnp.array(x) / 255.0 if classification else x\n",
    "    y = jnp.array(y)\n",
    "    # Calculate split indices (as integers)\n",
    "    train_end = int(train * n)\n",
    "    test_end = train_end + int((1-train)) * n\n",
    "    \n",
    "    # Split the data\n",
    "    x_train = x[:train_end]\n",
    "    y_train = y[:train_end]\n",
    "    \n",
    "    x_test = x[test_end:]\n",
    "    y_test = y[test_end:]\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def get_kfolds(x, y, k=5):\n",
    "    \"\"\"\n",
    "    Generate k-fold cross-validation splits.\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "\n",
    "    fold_size = n // k\n",
    "    folds = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # Validation fold indices\n",
    "        val_start = i * fold_size\n",
    "        val_end = (i + 1) * fold_size if i < k - 1 else n\n",
    "        \n",
    "        # Validation set\n",
    "        x_val = x[val_start:val_end]\n",
    "        y_val = y[val_start:val_end]\n",
    "        \n",
    "        # Training set (everything except validation fold)\n",
    "        x_train = jnp.concatenate([x[:val_start], x[val_end:]], axis=0)\n",
    "        y_train = jnp.concatenate([y[:val_start], y[val_end:]], axis=0)\n",
    "        \n",
    "        folds.append((x_train, y_train, x_val, y_val))\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c460bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we define the MSE loss function, we can have other loss functions\n",
    "def mse_loss(params, x, y, activation):\n",
    "    \"\"\"\n",
    "    MSE loss function for the network.\n",
    "    \"\"\"\n",
    "    batched_forward = vmap(forward, in_axes=(None, 0, None))\n",
    "    preds = batched_forward(params, x, activation)\n",
    "    return jnp.mean((preds - y) ** 2)\n",
    "\n",
    "def class_loss(params, x, y, activation):\n",
    "    \"\"\"\n",
    "    Classification cross-entroy loss function\n",
    "    \"\"\"\n",
    "    batched_forward = vmap(forward, in_axes=(None, 0, None))\n",
    "    logits = batched_forward(params, x, activation)\n",
    "\n",
    "    log_probs = jax.nn.log_softmax(logits, axis=1)\n",
    "    \n",
    "    nll = -log_probs[jnp.arange(y.shape[0]), y]\n",
    "    loss = jnp.mean(nll)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def evaluate_model(params, x, y, activation, classification):\n",
    "    \"\"\"\n",
    "    Evaluate model on a dataset and return accuracy and loss.\n",
    "    \"\"\"\n",
    "    batched_forward = vmap(forward, in_axes=(None, 0, None))\n",
    "    logits = batched_forward(params, x, activation)\n",
    "\n",
    "    if classification:\n",
    "        preds = jnp.argmax(logits, axis=1)\n",
    "        \n",
    "        accuracy = jnp.mean(preds == y)\n",
    "        loss = class_loss(params, x, y, activation)\n",
    "        \n",
    "        return accuracy, loss\n",
    "    else:\n",
    "        loss = jnp.mean((logits - y) ** 2)\n",
    "        return loss, loss # we return the loss twice for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d3f55d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now define an update function that updates the network parameters.\n",
    "def update(params, x, y, activation, lr, classification):\n",
    "    \"\"\"\n",
    "    Update function for the network parameters (basic gradient descent).\n",
    "    \"\"\"\n",
    "    loss_fn = class_loss if classification else mse_loss\n",
    "    grads = grad(loss_fn)(params, x, y, activation)\n",
    "    new_params = jax.tree.map(lambda p, g: p - lr * g, params, grads)\n",
    "    return new_params\n",
    "\n",
    "# After training, save the parameters\n",
    "def save_params(params, filename='assets/params.pkl'):\n",
    "    \"\"\"Save model parameters.\"\"\"\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "    print(f\"Parameters saved to {filename}\")\n",
    "\n",
    "def load_params(filename='assets/params.pkl'):\n",
    "    \"\"\"Load model parameters.\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "    print(f\"Parameters loaded from {filename}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dd746a",
   "metadata": {},
   "source": [
    "2. Consider a standard benchmark dataset for classification: train a neural network to classify handwritten digits into the ten classes 0, 1,..., 9. As input for your model, use flattened vector representations of the MNIST images\n",
    "\n",
    "   (a) For this multiclass classification task, train your neural network with cross-entropy loss and mini-batch gradient descent. Vary the neural network architecture (layers, neurons per layer, activation functions) and training hyperparameters (learning rate, batch size, epochs). Use grid search with k-fold cross-validation (e.g., k = 5) to select promising hyperparameters. Report the accuracy and learning curves for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a855b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 70000 images\n",
      "Each image has 784 pixels (features)\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784')\n",
    "print(f\"We have {mnist.data.shape[0]} images\")\n",
    "print(f\"Each image has {mnist.data.shape[1]} pixels (features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5dc4e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_kfold(x_train, y_train, layer_widths, activation, lr, batch_size, epochs, k=5, classification=True):\n",
    "    \"\"\"\n",
    "    Train the model using kfold cross-validation.\n",
    "    \"\"\"\n",
    "    folds = get_kfolds(x_train, y_train, k=k)\n",
    "    fold_results =[]\n",
    "\n",
    "    for fold_idx, (x_train_fold, y_train_fold, x_val_fold, y_val_fold) in enumerate(folds):\n",
    "        key = random.PRNGKey(42 + fold_idx) # we use a different key for each fold\n",
    "        params = init_net_params(layer_widths, key)\n",
    "\n",
    "        fold_history = {\n",
    "            'train_acc': [],\n",
    "            'val_acc': [],\n",
    "            'train_loss': [],\n",
    "            'val_loss': []\n",
    "        }\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            batches = get_batches(x_train_fold, y_train_fold, batch_size=batch_size)\n",
    "\n",
    "            for x_batch, y_batch in batches:\n",
    "                params = update(params, x_batch, y_batch, activation, lr, classification=classification)\n",
    "            \n",
    "            train_acc, train_loss = evaluate_model(params, x_train_fold, y_train_fold, activation, classification=classification)\n",
    "            val_acc, val_loss = evaluate_model(params, x_val_fold, y_val_fold, activation, classification=classification)\n",
    "\n",
    "            fold_history['train_acc'].append(float(train_acc))\n",
    "            fold_history['val_acc'].append(float(val_acc))\n",
    "            fold_history['train_loss'].append(float(train_loss))\n",
    "            fold_history['val_loss'].append(float(val_loss))\n",
    "            \n",
    "            if epoch % 50 == 0:\n",
    "                if classification:\n",
    "                    print(f\"Fold {fold_idx+1}, Epoch {epoch}: Train Acc = {train_acc:.4f}, Val Acc = {val_acc:.4f}\")\n",
    "                else:\n",
    "                    print(f\"Fold {fold_idx+1}, Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "        \n",
    "        final_train_acc, final_train_loss = evaluate_model(params, x_train_fold, y_train_fold, activation, classification=classification)\n",
    "        final_val_acc, final_val_loss = evaluate_model(params, x_val_fold, y_val_fold, activation, classification=classification)\n",
    "\n",
    "        fold_results.append((final_train_acc, final_val_acc, final_train_loss, final_val_loss))\n",
    "    \n",
    "    mean_val_acc = np.mean([fold[1] for fold in fold_results])\n",
    "    mean_val_loss = np.mean([fold[3] for fold in fold_results])\n",
    "    \n",
    "    return mean_val_acc, mean_val_loss\n",
    "\n",
    "def train_model(x_train, y_train, x_test, y_test, best_config, classification=True):\n",
    "    \"\"\"\n",
    "    Train the best model on the full training set and evaluate on test set.\n",
    "    \"\"\"\n",
    "    layer_widths = best_config['layer_widths']\n",
    "    activation = best_config['activation']\n",
    "    lr = best_config['learning_rate']\n",
    "    batch_size = best_config['batch_size']\n",
    "    epochs = best_config['epochs']\n",
    "    \n",
    "    print(f\"\\nTraining best model on full training set...\")\n",
    "    print(f\"Configuration: {best_config}\")\n",
    "    \n",
    "    # Initialize parameters\n",
    "    key = random.PRNGKey(42)\n",
    "    params = init_net_params(layer_widths, key)\n",
    "    \n",
    "    learning_curve = {\n",
    "        'train_acc': [],\n",
    "        'test_acc': [],\n",
    "        'train_loss': [],\n",
    "        'test_loss': []\n",
    "    }\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        batches = get_batches(x_train, y_train, batch_size=batch_size)\n",
    "        \n",
    "        for x_batch, y_batch in batches:\n",
    "            params = update(params, x_batch, y_batch, activation, lr, classification=classification)\n",
    "        \n",
    "        # Evaluate periodically\n",
    "        if epoch % 1 == 0 or epoch == epochs - 1:\n",
    "            train_acc, train_loss = evaluate_model(params, x_train, y_train, activation, classification=classification)\n",
    "            test_acc, test_loss = evaluate_model(params, x_test, y_test, activation, classification=classification)\n",
    "            \n",
    "            learning_curve['train_acc'].append(float(train_acc))\n",
    "            learning_curve['test_acc'].append(float(test_acc))\n",
    "            learning_curve['train_loss'].append(float(train_loss))\n",
    "            learning_curve['test_loss'].append(float(test_loss))\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                if classification:\n",
    "                    print(f\"Epoch {epoch}: Train Acc = {train_acc:.4f}, Test Acc = {test_acc:.4f}\")\n",
    "                else:\n",
    "                    print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Test Loss = {test_loss:.4f}\")\n",
    "    \n",
    "    # Final evaluation\n",
    "    test_acc, test_loss = evaluate_model(params, x_test, y_test, activation, classification=classification)\n",
    "    print(f\"\\nFinal Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\") if classification else print(f\"\\nFinal Test Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    return params, test_acc, test_loss, learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4a69033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search configurations\n",
    "grid_search_configs = {\n",
    "    # Testing Baseline vs. Wide vs. Deep\n",
    "    'architectures': [\n",
    "        # hidden layers\n",
    "        [784, 16, 10],\n",
    "        [784, 16, 16, 10],\n",
    "        [784, 16, 16, 16, 10],\n",
    "    ],\n",
    "    \n",
    "    # Activation functions to test\n",
    "    'activations': ['relu'],\n",
    "    \n",
    "    # Learning rates\n",
    "    'learning_rates': [0.1, 0.01],\n",
    "    \n",
    "    # Batch sizes (speed vs gradient noise)\n",
    "    'batch_sizes': [64, 128],\n",
    "    \n",
    "    # Epochs\n",
    "    'epochs': [20] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "20bb31c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the grid search function\n",
    "def grid_search(x_train, y_train, configs, k=5, classification=True):\n",
    "    \"\"\"\n",
    "    Perform grid search on the space of possible parameters defined earlier using k-fold cross validation\n",
    "    \n",
    "    \"\"\"\n",
    "    # Generate all combinations\n",
    "    combinations = list(itertools.product(\n",
    "        configs['architectures'],\n",
    "        configs['activations'],\n",
    "        configs['learning_rates'],\n",
    "        configs['batch_sizes'],\n",
    "        configs['epochs']\n",
    "    ))\n",
    "\n",
    "    total_combinations = len(combinations)\n",
    "    print(f\"Total configurations to test: {total_combinations}\")\n",
    "    print(f\"With k={k} folds, total training runs: {total_combinations * k}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    best_acc = -1\n",
    "    best_loss = np.inf\n",
    "    best_config = None\n",
    "\n",
    "    for idx, (layer_widths, activation, lr, batch_size, epochs) in enumerate(combinations):\n",
    "        print(f\"\\n[{idx+1}/{total_combinations}] Testing configuration:\")\n",
    "        print(f\"Architecture: {layer_widths}\")\n",
    "        print(f\"Activation: {activation}\")\n",
    "        print(f\"Learning Rate: {lr}\")\n",
    "        print(f\"Batch Size: {batch_size}\")\n",
    "        print(f\"Epochs: {epochs}\")\n",
    "        \n",
    "        mean_val_acc, mean_val_loss = train_model_kfold(\n",
    "            x_train, y_train, layer_widths, activation, lr, batch_size, epochs, k=k, classification=classification\n",
    "        )\n",
    "        \n",
    "        # result\n",
    "        config = {\n",
    "            'layer_widths': layer_widths,\n",
    "            'activation': activation,\n",
    "            'learning_rate': lr,\n",
    "            'batch_size': batch_size,\n",
    "            'epochs': epochs\n",
    "        }\n",
    "        \n",
    "        print(f\"Mean Validation Accuracy: {mean_val_acc:.4f} ({mean_val_acc*100:.2f}%)\")\n",
    "        print(f\"Mean Validation Loss: {mean_val_loss:.4f}\")\n",
    "        \n",
    "        # Update best configuration\n",
    "        if classification:\n",
    "            if mean_val_acc > best_acc:\n",
    "                best_acc = mean_val_acc\n",
    "                best_loss = mean_val_loss\n",
    "                best_config = config.copy()\n",
    "                print(f\"New best configuration!\")\n",
    "        else:\n",
    "            if mean_val_loss < best_loss:\n",
    "                best_loss = mean_val_loss\n",
    "                best_config = config.copy()\n",
    "                print(f\"New best configuration!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Grid Search Complete!\")\n",
    "    print(f\"Best Configuration:\")\n",
    "    print(f\"Architecture: {best_config['layer_widths']}\")\n",
    "    print(f\"Activation: {best_config['activation']}\")\n",
    "    print(f\"Learning Rate: {best_config['learning_rate']}\")\n",
    "    print(f\"Batch Size: {best_config['batch_size']}\")\n",
    "    print(f\"Epochs: {best_config['epochs']}\")\n",
    "    print(f\"Best Mean Validation Accuracy: {best_acc:.4f} ({best_acc*100:.2f}%)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return best_config, best_acc, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "33f92399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configurations to test: 12\n",
      "With k=3 folds, total training runs: 36\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[1/12] Testing configuration:\n",
      "Architecture: [784, 16, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.9067, Val Acc = 0.9050\n",
      "Fold 2, Epoch 0: Train Acc = 0.9064, Val Acc = 0.9040\n",
      "Fold 3, Epoch 0: Train Acc = 0.8824, Val Acc = 0.8727\n",
      "Mean Validation Accuracy: 0.9418 (94.18%)\n",
      "Mean Validation Loss: 0.2100\n",
      "New best configuration!\n",
      "\n",
      "[2/12] Testing configuration:\n",
      "Architecture: [784, 16, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.8951, Val Acc = 0.8931\n",
      "Fold 2, Epoch 0: Train Acc = 0.8934, Val Acc = 0.8927\n",
      "Fold 3, Epoch 0: Train Acc = 0.8931, Val Acc = 0.8837\n",
      "Mean Validation Accuracy: 0.9398 (93.98%)\n",
      "Mean Validation Loss: 0.2098\n",
      "\n",
      "[3/12] Testing configuration:\n",
      "Architecture: [784, 16, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.8114, Val Acc = 0.8094\n",
      "Fold 2, Epoch 0: Train Acc = 0.8236, Val Acc = 0.8212\n",
      "Fold 3, Epoch 0: Train Acc = 0.8275, Val Acc = 0.8298\n",
      "Mean Validation Accuracy: 0.9195 (91.95%)\n",
      "Mean Validation Loss: 0.2855\n",
      "\n",
      "[4/12] Testing configuration:\n",
      "Architecture: [784, 16, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.7148, Val Acc = 0.7139\n",
      "Fold 2, Epoch 0: Train Acc = 0.7373, Val Acc = 0.7303\n",
      "Fold 3, Epoch 0: Train Acc = 0.7551, Val Acc = 0.7577\n",
      "Mean Validation Accuracy: 0.9090 (90.90%)\n",
      "Mean Validation Loss: 0.3192\n",
      "\n",
      "[5/12] Testing configuration:\n",
      "Architecture: [784, 16, 16, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.9021, Val Acc = 0.9009\n",
      "Fold 2, Epoch 0: Train Acc = 0.8957, Val Acc = 0.8904\n",
      "Fold 3, Epoch 0: Train Acc = 0.8552, Val Acc = 0.8437\n",
      "Mean Validation Accuracy: 0.9363 (93.63%)\n",
      "Mean Validation Loss: 0.2419\n",
      "\n",
      "[6/12] Testing configuration:\n",
      "Architecture: [784, 16, 16, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.8750, Val Acc = 0.8773\n",
      "Fold 2, Epoch 0: Train Acc = 0.8888, Val Acc = 0.8900\n",
      "Fold 3, Epoch 0: Train Acc = 0.8823, Val Acc = 0.8749\n",
      "Mean Validation Accuracy: 0.9424 (94.24%)\n",
      "Mean Validation Loss: 0.2079\n",
      "New best configuration!\n",
      "\n",
      "[7/12] Testing configuration:\n",
      "Architecture: [784, 16, 16, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.7276, Val Acc = 0.7254\n",
      "Fold 2, Epoch 0: Train Acc = 0.7889, Val Acc = 0.7910\n",
      "Fold 3, Epoch 0: Train Acc = 0.8215, Val Acc = 0.8136\n",
      "Mean Validation Accuracy: 0.9310 (93.10%)\n",
      "Mean Validation Loss: 0.2401\n",
      "\n",
      "[8/12] Testing configuration:\n",
      "Architecture: [784, 16, 16, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.5042, Val Acc = 0.5076\n",
      "Fold 2, Epoch 0: Train Acc = 0.6527, Val Acc = 0.6477\n",
      "Fold 3, Epoch 0: Train Acc = 0.7124, Val Acc = 0.7105\n",
      "Mean Validation Accuracy: 0.9204 (92.04%)\n",
      "Mean Validation Loss: 0.2830\n",
      "\n",
      "[9/12] Testing configuration:\n",
      "Architecture: [784, 16, 16, 16, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.8761, Val Acc = 0.8757\n",
      "Fold 2, Epoch 0: Train Acc = 0.8447, Val Acc = 0.8393\n",
      "Fold 3, Epoch 0: Train Acc = 0.7397, Val Acc = 0.7340\n",
      "Mean Validation Accuracy: 0.9406 (94.06%)\n",
      "Mean Validation Loss: 0.2349\n",
      "\n",
      "[10/12] Testing configuration:\n",
      "Architecture: [784, 16, 16, 16, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.8761, Val Acc = 0.8709\n",
      "Fold 2, Epoch 0: Train Acc = 0.8398, Val Acc = 0.8364\n",
      "Fold 3, Epoch 0: Train Acc = 0.8490, Val Acc = 0.8397\n",
      "Mean Validation Accuracy: 0.9346 (93.46%)\n",
      "Mean Validation Loss: 0.2393\n",
      "\n",
      "[11/12] Testing configuration:\n",
      "Architecture: [784, 16, 16, 16, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.7482, Val Acc = 0.7438\n",
      "Fold 2, Epoch 0: Train Acc = 0.8145, Val Acc = 0.8106\n",
      "Fold 3, Epoch 0: Train Acc = 0.7866, Val Acc = 0.7793\n",
      "Mean Validation Accuracy: 0.9298 (92.98%)\n",
      "Mean Validation Loss: 0.2417\n",
      "\n",
      "[12/12] Testing configuration:\n",
      "Architecture: [784, 16, 16, 16, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.6096, Val Acc = 0.6068\n",
      "Fold 2, Epoch 0: Train Acc = 0.6831, Val Acc = 0.6849\n",
      "Fold 3, Epoch 0: Train Acc = 0.4528, Val Acc = 0.4519\n",
      "Mean Validation Accuracy: 0.9214 (92.14%)\n",
      "Mean Validation Loss: 0.2756\n",
      "\n",
      "================================================================================\n",
      "Grid Search Complete!\n",
      "Best Configuration:\n",
      "Architecture: [784, 16, 16, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Best Mean Validation Accuracy: 0.9424 (94.24%)\n",
      "================================================================================\n",
      "The best configuration is:\n",
      "{'layer_widths': [784, 16, 16, 10], 'activation': 'relu', 'learning_rate': 0.1, 'batch_size': 128, 'epochs': 20}\n",
      "Best K-fold Mean Accuracy: 0.94 (94.24%)\n",
      "Best K-fold Mean Loss: 0.21\n"
     ]
    }
   ],
   "source": [
    "# Run to perform grid search\n",
    "x = mnist.data.to_numpy()\n",
    "y = mnist.target.astype(int).to_numpy()\n",
    "x_train, y_train, x_test, y_test = get_splits(x, y)\n",
    "\n",
    "# Run grid search to find best configs\n",
    "best_config, best_acc, best_loss = grid_search(\n",
    "    x_train, y_train, \n",
    "    grid_search_configs, \n",
    "    k=3\n",
    ")\n",
    "\n",
    "print(\"The best configuration is:\")\n",
    "print(best_config)\n",
    "print(f\"Best K-fold Mean Accuracy: {best_acc:.2f} ({best_acc*100:.2f}%)\")\n",
    "print(f\"Best K-fold Mean Loss: {best_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b3ed26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training best model on full training set...\n",
      "Configuration: {'layer_widths': [784, 16, 16, 10], 'activation': 'relu', 'learning_rate': 0.1, 'batch_size': 64, 'epochs': 250}\n",
      "Epoch 0: Train Acc = 0.9138, Test Acc = 0.9204\n",
      "Epoch 10: Train Acc = 0.9489, Test Acc = 0.9449\n",
      "Epoch 20: Train Acc = 0.9562, Test Acc = 0.9465\n",
      "Epoch 30: Train Acc = 0.9640, Test Acc = 0.9505\n",
      "Epoch 40: Train Acc = 0.9657, Test Acc = 0.9486\n",
      "Epoch 50: Train Acc = 0.9676, Test Acc = 0.9488\n",
      "Epoch 60: Train Acc = 0.9673, Test Acc = 0.9475\n",
      "Epoch 70: Train Acc = 0.9689, Test Acc = 0.9470\n",
      "Epoch 80: Train Acc = 0.9685, Test Acc = 0.9459\n",
      "Epoch 90: Train Acc = 0.9690, Test Acc = 0.9444\n",
      "Epoch 100: Train Acc = 0.9683, Test Acc = 0.9439\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train best model on the best params\u001b[39;00m\n\u001b[1;32m      2\u001b[0m best_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer_widths\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m784\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m250\u001b[39m\n\u001b[1;32m      8\u001b[0m }\n\u001b[0;32m---> 10\u001b[0m params, test_acc, test_loss, learning_curve \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_config\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOur best model trained on the full training set has an accuracy of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOur best model trained on the full training set has a loss of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[63], line 78\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(x_train, y_train, x_test, y_test, best_config, classification)\u001b[0m\n\u001b[1;32m     75\u001b[0m batches \u001b[38;5;241m=\u001b[39m get_batches(x_train, y_train, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[0;32m---> 78\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassification\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Evaluate periodically\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "Cell \u001b[0;32mIn[61], line 7\u001b[0m, in \u001b[0;36mupdate\u001b[0;34m(params, x, y, activation, lr, classification)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mUpdate function for the network parameters (basic gradient descent).\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m class_loss \u001b[38;5;28;01mif\u001b[39;00m classification \u001b[38;5;28;01melse\u001b[39;00m mse_loss\n\u001b[0;32m----> 7\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m new_params \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m p, g: p \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m g, params, grads)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_params\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:399\u001b[0m, in \u001b[0;36mgrad.<locals>.grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fun, docstr\u001b[38;5;241m=\u001b[39mdocstr, argnums\u001b[38;5;241m=\u001b[39margnums)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgrad_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 399\u001b[0m   _, g \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_and_grad_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:470\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m   _check_input_dtype_grad(holomorphic, allow_int, leaf)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 470\u001b[0m   ans, vjp_py \u001b[38;5;241m=\u001b[39m \u001b[43m_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_partial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdyn_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    472\u001b[0m   ans, vjp_py, aux \u001b[38;5;241m=\u001b[39m _vjp(\n\u001b[1;32m    473\u001b[0m       f_partial, \u001b[38;5;241m*\u001b[39mdyn_args, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:2015\u001b[0m, in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, *primals)\u001b[0m\n\u001b[1;32m   2013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[1;32m   2014\u001b[0m   flat_fun, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun_nokwargs(fun, in_tree)\n\u001b[0;32m-> 2015\u001b[0m   out_primals, vjp \u001b[38;5;241m=\u001b[39m \u001b[43mad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2016\u001b[0m   out_tree \u001b[38;5;241m=\u001b[39m out_tree()\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:260\u001b[0m, in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvjp\u001b[39m(traceable: lu\u001b[38;5;241m.\u001b[39mWrappedFun, primals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    259\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 260\u001b[0m     out_primals, pvals, jaxpr, consts \u001b[38;5;241m=\u001b[39m \u001b[43mlinearize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraceable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m     out_primals, pvals, jaxpr, consts, aux \u001b[38;5;241m=\u001b[39m linearize(traceable, \u001b[38;5;241m*\u001b[39mprimals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:245\u001b[0m, in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m _, in_tree \u001b[38;5;241m=\u001b[39m tree_flatten(((primals, primals), {}))\n\u001b[1;32m    244\u001b[0m jvpfun_flat, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun(jvpfun, in_tree)\n\u001b[0;32m--> 245\u001b[0m jaxpr, out_pvals, consts \u001b[38;5;241m=\u001b[39m \u001b[43mpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_to_jaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjvpfun_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m out_primals_pvals, out_tangents_pvals \u001b[38;5;241m=\u001b[39m tree_unflatten(out_tree(), out_pvals)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m out_primal_pval\u001b[38;5;241m.\u001b[39mis_known() \u001b[38;5;28;01mfor\u001b[39;00m out_primal_pval \u001b[38;5;129;01min\u001b[39;00m out_primals_pvals):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/profiler.py:334\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    333\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:576\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_nounits\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    574\u001b[0m fun \u001b[38;5;241m=\u001b[39m trace_to_subjaxpr_nounits(fun, trace, instantiate, fun\u001b[38;5;241m.\u001b[39mdebug_info)\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m--> 576\u001b[0m   jaxpr, (out_pvals, consts, env) \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m trace, fun\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/linear_util.py:210\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    209\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the transformed function\"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_transformed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:590\u001b[0m, in \u001b[0;36mtrace_to_subjaxpr_nounits\u001b[0;34m(f, trace, instantiate, debug_info, in_pvals)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation2\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrace_to_subjaxpr_nounits\u001b[39m(\n\u001b[1;32m    584\u001b[0m     f: Callable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    587\u001b[0m     debug_info: core\u001b[38;5;241m.\u001b[39mDebugInfo,\n\u001b[1;32m    588\u001b[0m     in_pvals: Sequence[PartialVal]):\n\u001b[1;32m    589\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(pv, PartialVal) \u001b[38;5;28;01mfor\u001b[39;00m pv \u001b[38;5;129;01min\u001b[39;00m in_pvals), in_pvals\n\u001b[0;32m--> 590\u001b[0m   out_tracers, jaxpr, out_consts, env \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_to_subjaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m      \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstantiate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m   out_pvals \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mpval \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m out_tracers]\n\u001b[1;32m    593\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m out_tracers\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:623\u001b[0m, in \u001b[0;36m_trace_to_subjaxpr_nounits\u001b[0;34m(f, trace, instantiate, in_pvals, debug_info)\u001b[0m\n\u001b[1;32m    621\u001b[0m in_args \u001b[38;5;241m=\u001b[39m merge_lists(in_knowns, in_tracers, in_consts)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m--> 623\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ans, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)), (\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected return type when tracing function to jaxpr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mans\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, core\u001b[38;5;241m.\u001b[39mTracer) \u001b[38;5;129;01mor\u001b[39;00m core\u001b[38;5;241m.\u001b[39mvalid_jaxtype(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m ans), (\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected return type when tracing function to jaxpr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mans\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api_util.py:73\u001b[0m, in \u001b[0;36mflatten_fun\u001b[0;34m(f, store, in_tree, *args_flat)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_with_aux2\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflatten_fun\u001b[39m(f: Callable, store: lu\u001b[38;5;241m.\u001b[39mStore,\n\u001b[1;32m     71\u001b[0m                 in_tree: PyTreeDef, \u001b[38;5;241m*\u001b[39margs_flat):\n\u001b[1;32m     72\u001b[0m   py_args, py_kwargs \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, args_flat)\n\u001b[0;32m---> 73\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m   ans, out_tree \u001b[38;5;241m=\u001b[39m tree_flatten(ans)\n\u001b[1;32m     75\u001b[0m   store\u001b[38;5;241m.\u001b[39mstore(out_tree)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:80\u001b[0m, in \u001b[0;36mjvpfun\u001b[0;34m(f, instantiate, transform_stack, primals, tangents)\u001b[0m\n\u001b[1;32m     77\u001b[0m ctx \u001b[38;5;241m=\u001b[39m (source_info_util\u001b[38;5;241m.\u001b[39mtransform_name_stack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjvp\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m transform_stack\n\u001b[1;32m     78\u001b[0m        \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext())\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[0;32m---> 80\u001b[0m   out_primals, out_tangents \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtangents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(instantiate) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     82\u001b[0m   instantiate \u001b[38;5;241m=\u001b[39m [instantiate] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(out_tangents)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:120\u001b[0m, in \u001b[0;36mjvp_subtrace\u001b[0;34m(f, tag, primals, tangents)\u001b[0m\n\u001b[1;32m    117\u001b[0m   in_tracers \u001b[38;5;241m=\u001b[39m [maybe_jvp_tracer(trace, x, t)\n\u001b[1;32m    118\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m x, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(primals, tangents)]\n\u001b[1;32m    119\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m--> 120\u001b[0m     ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_tracers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m   out \u001b[38;5;241m=\u001b[39m unzip2(\u001b[38;5;28mmap\u001b[39m(trace\u001b[38;5;241m.\u001b[39mto_primal_tangent_pair, ans))\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api_util.py:90\u001b[0m, in \u001b[0;36mflatten_fun_nokwargs\u001b[0;34m(f, store, in_tree, *args_flat)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_with_aux2\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflatten_fun_nokwargs\u001b[39m(f: Callable, store: lu\u001b[38;5;241m.\u001b[39mStore,\n\u001b[1;32m     88\u001b[0m                          in_tree: PyTreeDef, \u001b[38;5;241m*\u001b[39margs_flat):\n\u001b[1;32m     89\u001b[0m   py_args \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, args_flat)\n\u001b[0;32m---> 90\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m   ans, out_tree \u001b[38;5;241m=\u001b[39m tree_flatten(ans)\n\u001b[1;32m     92\u001b[0m   store\u001b[38;5;241m.\u001b[39mstore(out_tree)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api_util.py:284\u001b[0m, in \u001b[0;36m_argnums_partial\u001b[0;34m(_fun, _dyn_argnums, _fixed_args, *dyn_args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m args \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mnext\u001b[39m(fixed_args_)\u001b[38;5;241m.\u001b[39mval \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m sentinel \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(fixed_args_, sentinel) \u001b[38;5;129;01mis\u001b[39;00m sentinel\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/linear_util.py:370\u001b[0m, in \u001b[0;36m_get_result_paths_thunk\u001b[0;34m(_fun, _store, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;129m@transformation_with_aux2\u001b[39m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_result_paths_thunk\u001b[39m(_fun: Callable, _store: Store, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 370\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m   result_paths \u001b[38;5;241m=\u001b[39m [_clean_keystr_arg_names(path) \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m generate_key_paths(ans)]\n\u001b[1;32m    372\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _store:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# In some instances a lu.WrappedFun is called multiple times, e.g.,\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# the bwd function in a custom_vjp\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[60], line 19\u001b[0m, in \u001b[0;36mclass_loss\u001b[0;34m(params, x, y, activation)\u001b[0m\n\u001b[1;32m     15\u001b[0m logits \u001b[38;5;241m=\u001b[39m batched_forward(params, x, activation)\n\u001b[1;32m     17\u001b[0m log_probs \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mlog_softmax(logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m nll \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mlog_probs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mmean(nll)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:1060\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 1060\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:652\u001b[0m, in \u001b[0;36m_getitem\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_getitem\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[0;32m--> 652\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrewriting_take\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/numpy/indexing.py:628\u001b[0m, in \u001b[0;36mrewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices, mode, fill_value, out_sharding)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39mdynamic_index_in_dim(arr, idx, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    627\u001b[0m treedef, static_idx, dynamic_idx \u001b[38;5;241m=\u001b[39m split_index_for_jit(idx, arr\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 628\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_gather\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtreedef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatic_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices_are_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m               \u001b[49m\u001b[43munique_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_sharding\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/numpy/indexing.py:637\u001b[0m, in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices, mode, fill_value, out_sharding)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_gather\u001b[39m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[1;32m    635\u001b[0m             unique_indices, mode, fill_value, out_sharding):\n\u001b[1;32m    636\u001b[0m   idx \u001b[38;5;241m=\u001b[39m merge_static_and_dynamic_indices(treedef, static_idx, dynamic_idx)\n\u001b[0;32m--> 637\u001b[0m   indexer \u001b[38;5;241m=\u001b[39m \u001b[43mindex_to_gather\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shared with _scatter_update\u001b[39;00m\n\u001b[1;32m    638\u001b[0m   y \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m    640\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/numpy/indexing.py:792\u001b[0m, in \u001b[0;36mindex_to_gather\u001b[0;34m(x_shape, idx, normalize_indices)\u001b[0m\n\u001b[1;32m    789\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m normalize_indices:\n\u001b[1;32m    790\u001b[0m     advanced_pairs \u001b[38;5;241m=\u001b[39m ((_normalize_index(e, x_shape[j]), i, j)\n\u001b[1;32m    791\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m e, i, j \u001b[38;5;129;01min\u001b[39;00m advanced_pairs)\n\u001b[0;32m--> 792\u001b[0m   advanced_indexes, idx_advanced_axes, x_advanced_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madvanced_pairs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    794\u001b[0m x_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Current axis in x.\u001b[39;00m\n\u001b[1;32m    795\u001b[0m y_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Current axis in y, before collapsing. See below.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/numpy/indexing.py:790\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    786\u001b[0m   advanced_pairs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    787\u001b[0m     (lax_numpy\u001b[38;5;241m.\u001b[39masarray(e), i, j) \u001b[38;5;28;01mfor\u001b[39;00m j, (i, e) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(idx_no_nones)\n\u001b[1;32m    788\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lax_numpy\u001b[38;5;241m.\u001b[39misscalar(e) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (Sequence, Array, np\u001b[38;5;241m.\u001b[39mndarray)))\n\u001b[1;32m    789\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m normalize_indices:\n\u001b[0;32m--> 790\u001b[0m     advanced_pairs \u001b[38;5;241m=\u001b[39m ((\u001b[43m_normalize_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m, i, j)\n\u001b[1;32m    791\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m e, i, j \u001b[38;5;129;01min\u001b[39;00m advanced_pairs)\n\u001b[1;32m    792\u001b[0m   advanced_indexes, idx_advanced_axes, x_advanced_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39madvanced_pairs)\n\u001b[1;32m    794\u001b[0m x_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Current axis in x.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/numpy/indexing.py:201\u001b[0m, in \u001b[0;36m_normalize_index\u001b[0;34m(index, axis_size)\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39madd(index, axis_size_val) \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m index\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 201\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39mselect(\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m, lax\u001b[38;5;241m.\u001b[39madd(index, axis_size_val), index)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:579\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    577\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 579\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/traceback_util.py:176\u001b[0m, in \u001b[0;36mapi_boundary.<locals>.reraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapi_boundary\u001b[39m(fun: C) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m C:\n\u001b[1;32m    154\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m'''Wraps ``fun`` to form a boundary for filtering exception tracebacks.\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m  When an exception occurs below ``fun``, this appends to it a custom\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03m  traceback that excludes the frames specific to JAX's implementation.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03m  '''\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m   \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fun)\n\u001b[1;32m    177\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreraise_with_filtered_traceback\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    178\u001b[0m     __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train best model on the best params\n",
    "best_config = {\n",
    "    'layer_widths': [784, 16, 16, 10],\n",
    "    'activation': 'relu',\n",
    "    'learning_rate': 0.1,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 100\n",
    "}\n",
    "\n",
    "params, test_acc, test_loss, learning_curve = train_model(\n",
    "    x_train, y_train, x_test, y_test, best_config\n",
    ")\n",
    "\n",
    "print(f\"Our best model trained on the full training set has an accuracy of {test_acc}%\")\n",
    "print(f\"Our best model trained on the full training set has a loss of {test_loss:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(learning_curve['train_acc'], label='Training Accuracy')\n",
    "plt.plot(learning_curve['test_acc'], label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(learning_curve['train_loss'], label='Training Loss')\n",
    "plt.plot(learning_curve['test_loss'], label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "save_params(params, filename='../assets/mnist_params.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ead2d0",
   "metadata": {},
   "source": [
    "   (b) Study how optimizer hyperparameters (batch size, learning rate) affect convergence speed and final performance, and discuss your observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309297a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d94dd50e",
   "metadata": {},
   "source": [
    " (c) Identify and visualize misclassified images for your best model, and provide possible explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "34344d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters loaded from ../assets/mnist_params.pkl\n",
      "\n",
      "Final Test Accuracy: 0.9771 (97.71%)\n",
      "We have 320 misclassified images\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load params\n",
    "params = load_params('../assets/mnist_params.pkl')\n",
    "\n",
    "# get predictions\n",
    "batched_forward = vmap(forward, in_axes=(None, 0, None))\n",
    "logits = batched_forward(params, x_test, 'relu')\n",
    "preds = jnp.argmax(logits, axis=1)\n",
    "\n",
    "test_acc, test_loss = evaluate_model(params, x_test, y_test, 'relu', classification=True)\n",
    "print(f\"\\nFinal Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "\n",
    "# get misclassified images\n",
    "misclassified = jnp.where(preds != y_test)[0]\n",
    "\n",
    "print(f\"We have {len(misclassified)} misclassified images\")\n",
    "\n",
    "# plot misclassified images with correct and predicted labels\n",
    "num_figures = 10\n",
    "rows = 4\n",
    "cols = 5  # rows * cols should be >= num_figures\n",
    "\n",
    "plt.figure(figsize=(cols * 3, rows * 3))\n",
    "for i in range(num_figures):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(x_test[misclassified[i]].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"True: {y_test[misclassified[i]]}, Pred: {preds[misclassified[i]]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd3db43",
   "metadata": {},
   "source": [
    "Next, test the performance of your neural network implementation on a simple regression problem. Fit functions of the form\n",
    "\n",
    "$$f_k(x) := \\sin(k\\pi x), \\quad x \\in [-1, 1],$$\n",
    "\n",
    "with $k \\in \\mathbb{N}$ using your neural network implementation. Use mean squared error (MSE) as the loss. Generate a sufficient number of training samples yourself, balancing approximation quality and computational cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14bee00",
   "metadata": {},
   "source": [
    "(a) Perform a grid search to find the best hyperparameters for fitting $f_1$, varying at least the parameters that you also tested in Question 2. Discuss your findings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "965e947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search configurations for regression\n",
    "grid_search_configs = {\n",
    "    'architectures': [\n",
    "        # hidden layers\n",
    "        [1, 16, 1],\n",
    "        [1, 16, 16, 1],\n",
    "        [1, 16, 16, 16, 1],\n",
    "    ],\n",
    "    \n",
    "    # Activation functions\n",
    "    'activations': ['relu'],\n",
    "    \n",
    "    # Learning rates\n",
    "    'learning_rates': [0.1, 0.01],\n",
    "    \n",
    "    # Batch sizes\n",
    "    'batch_sizes': [64, 256],\n",
    "    \n",
    "    # Epochs\n",
    "    'epochs': [50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c89ec276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by generating a sufficient number of training samples.\n",
    "n_samples = 20000\n",
    "k = 1\n",
    "x = jnp.linspace(-1, 1, n_samples).reshape(-1, 1)\n",
    "y = jnp.sin(k * jnp.pi * x)\n",
    "\n",
    "key = random.PRNGKey(42)\n",
    "indices = jnp.arange(n_samples)\n",
    "shuffled_indices = random.permutation(key, indices)\n",
    "x_shuffled = x[shuffled_indices]\n",
    "y_shuffled = y[shuffled_indices]\n",
    "\n",
    "x_train, y_train, x_test, y_test = get_splits(x_shuffled, y_shuffled, classification=False)\n",
    "\n",
    "# sort the x_test and y_test to plot\n",
    "sort_idx = jnp.argsort(x_test.flatten())\n",
    "x_test = x_test[sort_idx]\n",
    "y_test = y_test[sort_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a543bc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configurations to test: 12\n",
      "With k=3 folds, total training runs: 36\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[1/12] Testing configuration:\n",
      "Architecture: [1, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.0428, Val Loss = 0.0434\n",
      "Fold 2, Epoch 0: Train Loss = 0.0506, Val Loss = 0.0493\n",
      "Fold 3, Epoch 0: Train Loss = 0.0466, Val Loss = 0.0468\n",
      "Mean Validation Accuracy: 0.0003 (0.03%)\n",
      "Mean Validation Loss: 0.0003\n",
      "New best configuration!\n",
      "\n",
      "[2/12] Testing configuration:\n",
      "Architecture: [1, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 256\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.1213, Val Loss = 0.1211\n",
      "Fold 2, Epoch 0: Train Loss = 0.1261, Val Loss = 0.1245\n",
      "Fold 3, Epoch 0: Train Loss = 0.1299, Val Loss = 0.1316\n",
      "Mean Validation Accuracy: 0.0004 (0.04%)\n",
      "Mean Validation Loss: 0.0004\n",
      "\n",
      "[3/12] Testing configuration:\n",
      "Architecture: [1, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.1512, Val Loss = 0.1511\n",
      "Fold 2, Epoch 0: Train Loss = 0.1559, Val Loss = 0.1540\n",
      "Fold 3, Epoch 0: Train Loss = 0.1576, Val Loss = 0.1601\n",
      "Mean Validation Accuracy: 0.0015 (0.15%)\n",
      "Mean Validation Loss: 0.0015\n",
      "\n",
      "[4/12] Testing configuration:\n",
      "Architecture: [1, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 256\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.1760, Val Loss = 0.1765\n",
      "Fold 2, Epoch 0: Train Loss = 0.1807, Val Loss = 0.1776\n",
      "Fold 3, Epoch 0: Train Loss = 0.2837, Val Loss = 0.2884\n",
      "Mean Validation Accuracy: 0.0301 (3.01%)\n",
      "Mean Validation Loss: 0.0301\n",
      "\n",
      "[5/12] Testing configuration:\n",
      "Architecture: [1, 16, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.0099, Val Loss = 0.0096\n",
      "Fold 2, Epoch 0: Train Loss = 0.0249, Val Loss = 0.0243\n",
      "Fold 3, Epoch 0: Train Loss = 0.1375, Val Loss = 0.1386\n",
      "Mean Validation Accuracy: 0.0001 (0.01%)\n",
      "Mean Validation Loss: 0.0001\n",
      "New best configuration!\n",
      "\n",
      "[6/12] Testing configuration:\n",
      "Architecture: [1, 16, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 256\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.0680, Val Loss = 0.0671\n",
      "Fold 2, Epoch 0: Train Loss = 0.1213, Val Loss = 0.1199\n",
      "Fold 3, Epoch 0: Train Loss = 0.1070, Val Loss = 0.1077\n",
      "Mean Validation Accuracy: 0.0005 (0.05%)\n",
      "Mean Validation Loss: 0.0005\n",
      "\n",
      "[7/12] Testing configuration:\n",
      "Architecture: [1, 16, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.1128, Val Loss = 0.1127\n",
      "Fold 2, Epoch 0: Train Loss = 0.1242, Val Loss = 0.1235\n",
      "Fold 3, Epoch 0: Train Loss = 0.1491, Val Loss = 0.1505\n",
      "Mean Validation Accuracy: 0.0003 (0.03%)\n",
      "Mean Validation Loss: 0.0003\n",
      "\n",
      "[8/12] Testing configuration:\n",
      "Architecture: [1, 16, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 256\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.1666, Val Loss = 0.1687\n",
      "Fold 2, Epoch 0: Train Loss = 0.1737, Val Loss = 0.1745\n",
      "Fold 3, Epoch 0: Train Loss = 0.1902, Val Loss = 0.1915\n",
      "Mean Validation Accuracy: 0.0073 (0.73%)\n",
      "Mean Validation Loss: 0.0073\n",
      "\n",
      "[9/12] Testing configuration:\n",
      "Architecture: [1, 8, 8, 8, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.0108, Val Loss = 0.0110\n",
      "Fold 2, Epoch 0: Train Loss = 0.0309, Val Loss = 0.0310\n",
      "Fold 3, Epoch 0: Train Loss = 0.0588, Val Loss = 0.0592\n",
      "Mean Validation Accuracy: 0.0002 (0.02%)\n",
      "Mean Validation Loss: 0.0002\n",
      "\n",
      "[10/12] Testing configuration:\n",
      "Architecture: [1, 8, 8, 8, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 256\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.0724, Val Loss = 0.0737\n",
      "Fold 2, Epoch 0: Train Loss = 0.0999, Val Loss = 0.0997\n",
      "Fold 3, Epoch 0: Train Loss = 0.4888, Val Loss = 0.4990\n",
      "Mean Validation Accuracy: 0.0011 (0.11%)\n",
      "Mean Validation Loss: 0.0011\n",
      "\n",
      "[11/12] Testing configuration:\n",
      "Architecture: [1, 8, 8, 8, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.1309, Val Loss = 0.1328\n",
      "Fold 2, Epoch 0: Train Loss = 0.1300, Val Loss = 0.1304\n",
      "Fold 3, Epoch 0: Train Loss = 0.4941, Val Loss = 0.5042\n",
      "Mean Validation Accuracy: 0.0006 (0.06%)\n",
      "Mean Validation Loss: 0.0006\n",
      "\n",
      "[12/12] Testing configuration:\n",
      "Architecture: [1, 8, 8, 8, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 256\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.2946, Val Loss = 0.2945\n",
      "Fold 2, Epoch 0: Train Loss = 0.1819, Val Loss = 0.1775\n",
      "Fold 3, Epoch 0: Train Loss = 0.4952, Val Loss = 0.5052\n",
      "Mean Validation Accuracy: 0.0229 (2.29%)\n",
      "Mean Validation Loss: 0.0229\n",
      "\n",
      "================================================================================\n",
      "Grid Search Complete!\n",
      "Best Configuration:\n",
      "Architecture: [1, 16, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 50\n",
      "Best Mean Validation Accuracy: -1.0000 (-100.00%)\n",
      "================================================================================\n",
      "The best configuration is:\n",
      "{'layer_widths': [1, 16, 16, 1], 'activation': 'relu', 'learning_rate': 0.1, 'batch_size': 64, 'epochs': 50}\n",
      "Best K-fold Mean Accuracy: -1.00 (-100.00%)\n",
      "Best K-fold Mean Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "# We do the same grid search as in Question 2.\n",
    "best_config, best_acc, best_loss = grid_search(\n",
    "    x_train, y_train, \n",
    "    grid_search_configs, \n",
    "    k=3,\n",
    "    classification=False\n",
    ")\n",
    "\n",
    "print(\"The best configuration is:\")\n",
    "print(best_config)\n",
    "print(f\"Best K-fold Mean Accuracy: {best_acc:.2f} ({best_acc*100:.2f}%)\")\n",
    "print(f\"Best K-fold Mean Loss: {best_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9c648093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training best model on full training set...\n",
      "Configuration: {'layer_widths': [1, 16, 16, 16, 1], 'activation': 'relu', 'learning_rate': 0.1, 'batch_size': 64, 'epochs': 50}\n",
      "Epoch 0: Train Loss = 0.0133, Test Loss = 0.0133\n",
      "Epoch 10: Train Loss = 0.0001, Test Loss = 0.0001\n",
      "Epoch 20: Train Loss = 0.0000, Test Loss = 0.0000\n",
      "Epoch 30: Train Loss = 0.0000, Test Loss = 0.0000\n",
      "Epoch 40: Train Loss = 0.0000, Test Loss = 0.0000\n",
      "\n",
      "Final Test Loss: 0.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters saved to ../assets/1_reg_params.pkl\n"
     ]
    }
   ],
   "source": [
    "# We now train the best model on the full training set.\n",
    "best_config = {\n",
    "    'layer_widths': [1, 16, 16, 16, 1],\n",
    "    'activation': 'relu',\n",
    "    'learning_rate': 0.1,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 50\n",
    "}\n",
    "\n",
    "params, test_acc, test_loss, learning_curve = train_model(\n",
    "    x_train, y_train, x_test, y_test, best_config, classification=False\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(learning_curve['train_loss'], label='Training MSE Loss')\n",
    "plt.plot(learning_curve['test_loss'], label='Test MSE Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "save_params(params, filename=f'../assets/{k}_reg_params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef28ecbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x367a41c90>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the true function and the predicted function\n",
    "y_pred = forward(params, x_test, best_config['activation'])\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(x_test, y_test, label='True Function')\n",
    "plt.plot(x_test, y_pred, label='Predicted Function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d482da",
   "metadata": {},
   "source": [
    "(b) Try to fit $f_k$ for different values of $k$. How do you need to change the hyperparameters when increasing $k$? Discuss your findings. How far can you increase $k$?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4424d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing k = 5\n",
      "Total configurations to test: 12\n",
      "With k=3 folds, total training runs: 36\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[1/12] Testing configuration:\n",
      "Architecture: [1, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.5007, Val Loss = 0.4914\n",
      "Fold 2, Epoch 0: Train Loss = 0.5163, Val Loss = 0.5349\n",
      "Fold 3, Epoch 0: Train Loss = 0.4910, Val Loss = 0.4879\n",
      "Mean Validation Accuracy: 0.4452 (44.52%)\n",
      "Mean Validation Loss: 0.4452\n",
      "New best configuration!\n",
      "\n",
      "[2/12] Testing configuration:\n",
      "Architecture: [1, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 256\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.4907, Val Loss = 0.4797\n",
      "Fold 2, Epoch 0: Train Loss = 0.4865, Val Loss = 0.5026\n",
      "Fold 3, Epoch 0: Train Loss = 0.4874, Val Loss = 0.4869\n",
      "Mean Validation Accuracy: 0.4838 (48.38%)\n",
      "Mean Validation Loss: 0.4838\n",
      "\n",
      "[3/12] Testing configuration:\n",
      "Architecture: [1, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.4911, Val Loss = 0.4799\n",
      "Fold 2, Epoch 0: Train Loss = 0.4840, Val Loss = 0.4968\n",
      "Fold 3, Epoch 0: Train Loss = 0.4911, Val Loss = 0.4895\n",
      "Mean Validation Accuracy: 0.4860 (48.60%)\n",
      "Mean Validation Loss: 0.4860\n",
      "\n",
      "[4/12] Testing configuration:\n",
      "Architecture: [1, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 256\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.4925, Val Loss = 0.4818\n",
      "Fold 2, Epoch 0: Train Loss = 0.4888, Val Loss = 0.4990\n",
      "Fold 3, Epoch 0: Train Loss = 0.5367, Val Loss = 0.5253\n",
      "Mean Validation Accuracy: 0.4855 (48.55%)\n",
      "Mean Validation Loss: 0.4855\n",
      "\n",
      "[5/12] Testing configuration:\n",
      "Architecture: [1, 16, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.4830, Val Loss = 0.4741\n",
      "Fold 2, Epoch 0: Train Loss = 0.4798, Val Loss = 0.4929\n",
      "Fold 3, Epoch 0: Train Loss = 0.4857, Val Loss = 0.4837\n",
      "Mean Validation Accuracy: 0.1095 (10.95%)\n",
      "Mean Validation Loss: 0.1095\n",
      "New best configuration!\n",
      "\n",
      "[6/12] Testing configuration:\n",
      "Architecture: [1, 16, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 256\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.4863, Val Loss = 0.4764\n",
      "Fold 2, Epoch 0: Train Loss = 0.4799, Val Loss = 0.4954\n",
      "Fold 3, Epoch 0: Train Loss = 0.4677, Val Loss = 0.4688\n",
      "Mean Validation Accuracy: 0.3479 (34.79%)\n",
      "Mean Validation Loss: 0.3479\n",
      "\n",
      "[7/12] Testing configuration:\n",
      "Architecture: [1, 16, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.4893, Val Loss = 0.4785\n",
      "Fold 2, Epoch 0: Train Loss = 0.4796, Val Loss = 0.4960\n",
      "Fold 3, Epoch 0: Train Loss = 0.4821, Val Loss = 0.4845\n",
      "Mean Validation Accuracy: 0.3775 (37.75%)\n",
      "Mean Validation Loss: 0.3775\n",
      "\n",
      "[8/12] Testing configuration:\n",
      "Architecture: [1, 16, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 256\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.4977, Val Loss = 0.4879\n",
      "Fold 2, Epoch 0: Train Loss = 0.4843, Val Loss = 0.5009\n",
      "Fold 3, Epoch 0: Train Loss = 0.4996, Val Loss = 0.5037\n",
      "Mean Validation Accuracy: 0.4571 (45.71%)\n",
      "Mean Validation Loss: 0.4571\n",
      "\n",
      "[9/12] Testing configuration:\n",
      "Architecture: [1, 8, 8, 8, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.4845, Val Loss = 0.4746\n",
      "Fold 2, Epoch 0: Train Loss = 0.4837, Val Loss = 0.4968\n",
      "Fold 3, Epoch 0: Train Loss = 0.5014, Val Loss = 0.4978\n",
      "Mean Validation Accuracy: 0.2526 (25.26%)\n",
      "Mean Validation Loss: 0.2526\n",
      "\n",
      "[10/12] Testing configuration:\n",
      "Architecture: [1, 8, 8, 8, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 256\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.4879, Val Loss = 0.4769\n",
      "Fold 2, Epoch 0: Train Loss = 0.4835, Val Loss = 0.4956\n",
      "Fold 3, Epoch 0: Train Loss = 0.5007, Val Loss = 0.4966\n",
      "Mean Validation Accuracy: 0.3682 (36.82%)\n",
      "Mean Validation Loss: 0.3682\n",
      "\n",
      "[11/12] Testing configuration:\n",
      "Architecture: [1, 8, 8, 8, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.4895, Val Loss = 0.4783\n",
      "Fold 2, Epoch 0: Train Loss = 0.4842, Val Loss = 0.4955\n",
      "Fold 3, Epoch 0: Train Loss = 0.5008, Val Loss = 0.4964\n",
      "Mean Validation Accuracy: 0.3516 (35.16%)\n",
      "Mean Validation Loss: 0.3516\n",
      "\n",
      "[12/12] Testing configuration:\n",
      "Architecture: [1, 8, 8, 8, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 256\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.5005, Val Loss = 0.4905\n",
      "Fold 2, Epoch 0: Train Loss = 0.4855, Val Loss = 0.4962\n",
      "Fold 3, Epoch 0: Train Loss = 0.5119, Val Loss = 0.5062\n",
      "Mean Validation Accuracy: 0.4857 (48.57%)\n",
      "Mean Validation Loss: 0.4857\n",
      "\n",
      "================================================================================\n",
      "Grid Search Complete!\n",
      "Best Configuration:\n",
      "Architecture: [1, 16, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 50\n",
      "Best Mean Validation Accuracy: -1.0000 (-100.00%)\n",
      "================================================================================\n",
      "Analyzing k = 10\n",
      "Total configurations to test: 12\n",
      "With k=3 folds, total training runs: 36\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[1/12] Testing configuration:\n",
      "Architecture: [1, 16, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 50\n",
      "Fold 1, Epoch 0: Train Loss = 0.4935, Val Loss = 0.4927\n",
      "Fold 2, Epoch 0: Train Loss = 0.4999, Val Loss = 0.4976\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# We test low, medium, and high frequencies\u001b[39;00m\n\u001b[1;32m     42\u001b[0m k_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m100\u001b[39m]\n\u001b[0;32m---> 43\u001b[0m k_heuristics \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_k_impact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(k_heuristics)\n",
      "Cell \u001b[0;32mIn[46], line 27\u001b[0m, in \u001b[0;36manalyze_k_impact\u001b[0;34m(k_values)\u001b[0m\n\u001b[1;32m     21\u001b[0m     x_train, y_train, x_test, y_test \u001b[38;5;241m=\u001b[39m get_splits(\n\u001b[1;32m     22\u001b[0m         x_shuffled, y_shuffled, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, classification\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Run Grid Search\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# We use k=3 folds to save time, but get reliable results\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     best_cfg, best_acc, best_loss \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrid_search_configs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     heuristics[k] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m: best_cfg,\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: best_loss\n\u001b[1;32m     37\u001b[0m     }\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m heuristics\n",
      "Cell \u001b[0;32mIn[38], line 33\u001b[0m, in \u001b[0;36mgrid_search\u001b[0;34m(x_train, y_train, configs, k, classification)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch Size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m mean_val_acc, mean_val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_kfold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_widths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassification\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# result\u001b[39;00m\n\u001b[1;32m     38\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer_widths\u001b[39m\u001b[38;5;124m'\u001b[39m: layer_widths,\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m: activation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: epochs\n\u001b[1;32m     44\u001b[0m }\n",
      "Cell \u001b[0;32mIn[36], line 23\u001b[0m, in \u001b[0;36mtrain_model_kfold\u001b[0;34m(x_train, y_train, layer_widths, activation, lr, batch_size, epochs, k, classification)\u001b[0m\n\u001b[1;32m     20\u001b[0m batches \u001b[38;5;241m=\u001b[39m get_batches(x_train_fold, y_train_fold, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[0;32m---> 23\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassification\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m train_acc, train_loss \u001b[38;5;241m=\u001b[39m evaluate_model(params, x_train_fold, y_train_fold, activation, classification\u001b[38;5;241m=\u001b[39mclassification)\n\u001b[1;32m     26\u001b[0m val_acc, val_loss \u001b[38;5;241m=\u001b[39m evaluate_model(params, x_val_fold, y_val_fold, activation, classification\u001b[38;5;241m=\u001b[39mclassification)\n",
      "Cell \u001b[0;32mIn[34], line 7\u001b[0m, in \u001b[0;36mupdate\u001b[0;34m(params, x, y, activation, lr, classification)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mUpdate function for the network parameters (basic gradient descent).\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m class_loss \u001b[38;5;28;01mif\u001b[39;00m classification \u001b[38;5;28;01melse\u001b[39;00m mse_loss\n\u001b[0;32m----> 7\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m new_params \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m p, g: p \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m g, params, grads)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_params\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:399\u001b[0m, in \u001b[0;36mgrad.<locals>.grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fun, docstr\u001b[38;5;241m=\u001b[39mdocstr, argnums\u001b[38;5;241m=\u001b[39margnums)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgrad_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 399\u001b[0m   _, g \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_and_grad_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:470\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m   _check_input_dtype_grad(holomorphic, allow_int, leaf)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 470\u001b[0m   ans, vjp_py \u001b[38;5;241m=\u001b[39m \u001b[43m_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_partial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdyn_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    472\u001b[0m   ans, vjp_py, aux \u001b[38;5;241m=\u001b[39m _vjp(\n\u001b[1;32m    473\u001b[0m       f_partial, \u001b[38;5;241m*\u001b[39mdyn_args, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:2015\u001b[0m, in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, *primals)\u001b[0m\n\u001b[1;32m   2013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[1;32m   2014\u001b[0m   flat_fun, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun_nokwargs(fun, in_tree)\n\u001b[0;32m-> 2015\u001b[0m   out_primals, vjp \u001b[38;5;241m=\u001b[39m \u001b[43mad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2016\u001b[0m   out_tree \u001b[38;5;241m=\u001b[39m out_tree()\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:260\u001b[0m, in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvjp\u001b[39m(traceable: lu\u001b[38;5;241m.\u001b[39mWrappedFun, primals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    259\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 260\u001b[0m     out_primals, pvals, jaxpr, consts \u001b[38;5;241m=\u001b[39m \u001b[43mlinearize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraceable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m     out_primals, pvals, jaxpr, consts, aux \u001b[38;5;241m=\u001b[39m linearize(traceable, \u001b[38;5;241m*\u001b[39mprimals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:245\u001b[0m, in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m _, in_tree \u001b[38;5;241m=\u001b[39m tree_flatten(((primals, primals), {}))\n\u001b[1;32m    244\u001b[0m jvpfun_flat, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun(jvpfun, in_tree)\n\u001b[0;32m--> 245\u001b[0m jaxpr, out_pvals, consts \u001b[38;5;241m=\u001b[39m \u001b[43mpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_to_jaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjvpfun_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m out_primals_pvals, out_tangents_pvals \u001b[38;5;241m=\u001b[39m tree_unflatten(out_tree(), out_pvals)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m out_primal_pval\u001b[38;5;241m.\u001b[39mis_known() \u001b[38;5;28;01mfor\u001b[39;00m out_primal_pval \u001b[38;5;129;01min\u001b[39;00m out_primals_pvals):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/profiler.py:334\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    333\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:576\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_nounits\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    574\u001b[0m fun \u001b[38;5;241m=\u001b[39m trace_to_subjaxpr_nounits(fun, trace, instantiate, fun\u001b[38;5;241m.\u001b[39mdebug_info)\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m--> 576\u001b[0m   jaxpr, (out_pvals, consts, env) \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m trace, fun\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/linear_util.py:210\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    209\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the transformed function\"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_transformed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:590\u001b[0m, in \u001b[0;36mtrace_to_subjaxpr_nounits\u001b[0;34m(f, trace, instantiate, debug_info, in_pvals)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation2\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrace_to_subjaxpr_nounits\u001b[39m(\n\u001b[1;32m    584\u001b[0m     f: Callable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    587\u001b[0m     debug_info: core\u001b[38;5;241m.\u001b[39mDebugInfo,\n\u001b[1;32m    588\u001b[0m     in_pvals: Sequence[PartialVal]):\n\u001b[1;32m    589\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(pv, PartialVal) \u001b[38;5;28;01mfor\u001b[39;00m pv \u001b[38;5;129;01min\u001b[39;00m in_pvals), in_pvals\n\u001b[0;32m--> 590\u001b[0m   out_tracers, jaxpr, out_consts, env \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_to_subjaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m      \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstantiate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m   out_pvals \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mpval \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m out_tracers]\n\u001b[1;32m    593\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m out_tracers\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:623\u001b[0m, in \u001b[0;36m_trace_to_subjaxpr_nounits\u001b[0;34m(f, trace, instantiate, in_pvals, debug_info)\u001b[0m\n\u001b[1;32m    621\u001b[0m in_args \u001b[38;5;241m=\u001b[39m merge_lists(in_knowns, in_tracers, in_consts)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m--> 623\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ans, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)), (\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected return type when tracing function to jaxpr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mans\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, core\u001b[38;5;241m.\u001b[39mTracer) \u001b[38;5;129;01mor\u001b[39;00m core\u001b[38;5;241m.\u001b[39mvalid_jaxtype(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m ans), (\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected return type when tracing function to jaxpr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mans\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api_util.py:73\u001b[0m, in \u001b[0;36mflatten_fun\u001b[0;34m(f, store, in_tree, *args_flat)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_with_aux2\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflatten_fun\u001b[39m(f: Callable, store: lu\u001b[38;5;241m.\u001b[39mStore,\n\u001b[1;32m     71\u001b[0m                 in_tree: PyTreeDef, \u001b[38;5;241m*\u001b[39margs_flat):\n\u001b[1;32m     72\u001b[0m   py_args, py_kwargs \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, args_flat)\n\u001b[0;32m---> 73\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m   ans, out_tree \u001b[38;5;241m=\u001b[39m tree_flatten(ans)\n\u001b[1;32m     75\u001b[0m   store\u001b[38;5;241m.\u001b[39mstore(out_tree)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:80\u001b[0m, in \u001b[0;36mjvpfun\u001b[0;34m(f, instantiate, transform_stack, primals, tangents)\u001b[0m\n\u001b[1;32m     77\u001b[0m ctx \u001b[38;5;241m=\u001b[39m (source_info_util\u001b[38;5;241m.\u001b[39mtransform_name_stack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjvp\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m transform_stack\n\u001b[1;32m     78\u001b[0m        \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext())\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[0;32m---> 80\u001b[0m   out_primals, out_tangents \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtangents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(instantiate) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     82\u001b[0m   instantiate \u001b[38;5;241m=\u001b[39m [instantiate] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(out_tangents)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:120\u001b[0m, in \u001b[0;36mjvp_subtrace\u001b[0;34m(f, tag, primals, tangents)\u001b[0m\n\u001b[1;32m    117\u001b[0m   in_tracers \u001b[38;5;241m=\u001b[39m [maybe_jvp_tracer(trace, x, t)\n\u001b[1;32m    118\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m x, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(primals, tangents)]\n\u001b[1;32m    119\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m--> 120\u001b[0m     ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_tracers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m   out \u001b[38;5;241m=\u001b[39m unzip2(\u001b[38;5;28mmap\u001b[39m(trace\u001b[38;5;241m.\u001b[39mto_primal_tangent_pair, ans))\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api_util.py:90\u001b[0m, in \u001b[0;36mflatten_fun_nokwargs\u001b[0;34m(f, store, in_tree, *args_flat)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_with_aux2\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflatten_fun_nokwargs\u001b[39m(f: Callable, store: lu\u001b[38;5;241m.\u001b[39mStore,\n\u001b[1;32m     88\u001b[0m                          in_tree: PyTreeDef, \u001b[38;5;241m*\u001b[39margs_flat):\n\u001b[1;32m     89\u001b[0m   py_args \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, args_flat)\n\u001b[0;32m---> 90\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m   ans, out_tree \u001b[38;5;241m=\u001b[39m tree_flatten(ans)\n\u001b[1;32m     92\u001b[0m   store\u001b[38;5;241m.\u001b[39mstore(out_tree)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api_util.py:284\u001b[0m, in \u001b[0;36m_argnums_partial\u001b[0;34m(_fun, _dyn_argnums, _fixed_args, *dyn_args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m args \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mnext\u001b[39m(fixed_args_)\u001b[38;5;241m.\u001b[39mval \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m sentinel \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(fixed_args_, sentinel) \u001b[38;5;129;01mis\u001b[39;00m sentinel\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/linear_util.py:370\u001b[0m, in \u001b[0;36m_get_result_paths_thunk\u001b[0;34m(_fun, _store, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;129m@transformation_with_aux2\u001b[39m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_result_paths_thunk\u001b[39m(_fun: Callable, _store: Store, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 370\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m   result_paths \u001b[38;5;241m=\u001b[39m [_clean_keystr_arg_names(path) \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m generate_key_paths(ans)]\n\u001b[1;32m    372\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _store:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# In some instances a lu.WrappedFun is called multiple times, e.g.,\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# the bwd function in a custom_vjp\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[33], line 8\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(params, x, y, activation)\u001b[0m\n\u001b[1;32m      6\u001b[0m batched_forward \u001b[38;5;241m=\u001b[39m vmap(forward, in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m      7\u001b[0m preds \u001b[38;5;241m=\u001b[39m batched_forward(params, x, activation)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mmean(\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:1060\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 1060\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:579\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    577\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 579\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/numpy/ufuncs.py:2644\u001b[0m, in \u001b[0;36mpower\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m   2642\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   2643\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2644\u001b[0m     x1, \u001b[38;5;241m=\u001b[39m \u001b[43mpromote_dtypes_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39minteger_pow(x1, x2)\n\u001b[1;32m   2647\u001b[0m \u001b[38;5;66;03m# Handle cases #2 and #3 under a jit:\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/numpy/util.py:109\u001b[0m, in \u001b[0;36mpromote_dtypes_numeric\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    107\u001b[0m to_dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mcanonicalize_dtype(to_dtype)\n\u001b[1;32m    108\u001b[0m to_dtype_numeric \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mto_numeric_dtype(to_dtype)\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [lax\u001b[38;5;241m.\u001b[39m_convert_element_type(x, to_dtype_numeric, weak_type)\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/numpy/util.py:109\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    107\u001b[0m to_dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mcanonicalize_dtype(to_dtype)\n\u001b[1;32m    108\u001b[0m to_dtype_numeric \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mto_numeric_dtype(to_dtype)\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_element_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_dtype_numeric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweak_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/lax/lax.py:1355\u001b[0m, in \u001b[0;36m_convert_element_type\u001b[0;34m(operand, new_dtype, weak_type, sharding, warn_on_complex_to_real_cast)\u001b[0m\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_convert_element_type\u001b[39m(\n\u001b[1;32m   1350\u001b[0m     operand: ArrayLike,\n\u001b[1;32m   1351\u001b[0m     new_dtype: DTypeLike \u001b[38;5;241m|\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mExtendedDType \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1352\u001b[0m     weak_type: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1353\u001b[0m     sharding: Sharding \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1354\u001b[0m     warn_on_complex_to_real_cast: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m-> 1355\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moperand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m__jax_array__\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1356\u001b[0m     operand \u001b[38;5;241m=\u001b[39m operand\u001b[38;5;241m.\u001b[39m__jax_array__()\n\u001b[1;32m   1358\u001b[0m   \u001b[38;5;66;03m# Don't canonicalize old_dtype because x64 context might cause\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m   \u001b[38;5;66;03m# un-canonicalized operands to be passed in.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def analyze_k_impact(k_values):\n",
    "    \"\"\"\n",
    "    Runs grid search for different values of k to determine optimal hyperparameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Store best params for each k\n",
    "    heuristics = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        print(f\"Analyzing k = {k}\")\n",
    "        \n",
    "        # Generate Data for this specific k\n",
    "        n_samples = 20000\n",
    "        x = jnp.linspace(-1, 1, n_samples).reshape(-1, 1)\n",
    "        y = jnp.sin(k * jnp.pi * x)\n",
    "        \n",
    "        key = random.PRNGKey(k)\n",
    "        perm = random.permutation(key, n_samples)\n",
    "        x_shuffled, y_shuffled = x[perm], y[perm]\n",
    "        \n",
    "        x_train, y_train, x_test, y_test = get_splits(\n",
    "            x_shuffled, y_shuffled, train=0.8, classification=False\n",
    "        )\n",
    "        \n",
    "        # Run Grid Search\n",
    "        # We use k=3 folds to save time, but get reliable results\n",
    "        best_cfg, best_acc, best_loss = grid_search(\n",
    "            x_train, y_train, \n",
    "            grid_search_configs, \n",
    "            k=3, \n",
    "            classification=False\n",
    "        )\n",
    "        \n",
    "        heuristics[k] = {\n",
    "            'config': best_cfg,\n",
    "            'loss': best_loss\n",
    "        }\n",
    "\n",
    "    return heuristics\n",
    "\n",
    "# We test low, medium, and high frequencies\n",
    "k_list = [5, 10, 20, 100]\n",
    "k_heuristics = analyze_k_impact(k_list)\n",
    "print(k_heuristics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9a0238",
   "metadata": {},
   "source": [
    "The problem is hinting at the spectral bias of neural networks: neural network fit lower frequencies better than higher frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddeb51f",
   "metadata": {},
   "source": [
    "(c) Finally, propose an approach to approximate $f_k$ with higher values of $k$ and test it. Examples could include different function spaces than neural networks, architectural tweaks, activation changes, initialization strategies, or training approaches. Motivate your choice and discuss your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2f0f00e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on f_20 with Fourier Features...\n",
      "\n",
      "Training best model on full training set...\n",
      "Configuration: {'layer_widths': [256, 64, 64, 1], 'activation': 'relu', 'learning_rate': 0.01, 'batch_size': 64, 'epochs': 100}\n",
      "Epoch 0: Train Loss = 0.0411, Test Loss = 0.4691\n",
      "Epoch 10: Train Loss = 0.0012, Test Loss = 0.4201\n",
      "Epoch 20: Train Loss = 0.0006, Test Loss = 0.4174\n",
      "Epoch 30: Train Loss = 0.0004, Test Loss = 0.4165\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 42\u001b[0m\n\u001b[1;32m     33\u001b[0m best_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer_widths\u001b[39m\u001b[38;5;124m'\u001b[39m: [input_dim, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     39\u001b[0m }\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining on f_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk_high\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with Fourier Features...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 42\u001b[0m params, test_acc, test_loss, learning_curve \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     44\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m forward(params, x_plot_mapped, best_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     48\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "Cell \u001b[0;32mIn[63], line 78\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(x_train, y_train, x_test, y_test, best_config, classification)\u001b[0m\n\u001b[1;32m     75\u001b[0m batches \u001b[38;5;241m=\u001b[39m get_batches(x_train, y_train, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[0;32m---> 78\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassification\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Evaluate periodically\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "Cell \u001b[0;32mIn[61], line 7\u001b[0m, in \u001b[0;36mupdate\u001b[0;34m(params, x, y, activation, lr, classification)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mUpdate function for the network parameters (basic gradient descent).\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m class_loss \u001b[38;5;28;01mif\u001b[39;00m classification \u001b[38;5;28;01melse\u001b[39;00m mse_loss\n\u001b[0;32m----> 7\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m new_params \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m p, g: p \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m g, params, grads)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_params\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:399\u001b[0m, in \u001b[0;36mgrad.<locals>.grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fun, docstr\u001b[38;5;241m=\u001b[39mdocstr, argnums\u001b[38;5;241m=\u001b[39margnums)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgrad_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 399\u001b[0m   _, g \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_and_grad_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:470\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m   _check_input_dtype_grad(holomorphic, allow_int, leaf)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 470\u001b[0m   ans, vjp_py \u001b[38;5;241m=\u001b[39m \u001b[43m_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_partial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdyn_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    472\u001b[0m   ans, vjp_py, aux \u001b[38;5;241m=\u001b[39m _vjp(\n\u001b[1;32m    473\u001b[0m       f_partial, \u001b[38;5;241m*\u001b[39mdyn_args, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:2015\u001b[0m, in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, *primals)\u001b[0m\n\u001b[1;32m   2013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[1;32m   2014\u001b[0m   flat_fun, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun_nokwargs(fun, in_tree)\n\u001b[0;32m-> 2015\u001b[0m   out_primals, vjp \u001b[38;5;241m=\u001b[39m \u001b[43mad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2016\u001b[0m   out_tree \u001b[38;5;241m=\u001b[39m out_tree()\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:260\u001b[0m, in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvjp\u001b[39m(traceable: lu\u001b[38;5;241m.\u001b[39mWrappedFun, primals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    259\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 260\u001b[0m     out_primals, pvals, jaxpr, consts \u001b[38;5;241m=\u001b[39m \u001b[43mlinearize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraceable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m     out_primals, pvals, jaxpr, consts, aux \u001b[38;5;241m=\u001b[39m linearize(traceable, \u001b[38;5;241m*\u001b[39mprimals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:245\u001b[0m, in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m _, in_tree \u001b[38;5;241m=\u001b[39m tree_flatten(((primals, primals), {}))\n\u001b[1;32m    244\u001b[0m jvpfun_flat, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun(jvpfun, in_tree)\n\u001b[0;32m--> 245\u001b[0m jaxpr, out_pvals, consts \u001b[38;5;241m=\u001b[39m \u001b[43mpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_to_jaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjvpfun_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m out_primals_pvals, out_tangents_pvals \u001b[38;5;241m=\u001b[39m tree_unflatten(out_tree(), out_pvals)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m out_primal_pval\u001b[38;5;241m.\u001b[39mis_known() \u001b[38;5;28;01mfor\u001b[39;00m out_primal_pval \u001b[38;5;129;01min\u001b[39;00m out_primals_pvals):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/profiler.py:334\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    333\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:576\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_nounits\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    574\u001b[0m fun \u001b[38;5;241m=\u001b[39m trace_to_subjaxpr_nounits(fun, trace, instantiate, fun\u001b[38;5;241m.\u001b[39mdebug_info)\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m--> 576\u001b[0m   jaxpr, (out_pvals, consts, env) \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m trace, fun\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/linear_util.py:210\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    209\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the transformed function\"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_transformed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:590\u001b[0m, in \u001b[0;36mtrace_to_subjaxpr_nounits\u001b[0;34m(f, trace, instantiate, debug_info, in_pvals)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation2\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrace_to_subjaxpr_nounits\u001b[39m(\n\u001b[1;32m    584\u001b[0m     f: Callable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    587\u001b[0m     debug_info: core\u001b[38;5;241m.\u001b[39mDebugInfo,\n\u001b[1;32m    588\u001b[0m     in_pvals: Sequence[PartialVal]):\n\u001b[1;32m    589\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(pv, PartialVal) \u001b[38;5;28;01mfor\u001b[39;00m pv \u001b[38;5;129;01min\u001b[39;00m in_pvals), in_pvals\n\u001b[0;32m--> 590\u001b[0m   out_tracers, jaxpr, out_consts, env \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_to_subjaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m      \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstantiate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m   out_pvals \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mpval \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m out_tracers]\n\u001b[1;32m    593\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m out_tracers\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:623\u001b[0m, in \u001b[0;36m_trace_to_subjaxpr_nounits\u001b[0;34m(f, trace, instantiate, in_pvals, debug_info)\u001b[0m\n\u001b[1;32m    621\u001b[0m in_args \u001b[38;5;241m=\u001b[39m merge_lists(in_knowns, in_tracers, in_consts)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m--> 623\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ans, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)), (\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected return type when tracing function to jaxpr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mans\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, core\u001b[38;5;241m.\u001b[39mTracer) \u001b[38;5;129;01mor\u001b[39;00m core\u001b[38;5;241m.\u001b[39mvalid_jaxtype(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m ans), (\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected return type when tracing function to jaxpr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mans\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api_util.py:73\u001b[0m, in \u001b[0;36mflatten_fun\u001b[0;34m(f, store, in_tree, *args_flat)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_with_aux2\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflatten_fun\u001b[39m(f: Callable, store: lu\u001b[38;5;241m.\u001b[39mStore,\n\u001b[1;32m     71\u001b[0m                 in_tree: PyTreeDef, \u001b[38;5;241m*\u001b[39margs_flat):\n\u001b[1;32m     72\u001b[0m   py_args, py_kwargs \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, args_flat)\n\u001b[0;32m---> 73\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m   ans, out_tree \u001b[38;5;241m=\u001b[39m tree_flatten(ans)\n\u001b[1;32m     75\u001b[0m   store\u001b[38;5;241m.\u001b[39mstore(out_tree)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:80\u001b[0m, in \u001b[0;36mjvpfun\u001b[0;34m(f, instantiate, transform_stack, primals, tangents)\u001b[0m\n\u001b[1;32m     77\u001b[0m ctx \u001b[38;5;241m=\u001b[39m (source_info_util\u001b[38;5;241m.\u001b[39mtransform_name_stack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjvp\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m transform_stack\n\u001b[1;32m     78\u001b[0m        \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext())\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[0;32m---> 80\u001b[0m   out_primals, out_tangents \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtangents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(instantiate) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     82\u001b[0m   instantiate \u001b[38;5;241m=\u001b[39m [instantiate] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(out_tangents)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:120\u001b[0m, in \u001b[0;36mjvp_subtrace\u001b[0;34m(f, tag, primals, tangents)\u001b[0m\n\u001b[1;32m    117\u001b[0m   in_tracers \u001b[38;5;241m=\u001b[39m [maybe_jvp_tracer(trace, x, t)\n\u001b[1;32m    118\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m x, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(primals, tangents)]\n\u001b[1;32m    119\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m--> 120\u001b[0m     ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_tracers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m   out \u001b[38;5;241m=\u001b[39m unzip2(\u001b[38;5;28mmap\u001b[39m(trace\u001b[38;5;241m.\u001b[39mto_primal_tangent_pair, ans))\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api_util.py:90\u001b[0m, in \u001b[0;36mflatten_fun_nokwargs\u001b[0;34m(f, store, in_tree, *args_flat)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_with_aux2\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflatten_fun_nokwargs\u001b[39m(f: Callable, store: lu\u001b[38;5;241m.\u001b[39mStore,\n\u001b[1;32m     88\u001b[0m                          in_tree: PyTreeDef, \u001b[38;5;241m*\u001b[39margs_flat):\n\u001b[1;32m     89\u001b[0m   py_args \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, args_flat)\n\u001b[0;32m---> 90\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m   ans, out_tree \u001b[38;5;241m=\u001b[39m tree_flatten(ans)\n\u001b[1;32m     92\u001b[0m   store\u001b[38;5;241m.\u001b[39mstore(out_tree)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api_util.py:284\u001b[0m, in \u001b[0;36m_argnums_partial\u001b[0;34m(_fun, _dyn_argnums, _fixed_args, *dyn_args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m args \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mnext\u001b[39m(fixed_args_)\u001b[38;5;241m.\u001b[39mval \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m sentinel \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(fixed_args_, sentinel) \u001b[38;5;129;01mis\u001b[39;00m sentinel\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/linear_util.py:370\u001b[0m, in \u001b[0;36m_get_result_paths_thunk\u001b[0;34m(_fun, _store, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;129m@transformation_with_aux2\u001b[39m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_result_paths_thunk\u001b[39m(_fun: Callable, _store: Store, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 370\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m   result_paths \u001b[38;5;241m=\u001b[39m [_clean_keystr_arg_names(path) \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m generate_key_paths(ans)]\n\u001b[1;32m    372\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _store:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# In some instances a lu.WrappedFun is called multiple times, e.g.,\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# the bwd function in a custom_vjp\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[60], line 8\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(params, x, y, activation)\u001b[0m\n\u001b[1;32m      6\u001b[0m batched_forward \u001b[38;5;241m=\u001b[39m vmap(forward, in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m      7\u001b[0m preds \u001b[38;5;241m=\u001b[39m batched_forward(params, x, activation)\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/numpy/reductions.py:867\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;129m@export\u001b[39m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmean\u001b[39m(a: ArrayLike, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, dtype: DTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    805\u001b[0m          out: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, keepdims: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    806\u001b[0m          where: ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[1;32m    807\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Return the mean of array elements along a given axis.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m \n\u001b[1;32m    809\u001b[0m \u001b[38;5;124;03m  JAX implementation of :func:`numpy.mean`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;124;03m           [6. ]], dtype=float32)\u001b[39;00m\n\u001b[1;32m    866\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_ensure_optional_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m               \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupcast_f16_for_computation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/pjit.py:341\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mno_tracing\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[1;32m    337\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mre-tracing function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjit_info\u001b[38;5;241m.\u001b[39mfun_sourceinfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`jit`, but \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_tracing\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    340\u001b[0m (outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked, executable,\n\u001b[0;32m--> 341\u001b[0m  pgle_profiler) \u001b[38;5;241m=\u001b[39m \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m maybe_fastpath_data \u001b[38;5;241m=\u001b[39m _get_fastpath_data(\n\u001b[1;32m    344\u001b[0m     executable, out_tree, args_flat, out_flat, attrs_tracked, jaxpr\u001b[38;5;241m.\u001b[39meffects,\n\u001b[1;32m    345\u001b[0m     jaxpr\u001b[38;5;241m.\u001b[39mconsts, jit_info\u001b[38;5;241m.\u001b[39mabstracted_axes,\n\u001b[1;32m    346\u001b[0m     pgle_profiler)\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs, maybe_fastpath_data, _need_to_rebuild_with_fdo(pgle_profiler)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/pjit.py:197\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[0;34m(fun, jit_info, *args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m   out_flat, compiled, profiler \u001b[38;5;241m=\u001b[39m _pjit_call_impl_python(\u001b[38;5;241m*\u001b[39margs_flat, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mp\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m   compiled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    199\u001b[0m   profiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:502\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    501\u001b[0m   args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_canonicalization \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(canonicalize_value, args)\n\u001b[0;32m--> 502\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:520\u001b[0m, in \u001b[0;36mPrimitive._true_bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    518\u001b[0m trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(eval_trace)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 520\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m   trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(prev_trace)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:525\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 525\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:440\u001b[0m, in \u001b[0;36mJVPTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_trace):\n\u001b[0;32m--> 440\u001b[0m   primal_out, tangent_out \u001b[38;5;241m=\u001b[39m \u001b[43mjvp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprimals_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtangents_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m primitive\u001b[38;5;241m.\u001b[39mmultiple_results:\n\u001b[1;32m    443\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [maybe_jvp_tracer(\u001b[38;5;28mself\u001b[39m, x, t) \u001b[38;5;28;01mfor\u001b[39;00m x, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(primal_out, tangent_out)]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/pjit.py:2050\u001b[0m, in \u001b[0;36m_pjit_jvp\u001b[0;34m(primals_in, tangents_in, jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, name, keep_unused, inline, compiler_options_kvs)\u001b[0m\n\u001b[1;32m   2048\u001b[0m _filter_zeros_in \u001b[38;5;241m=\u001b[39m partial(_filter_zeros, is_nz_tangents_in)\n\u001b[1;32m   2049\u001b[0m _filter_zeros_out \u001b[38;5;241m=\u001b[39m partial(_filter_zeros, is_nz_tangents_out)\n\u001b[0;32m-> 2050\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2051\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_filter_zeros_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtangents_in\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjaxpr_jvp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_filter_zeros_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_filter_zeros_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_layouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_layouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_filter_zeros_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_layouts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_layouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_filter_zeros_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_filter_zeros_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2064\u001b[0m primals_out, tangents_out \u001b[38;5;241m=\u001b[39m split_list(outputs, [\u001b[38;5;28mlen\u001b[39m(jaxpr\u001b[38;5;241m.\u001b[39mjaxpr\u001b[38;5;241m.\u001b[39moutvars)])\n\u001b[1;32m   2065\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(primals_out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(jaxpr\u001b[38;5;241m.\u001b[39mjaxpr\u001b[38;5;241m.\u001b[39moutvars)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:502\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    501\u001b[0m   args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_canonicalization \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(canonicalize_value, args)\n\u001b[0;32m--> 502\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:520\u001b[0m, in \u001b[0;36mPrimitive._true_bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    518\u001b[0m trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(eval_trace)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 520\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m   trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(prev_trace)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:525\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 525\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:209\u001b[0m, in \u001b[0;36mJaxprTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m primitive \u001b[38;5;129;01min\u001b[39;00m custom_partial_eval_rules:\n\u001b[1;32m    208\u001b[0m   tracers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_jaxpr_tracer, tracers)\n\u001b[0;32m--> 209\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcustom_partial_eval_rules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprimitive\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_process_primitive(primitive, tracers, params)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/pjit.py:2202\u001b[0m, in \u001b[0;36m_pjit_partial_eval\u001b[0;34m(trace, jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, name, keep_unused, inline, compiler_options_kvs, *in_tracers)\u001b[0m\n\u001b[1;32m   2200\u001b[0m \u001b[38;5;66;03m# Bind known things to pjit_p.\u001b[39;00m\n\u001b[1;32m   2201\u001b[0m known_inputs \u001b[38;5;241m=\u001b[39m [pv\u001b[38;5;241m.\u001b[39mget_known() \u001b[38;5;28;01mfor\u001b[39;00m pv \u001b[38;5;129;01min\u001b[39;00m in_pvals \u001b[38;5;28;01mif\u001b[39;00m pv\u001b[38;5;241m.\u001b[39mis_known()]\n\u001b[0;32m-> 2202\u001b[0m all_known_outs \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mknown_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mknown_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2203\u001b[0m \u001b[38;5;66;03m# Add back in the output fwds.\u001b[39;00m\n\u001b[1;32m   2204\u001b[0m all_known_outs \u001b[38;5;241m=\u001b[39m subs_list(out_fwd, all_known_outs, all_known_outs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:502\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    501\u001b[0m   args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_canonicalization \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(canonicalize_value, args)\n\u001b[0;32m--> 502\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:520\u001b[0m, in \u001b[0;36mPrimitive._true_bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    518\u001b[0m trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(eval_trace)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 520\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m   trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(prev_trace)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:525\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 525\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:1024\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, args, params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m primitive\u001b[38;5;241m.\u001b[39mbind_with_trace(arg\u001b[38;5;241m.\u001b[39m_trace, args, params)\n\u001b[1;32m   1023\u001b[0m check_eval_args(args)\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/pjit.py:1724\u001b[0m, in \u001b[0;36m_pjit_call_impl\u001b[0;34m(jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, name, keep_unused, inline, compiler_options_kvs, *args)\u001b[0m\n\u001b[1;32m   1715\u001b[0m donated_argnums \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(i \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(donated_invars) \u001b[38;5;28;01mif\u001b[39;00m d)\n\u001b[1;32m   1716\u001b[0m cache_key \u001b[38;5;241m=\u001b[39m pxla\u001b[38;5;241m.\u001b[39mJitGlobalCppCacheKeys(\n\u001b[1;32m   1717\u001b[0m     donate_argnums\u001b[38;5;241m=\u001b[39mdonated_argnums, donate_argnames\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1718\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, backend\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1722\u001b[0m     out_layouts_treedef\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out_layouts_leaves\u001b[38;5;241m=\u001b[39mout_layouts,\n\u001b[1;32m   1723\u001b[0m     use_resource_env\u001b[38;5;241m=\u001b[39mresource_env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1724\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mxc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_xla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpjit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcall_impl_cache_miss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_registry\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpxla\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcc_shard_arg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_get_cpp_global_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcache_key\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains_explicit_attributes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# The Fourier Feature Mapping function\n",
    "def input_mapping(x, B):\n",
    "    \"\"\"\n",
    "    Maps input x (shape: [N, 1]) to Fourier features.\n",
    "    \"\"\"\n",
    "    if B is None:\n",
    "        return x\n",
    "    xp = 2 * jnp.pi * (x @ B)\n",
    "    \n",
    "    return jnp.concatenate([jnp.cos(xp), jnp.sin(xp)], axis=-1)\n",
    "\n",
    "k_high = 20\n",
    "n_samples = 5000\n",
    "x = jnp.linspace(-1, 1, n_samples).reshape(-1, 1)\n",
    "y = jnp.sin(k_high * jnp.pi * x)\n",
    "\n",
    "# mapping_size is half the width of the input layer\n",
    "mapping_size = 128 \n",
    "scale = 10.0 # Sigma: Controls the frequency bandwidth\n",
    "key = random.PRNGKey(1337)\n",
    "B = random.normal(key, (1, mapping_size)) * scale\n",
    "\n",
    "x_mapped = input_mapping(x, B)\n",
    "\n",
    "x_train, y_train, x_test, y_test = get_splits(x_mapped, y, classification=False)\n",
    "\n",
    "sort_idx = jnp.argsort(x_test[:, 0])\n",
    "x_plot = jnp.linspace(-1, 1, 1000).reshape(-1, 1)\n",
    "x_plot_mapped = input_mapping(x_plot, B)\n",
    "\n",
    "input_dim = mapping_size * 2\n",
    "\n",
    "best_config = {\n",
    "    'layer_widths': [input_dim, 64, 64, 1],\n",
    "    'activation': 'relu',\n",
    "    'learning_rate': 0.01,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 100\n",
    "}\n",
    "\n",
    "print(f\"Training on f_{k_high} with Fourier Features...\")\n",
    "params, test_acc, test_loss, learning_curve = train_model(\n",
    "    x_train, y_train, x_test, y_test, best_config, classification=False\n",
    ")\n",
    "\n",
    "y_pred = forward(params, x_plot_mapped, best_config['activation'])\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(x, y, color='red', alpha=0.3, label='True Function (High k)')\n",
    "plt.plot(x_plot, y_pred, color='blue', label='Fourier MLP Prediction')\n",
    "plt.title(f\"Approximation of sin({k_high}$\\pi$x) using Fourier Features ($\\sigma$={scale})\")\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(learning_curve['train_loss'], label='Train Loss')\n",
    "plt.plot(learning_curve['test_loss'], label='Test Loss')\n",
    "plt.yscale('log')\n",
    "plt.title('Loss Curve (Log Scale)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
