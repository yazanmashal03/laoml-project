{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4da8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import JAX to use\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import grad, vmap, random\n",
    "from sklearn.datasets import fetch_openml\n",
    "import pickle\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7223a1fc",
   "metadata": {},
   "source": [
    "1. Implement a dense feedforward neural network from scratch.\n",
    "\n",
    "   The implementation must be flexible with respect to:\n",
    "   - The input and output dimensions.\n",
    "   - The number of hidden layers.\n",
    "   - The number of neurons per hidden layer.\n",
    "   - The activation functions used.\n",
    "\n",
    "   This implementation will be used for the following two questions.\n",
    "\n",
    "   Choose a suitable initialization for the network parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e84432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start with a function that initializes the network parameters.\n",
    "def init_net_params(layer_widths, key):\n",
    "    \"\"\"\n",
    "    Initialize the network parameters.\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    keys = random.split(key, len(layer_widths) - 1)\n",
    "\n",
    "    for i, (n_in, n_out) in enumerate(zip(layer_widths[:-1], layer_widths[1:])):\n",
    "        w_key = keys[i]\n",
    "        scale = jnp.sqrt(2.0 / n_in) # xavier initialization\n",
    "        w = random.normal(w_key, shape=(n_in, n_out)) * scale\n",
    "        b = jnp.zeros((n_out,))\n",
    "        params.append({'w': w, 'b': b})\n",
    "\n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27ef9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we define a forward pass function that computes the output of the network for a given input.\n",
    "def forward(params, x, activation):\n",
    "    \"\"\"\n",
    "    Forward pass of the network.\n",
    "    \"\"\"\n",
    "\n",
    "    activations = {\n",
    "        'relu': jax.nn.relu,\n",
    "        'sigmoid': jax.nn.sigmoid,\n",
    "        'tanh': jax.nn.tanh,\n",
    "        'softmax': jax.nn.softmax\n",
    "    }\n",
    "    activation = activations[activation]\n",
    "\n",
    "    for layer in params[:-1]:\n",
    "        x = x @ layer['w'] + layer['b']\n",
    "        x = activation(x)\n",
    "\n",
    "    # output layer, no activation function\n",
    "    final_layer = params[-1]\n",
    "    return jnp.dot(x, final_layer['w']) + final_layer['b']\n",
    "\n",
    "def get_batches(x, y, batch_size=256):\n",
    "    \"\"\"\n",
    "    Returns a list of tuples (x_batch, y_batch), each of size batch_size\n",
    "    (last batch may be smaller).\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    \n",
    "    # Make key\n",
    "    key = random.PRNGKey(0)\n",
    "    perm = jax.random.permutation(key, n)\n",
    "    x_shuffled = x[perm]\n",
    "    y_shuffled = y[perm]\n",
    "\n",
    "    batches = []\n",
    "    for i in range(0, n, batch_size):\n",
    "        x_batch = x_shuffled[i:i+batch_size]\n",
    "        y_batch = y_shuffled[i:i+batch_size]\n",
    "        batches.append((x_batch, y_batch))\n",
    "\n",
    "    return batches\n",
    "\n",
    "def get_splits(x, y, train=0.8, classification=True):\n",
    "    \"\"\"\n",
    "    This return a jax array of the training, validation, and test splits\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "    x = jnp.array(x) / 255.0 if classification else x\n",
    "    y = jnp.array(y)\n",
    "    # Calculate split indices (as integers)\n",
    "    train_end = int(train * n)\n",
    "    test_end = train_end + int((1-train)) * n\n",
    "    \n",
    "    # Split the data\n",
    "    x_train = x[:train_end]\n",
    "    y_train = y[:train_end]\n",
    "    \n",
    "    x_test = x[test_end:]\n",
    "    y_test = y[test_end:]\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def get_kfolds(x, y, k=5):\n",
    "    \"\"\"\n",
    "    Generate k-fold cross-validation splits.\n",
    "    \"\"\"\n",
    "    n = x.shape[0]\n",
    "\n",
    "    fold_size = n // k\n",
    "    folds = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # Validation fold indices\n",
    "        val_start = i * fold_size\n",
    "        val_end = (i + 1) * fold_size if i < k - 1 else n\n",
    "        \n",
    "        # Validation set\n",
    "        x_val = x[val_start:val_end]\n",
    "        y_val = y[val_start:val_end]\n",
    "        \n",
    "        # Training set (everything except validation fold)\n",
    "        x_train = jnp.concatenate([x[:val_start], x[val_end:]], axis=0)\n",
    "        y_train = jnp.concatenate([y[:val_start], y[val_end:]], axis=0)\n",
    "        \n",
    "        folds.append((x_train, y_train, x_val, y_val))\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c460bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we define the MSE loss function, we can have other loss functions\n",
    "def mse_loss(params, x, y, activation):\n",
    "    \"\"\"\n",
    "    MSE loss function for the network.\n",
    "    \"\"\"\n",
    "    batched_forward = vmap(forward, in_axes=(None, 0, None))\n",
    "    preds = batched_forward(params, x, activation)\n",
    "    return jnp.mean((preds - y) ** 2)\n",
    "\n",
    "def class_loss(params, x, y, activation):\n",
    "    \"\"\"\n",
    "    Classification cross-entroy loss function\n",
    "    \"\"\"\n",
    "    batched_forward = vmap(forward, in_axes=(None, 0, None))\n",
    "    logits = batched_forward(params, x, activation)\n",
    "\n",
    "    log_probs = jax.nn.log_softmax(logits, axis=1)\n",
    "    \n",
    "    nll = -log_probs[jnp.arange(y.shape[0]), y]\n",
    "    loss = jnp.mean(nll)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def evaluate_model(params, x, y, activation, classification):\n",
    "    \"\"\"\n",
    "    Evaluate model on a dataset and return accuracy and loss.\n",
    "    \"\"\"\n",
    "    batched_forward = vmap(forward, in_axes=(None, 0, None))\n",
    "    logits = batched_forward(params, x, activation)\n",
    "\n",
    "    if classification:\n",
    "        preds = jnp.argmax(logits, axis=1)\n",
    "        \n",
    "        accuracy = jnp.mean(preds == y)\n",
    "        loss = class_loss(params, x, y, activation)\n",
    "        \n",
    "        return accuracy, loss\n",
    "    else:\n",
    "        loss = jnp.mean((logits - y) ** 2)\n",
    "        return loss, loss # we return the loss twice for consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3f55d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now define an update function that updates the network parameters.\n",
    "def update(params, x, y, activation, lr, classification):\n",
    "    \"\"\"\n",
    "    Update function for the network parameters (basic gradient descent).\n",
    "    \"\"\"\n",
    "    loss_fn = class_loss if classification else mse_loss\n",
    "    grads = grad(loss_fn)(params, x, y, activation)\n",
    "    new_params = jax.tree.map(lambda p, g: p - lr * g, params, grads)\n",
    "    return new_params\n",
    "\n",
    "# After training, save the parameters\n",
    "def save_params(params, filename='assets/params.pkl'):\n",
    "    \"\"\"Save model parameters.\"\"\"\n",
    "    os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(params, f)\n",
    "    print(f\"Parameters saved to {filename}\")\n",
    "\n",
    "def load_params(filename='assets/params.pkl'):\n",
    "    \"\"\"Load model parameters.\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "    print(f\"Parameters loaded from {filename}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dd746a",
   "metadata": {},
   "source": [
    "2. Consider a standard benchmark dataset for classification: train a neural network to classify handwritten digits into the ten classes 0, 1,..., 9. As input for your model, use flattened vector representations of the MNIST images\n",
    "\n",
    "   (a) For this multiclass classification task, train your neural network with cross-entropy loss and mini-batch gradient descent. Vary the neural network architecture (layers, neurons per layer, activation functions) and training hyperparameters (learning rate, batch size, epochs). Use grid search with k-fold cross-validation (e.g., k = 5) to select promising hyperparameters. Report the accuracy and learning curves for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a855b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 70000 images\n",
      "Each image has 784 pixels (features)\n"
     ]
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784')\n",
    "print(f\"We have {mnist.data.shape[0]} images\")\n",
    "print(f\"Each image has {mnist.data.shape[1]} pixels (features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dc4e63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_kfold(x_train, y_train, layer_widths, activation, lr, batch_size, epochs, k=5, classification=True):\n",
    "    \"\"\"\n",
    "    Train the model using kfold cross-validation.\n",
    "    \"\"\"\n",
    "    folds = get_kfolds(x_train, y_train, k=k)\n",
    "    fold_results =[]\n",
    "    learning_curves = []\n",
    "\n",
    "    for fold_idx, (x_train_fold, y_train_fold, x_val_fold, y_val_fold) in enumerate(folds):\n",
    "        key = random.PRNGKey(42 + fold_idx) # we use a different key for each fold\n",
    "        params = init_net_params(layer_widths, key)\n",
    "\n",
    "        fold_history = {\n",
    "            'train_acc': [],\n",
    "            'val_acc': [],\n",
    "            'train_loss': [],\n",
    "            'val_loss': []\n",
    "        }\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            batches = get_batches(x_train_fold, y_train_fold, batch_size=batch_size)\n",
    "\n",
    "            for x_batch, y_batch in batches:\n",
    "                params = update(params, x_batch, y_batch, activation, lr, classification=classification)\n",
    "            \n",
    "            train_acc, train_loss = evaluate_model(params, x_train_fold, y_train_fold, activation, classification=classification)\n",
    "            val_acc, val_loss = evaluate_model(params, x_val_fold, y_val_fold, activation, classification=classification)\n",
    "\n",
    "            fold_history['train_acc'].append(float(train_acc))\n",
    "            fold_history['val_acc'].append(float(val_acc))\n",
    "            fold_history['train_loss'].append(float(train_loss))\n",
    "            fold_history['val_loss'].append(float(val_loss))\n",
    "            \n",
    "            if epoch % 50 == 0:\n",
    "                if classification:\n",
    "                    print(f\"Fold {fold_idx+1}, Epoch {epoch}: Train Acc = {train_acc:.4f}, Val Acc = {val_acc:.4f}\")\n",
    "                else:\n",
    "                    print(f\"Fold {fold_idx+1}, Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "        \n",
    "        final_train_acc, final_train_loss = evaluate_model(params, x_train_fold, y_train_fold, activation, classification=classification)\n",
    "        final_val_acc, final_val_loss = evaluate_model(params, x_val_fold, y_val_fold, activation, classification=classification)\n",
    "\n",
    "        fold_results.append((final_train_acc, final_val_acc, final_train_loss, final_val_loss))\n",
    "        learning_curves.append(fold_history)\n",
    "    \n",
    "    mean_val_acc = np.mean([fold[1] for fold in fold_results])\n",
    "    mean_val_loss = np.mean([fold[3] for fold in fold_results])\n",
    "    \n",
    "    return mean_val_acc, mean_val_loss, fold_results, learning_curves\n",
    "\n",
    "def train_model(x_train, y_train, x_test, y_test, best_config, classification=True):\n",
    "    \"\"\"\n",
    "    Train the best model on the full training set and evaluate on test set.\n",
    "    \"\"\"\n",
    "    layer_widths = best_config['layer_widths']\n",
    "    activation = best_config['activation']\n",
    "    lr = best_config['learning_rate']\n",
    "    batch_size = best_config['batch_size']\n",
    "    epochs = best_config['epochs']\n",
    "    \n",
    "    print(f\"\\nTraining best model on full training set...\")\n",
    "    print(f\"Configuration: {best_config}\")\n",
    "    \n",
    "    # Initialize parameters\n",
    "    key = random.PRNGKey(42)\n",
    "    params = init_net_params(layer_widths, key)\n",
    "    \n",
    "    learning_curve = {\n",
    "        'train_acc': [],\n",
    "        'test_acc': [],\n",
    "        'train_loss': [],\n",
    "        'test_loss': []\n",
    "    }\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        batches = get_batches(x_train, y_train, batch_size=batch_size)\n",
    "        \n",
    "        for x_batch, y_batch in batches:\n",
    "            params = update(params, x_batch, y_batch, activation, lr, classification=classification)\n",
    "        \n",
    "        # Evaluate periodically\n",
    "        if epoch % 1 == 0 or epoch == epochs - 1:\n",
    "            train_acc, train_loss = evaluate_model(params, x_train, y_train, activation, classification=classification)\n",
    "            test_acc, test_loss = evaluate_model(params, x_test, y_test, activation, classification=classification)\n",
    "            \n",
    "            learning_curve['train_acc'].append(float(train_acc))\n",
    "            learning_curve['test_acc'].append(float(test_acc))\n",
    "            learning_curve['train_loss'].append(float(train_loss))\n",
    "            learning_curve['test_loss'].append(float(test_loss))\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                if classification:\n",
    "                    print(f\"Epoch {epoch}: Train Acc = {train_acc:.4f}, Test Acc = {test_acc:.4f}\")\n",
    "                else:\n",
    "                    print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Test Loss = {test_loss:.4f}\")\n",
    "    \n",
    "    # Final evaluation\n",
    "    test_acc, test_loss = evaluate_model(params, x_test, y_test, activation, classification=classification)\n",
    "    print(f\"\\nFinal Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\") if classification else print(f\"\\nFinal Test Loss: {test_loss:.4f}\")\n",
    "    \n",
    "    return params, test_acc, test_loss, learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a69033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search configurations\n",
    "grid_search_configs = {\n",
    "    # Testing Baseline vs. Wide vs. Deep\n",
    "    'architectures': [\n",
    "        [784, 128, 10], \n",
    "        [784, 512, 10], \n",
    "        [784, 128, 128, 10]  \n",
    "    ],\n",
    "    \n",
    "    # Activation functions to test\n",
    "    'activations': ['relu', 'tanh'],\n",
    "    \n",
    "    # Learning rates\n",
    "    'learning_rates': [0.1, 0.01],\n",
    "    \n",
    "    # Batch sizes (speed vs gradient noise)\n",
    "    'batch_sizes': [64, 128],\n",
    "    \n",
    "    # Epochs\n",
    "    'epochs': [20] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20bb31c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the grid search function\n",
    "def grid_search(x_train, y_train, configs, k=5, classification=True):\n",
    "    \"\"\"\n",
    "    Perform grid search on the space of possible parameters defined earlier using k-fold cross validation\n",
    "    \n",
    "    \"\"\"\n",
    "    # Generate all combinations\n",
    "    combinations = list(itertools.product(\n",
    "        configs['architectures'],\n",
    "        configs['activations'],\n",
    "        configs['learning_rates'],\n",
    "        configs['batch_sizes'],\n",
    "        configs['epochs']\n",
    "    ))\n",
    "\n",
    "    total_combinations = len(combinations)\n",
    "    print(f\"Total configurations to test: {total_combinations}\")\n",
    "    print(f\"With k={k} folds, total training runs: {total_combinations * k}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    best_acc = -1\n",
    "    best_loss = -1\n",
    "    best_config = None\n",
    "    best_learning_curves = None\n",
    "    best_fold_results = None\n",
    "\n",
    "    for idx, (layer_widths, activation, lr, batch_size, epochs) in enumerate(combinations):\n",
    "        print(f\"\\n[{idx+1}/{total_combinations}] Testing configuration:\")\n",
    "        print(f\"Architecture: {layer_widths}\")\n",
    "        print(f\"Activation: {activation}\")\n",
    "        print(f\"Learning Rate: {lr}\")\n",
    "        print(f\"Batch Size: {batch_size}\")\n",
    "        print(f\"Epochs: {epochs}\")\n",
    "        \n",
    "        mean_val_acc, mean_val_loss, fold_results, learning_curves = train_model_kfold(\n",
    "            x_train, y_train, layer_widths, activation, lr, batch_size, epochs, k=k, classification=classification\n",
    "        )\n",
    "        \n",
    "        # result\n",
    "        config = {\n",
    "            'layer_widths': layer_widths,\n",
    "            'activation': activation,\n",
    "            'learning_rate': lr,\n",
    "            'batch_size': batch_size,\n",
    "            'epochs': epochs\n",
    "        }\n",
    "        \n",
    "        print(f\"Mean Validation Accuracy: {mean_val_acc:.4f} ({mean_val_acc*100:.2f}%)\")\n",
    "        print(f\"Mean Validation Loss: {mean_val_loss:.4f}\")\n",
    "        \n",
    "        # Update best configuration\n",
    "        if mean_val_acc > best_acc:\n",
    "            best_acc = mean_val_acc\n",
    "            best_loss = mean_val_loss\n",
    "            best_config = config.copy()\n",
    "            best_learning_curves = learning_curves\n",
    "            best_fold_results = fold_results\n",
    "            print(f\"New best configuration!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Grid Search Complete!\")\n",
    "    print(f\"Best Configuration:\")\n",
    "    print(f\"Architecture: {best_config['layer_widths']}\")\n",
    "    print(f\"Activation: {best_config['activation']}\")\n",
    "    print(f\"Learning Rate: {best_config['learning_rate']}\")\n",
    "    print(f\"Batch Size: {best_config['batch_size']}\")\n",
    "    print(f\"Epochs: {best_config['epochs']}\")\n",
    "    print(f\"Best Mean Validation Accuracy: {best_acc:.4f} ({best_acc*100:.2f}%)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return best_config, best_acc, best_loss, best_learning_curves, best_fold_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33f92399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configurations to test: 36\n",
      "With k=3 folds, total training runs: 108\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[1/36] Testing configuration:\n",
      "Architecture: [784, 128, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.9234, Val Acc = 0.9211\n",
      "Fold 2, Epoch 0: Train Acc = 0.9201, Val Acc = 0.9171\n",
      "Fold 3, Epoch 0: Train Acc = 0.9131, Val Acc = 0.9014\n",
      "Mean Validation Accuracy: 0.9693 (96.93%)\n",
      "Mean Validation Loss: 0.1025\n",
      "New best configuration!\n",
      "\n",
      "[2/36] Testing configuration:\n",
      "Architecture: [784, 128, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.9061, Val Acc = 0.9043\n",
      "Fold 2, Epoch 0: Train Acc = 0.9056, Val Acc = 0.9019\n",
      "Fold 3, Epoch 0: Train Acc = 0.9030, Val Acc = 0.8957\n",
      "Mean Validation Accuracy: 0.9651 (96.51%)\n",
      "Mean Validation Loss: 0.1162\n",
      "\n",
      "[3/36] Testing configuration:\n",
      "Architecture: [784, 128, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.8493, Val Acc = 0.8485\n",
      "Fold 2, Epoch 0: Train Acc = 0.8530, Val Acc = 0.8531\n",
      "Fold 3, Epoch 0: Train Acc = 0.8518, Val Acc = 0.8488\n",
      "Mean Validation Accuracy: 0.9365 (93.65%)\n",
      "Mean Validation Loss: 0.2216\n",
      "\n",
      "[4/36] Testing configuration:\n",
      "Architecture: [784, 128, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.7992, Val Acc = 0.7995\n",
      "Fold 2, Epoch 0: Train Acc = 0.8096, Val Acc = 0.8068\n",
      "Fold 3, Epoch 0: Train Acc = 0.8040, Val Acc = 0.8039\n",
      "Mean Validation Accuracy: 0.9199 (91.99%)\n",
      "Mean Validation Loss: 0.2799\n",
      "\n",
      "[5/36] Testing configuration:\n",
      "Architecture: [784, 128, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.5174, Val Acc = 0.5167\n",
      "Fold 2, Epoch 0: Train Acc = 0.5108, Val Acc = 0.5069\n",
      "Fold 3, Epoch 0: Train Acc = 0.5158, Val Acc = 0.5264\n",
      "Mean Validation Accuracy: 0.8804 (88.04%)\n",
      "Mean Validation Loss: 0.4447\n",
      "\n",
      "[6/36] Testing configuration:\n",
      "Architecture: [784, 128, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.3115, Val Acc = 0.3052\n",
      "Fold 2, Epoch 0: Train Acc = 0.3422, Val Acc = 0.3326\n",
      "Fold 3, Epoch 0: Train Acc = 0.3238, Val Acc = 0.3330\n",
      "Mean Validation Accuracy: 0.8519 (85.19%)\n",
      "Mean Validation Loss: 0.5967\n",
      "\n",
      "[7/36] Testing configuration:\n",
      "Architecture: [784, 128, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.9142, Val Acc = 0.9119\n",
      "Fold 2, Epoch 0: Train Acc = 0.9121, Val Acc = 0.9094\n",
      "Fold 3, Epoch 0: Train Acc = 0.9111, Val Acc = 0.9000\n",
      "Mean Validation Accuracy: 0.9670 (96.70%)\n",
      "Mean Validation Loss: 0.1084\n",
      "\n",
      "[8/36] Testing configuration:\n",
      "Architecture: [784, 128, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.9006, Val Acc = 0.8985\n",
      "Fold 2, Epoch 0: Train Acc = 0.8995, Val Acc = 0.8973\n",
      "Fold 3, Epoch 0: Train Acc = 0.9007, Val Acc = 0.8916\n",
      "Mean Validation Accuracy: 0.9608 (96.08%)\n",
      "Mean Validation Loss: 0.1347\n",
      "\n",
      "[9/36] Testing configuration:\n",
      "Architecture: [784, 128, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.8523, Val Acc = 0.8508\n",
      "Fold 2, Epoch 0: Train Acc = 0.8561, Val Acc = 0.8536\n",
      "Fold 3, Epoch 0: Train Acc = 0.8522, Val Acc = 0.8493\n",
      "Mean Validation Accuracy: 0.9264 (92.64%)\n",
      "Mean Validation Loss: 0.2559\n",
      "\n",
      "[10/36] Testing configuration:\n",
      "Architecture: [784, 128, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.8121, Val Acc = 0.8113\n",
      "Fold 2, Epoch 0: Train Acc = 0.8212, Val Acc = 0.8181\n",
      "Fold 3, Epoch 0: Train Acc = 0.8125, Val Acc = 0.8129\n",
      "Mean Validation Accuracy: 0.9121 (91.21%)\n",
      "Mean Validation Loss: 0.3062\n",
      "\n",
      "[11/36] Testing configuration:\n",
      "Architecture: [784, 128, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.5863, Val Acc = 0.5777\n",
      "Fold 2, Epoch 0: Train Acc = 0.6195, Val Acc = 0.6139\n",
      "Fold 3, Epoch 0: Train Acc = 0.6032, Val Acc = 0.6065\n",
      "Mean Validation Accuracy: 0.8771 (87.71%)\n",
      "Mean Validation Loss: 0.4605\n",
      "\n",
      "[12/36] Testing configuration:\n",
      "Architecture: [784, 128, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.3848, Val Acc = 0.3754\n",
      "Fold 2, Epoch 0: Train Acc = 0.4608, Val Acc = 0.4489\n",
      "Fold 3, Epoch 0: Train Acc = 0.4114, Val Acc = 0.4172\n",
      "Mean Validation Accuracy: 0.8528 (85.28%)\n",
      "Mean Validation Loss: 0.5920\n",
      "\n",
      "[13/36] Testing configuration:\n",
      "Architecture: [784, 512, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.9281, Val Acc = 0.9257\n",
      "Fold 2, Epoch 0: Train Acc = 0.9258, Val Acc = 0.9206\n",
      "Fold 3, Epoch 0: Train Acc = 0.9182, Val Acc = 0.9071\n",
      "Mean Validation Accuracy: 0.9723 (97.23%)\n",
      "Mean Validation Loss: 0.0906\n",
      "New best configuration!\n",
      "\n",
      "[14/36] Testing configuration:\n",
      "Architecture: [784, 512, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.9094, Val Acc = 0.9093\n",
      "Fold 2, Epoch 0: Train Acc = 0.9109, Val Acc = 0.9096\n",
      "Fold 3, Epoch 0: Train Acc = 0.9070, Val Acc = 0.8973\n",
      "Mean Validation Accuracy: 0.9679 (96.79%)\n",
      "Mean Validation Loss: 0.1047\n",
      "\n",
      "[15/36] Testing configuration:\n",
      "Architecture: [784, 512, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.8648, Val Acc = 0.8647\n",
      "Fold 2, Epoch 0: Train Acc = 0.8646, Val Acc = 0.8657\n",
      "Fold 3, Epoch 0: Train Acc = 0.8643, Val Acc = 0.8598\n",
      "Mean Validation Accuracy: 0.9413 (94.13%)\n",
      "Mean Validation Loss: 0.2057\n",
      "\n",
      "[16/36] Testing configuration:\n",
      "Architecture: [784, 512, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.8322, Val Acc = 0.8347\n",
      "Fold 2, Epoch 0: Train Acc = 0.8262, Val Acc = 0.8289\n",
      "Fold 3, Epoch 0: Train Acc = 0.8251, Val Acc = 0.8231\n",
      "Mean Validation Accuracy: 0.9255 (92.55%)\n",
      "Mean Validation Loss: 0.2628\n",
      "\n",
      "[17/36] Testing configuration:\n",
      "Architecture: [784, 512, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.6314, Val Acc = 0.6308\n",
      "Fold 2, Epoch 0: Train Acc = 0.5952, Val Acc = 0.5917\n",
      "Fold 3, Epoch 0: Train Acc = 0.6054, Val Acc = 0.6039\n",
      "Mean Validation Accuracy: 0.8877 (88.77%)\n",
      "Mean Validation Loss: 0.4199\n",
      "\n",
      "[18/36] Testing configuration:\n",
      "Architecture: [784, 512, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.3974, Val Acc = 0.4051\n",
      "Fold 2, Epoch 0: Train Acc = 0.3486, Val Acc = 0.3546\n",
      "Fold 3, Epoch 0: Train Acc = 0.4096, Val Acc = 0.4104\n",
      "Mean Validation Accuracy: 0.8659 (86.59%)\n",
      "Mean Validation Loss: 0.5526\n",
      "\n",
      "[19/36] Testing configuration:\n",
      "Architecture: [784, 512, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.9140, Val Acc = 0.9120\n",
      "Fold 2, Epoch 0: Train Acc = 0.9114, Val Acc = 0.9079\n",
      "Fold 3, Epoch 0: Train Acc = 0.9079, Val Acc = 0.8964\n",
      "Mean Validation Accuracy: 0.9678 (96.78%)\n",
      "Mean Validation Loss: 0.1074\n",
      "\n",
      "[20/36] Testing configuration:\n",
      "Architecture: [784, 512, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.9028, Val Acc = 0.9021\n",
      "Fold 2, Epoch 0: Train Acc = 0.9023, Val Acc = 0.9004\n",
      "Fold 3, Epoch 0: Train Acc = 0.9027, Val Acc = 0.8942\n",
      "Mean Validation Accuracy: 0.9590 (95.90%)\n",
      "Mean Validation Loss: 0.1392\n",
      "\n",
      "[21/36] Testing configuration:\n",
      "Architecture: [784, 512, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.8663, Val Acc = 0.8653\n",
      "Fold 2, Epoch 0: Train Acc = 0.8667, Val Acc = 0.8661\n",
      "Fold 3, Epoch 0: Train Acc = 0.8660, Val Acc = 0.8603\n",
      "Mean Validation Accuracy: 0.9238 (92.38%)\n",
      "Mean Validation Loss: 0.2695\n",
      "\n",
      "[22/36] Testing configuration:\n",
      "Architecture: [784, 512, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.8413, Val Acc = 0.8408\n",
      "Fold 2, Epoch 0: Train Acc = 0.8390, Val Acc = 0.8371\n",
      "Fold 3, Epoch 0: Train Acc = 0.8355, Val Acc = 0.8331\n",
      "Mean Validation Accuracy: 0.9124 (91.24%)\n",
      "Mean Validation Loss: 0.3073\n",
      "\n",
      "[23/36] Testing configuration:\n",
      "Architecture: [784, 512, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.6928, Val Acc = 0.6907\n",
      "Fold 2, Epoch 0: Train Acc = 0.6717, Val Acc = 0.6678\n",
      "Fold 3, Epoch 0: Train Acc = 0.6599, Val Acc = 0.6592\n",
      "Mean Validation Accuracy: 0.8841 (88.41%)\n",
      "Mean Validation Loss: 0.4239\n",
      "\n",
      "[24/36] Testing configuration:\n",
      "Architecture: [784, 512, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.5215, Val Acc = 0.5211\n",
      "Fold 2, Epoch 0: Train Acc = 0.4826, Val Acc = 0.4878\n",
      "Fold 3, Epoch 0: Train Acc = 0.5108, Val Acc = 0.5090\n",
      "Mean Validation Accuracy: 0.8653 (86.53%)\n",
      "Mean Validation Loss: 0.5229\n",
      "\n",
      "[25/36] Testing configuration:\n",
      "Architecture: [784, 128, 128, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.9355, Val Acc = 0.9300\n",
      "Fold 2, Epoch 0: Train Acc = 0.9160, Val Acc = 0.9100\n",
      "Fold 3, Epoch 0: Train Acc = 0.9079, Val Acc = 0.8967\n",
      "Mean Validation Accuracy: 0.9714 (97.14%)\n",
      "Mean Validation Loss: 0.1167\n",
      "\n",
      "[26/36] Testing configuration:\n",
      "Architecture: [784, 128, 128, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.9149, Val Acc = 0.9115\n",
      "Fold 2, Epoch 0: Train Acc = 0.8974, Val Acc = 0.8920\n",
      "Fold 3, Epoch 0: Train Acc = 0.9073, Val Acc = 0.8960\n",
      "Mean Validation Accuracy: 0.9686 (96.86%)\n",
      "Mean Validation Loss: 0.1094\n",
      "\n",
      "[27/36] Testing configuration:\n",
      "Architecture: [784, 128, 128, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.8622, Val Acc = 0.8583\n",
      "Fold 2, Epoch 0: Train Acc = 0.8643, Val Acc = 0.8615\n",
      "Fold 3, Epoch 0: Train Acc = 0.8729, Val Acc = 0.8689\n",
      "Mean Validation Accuracy: 0.9527 (95.27%)\n",
      "Mean Validation Loss: 0.1622\n",
      "\n",
      "[28/36] Testing configuration:\n",
      "Architecture: [784, 128, 128, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.8064, Val Acc = 0.8026\n",
      "Fold 2, Epoch 0: Train Acc = 0.8025, Val Acc = 0.7966\n",
      "Fold 3, Epoch 0: Train Acc = 0.8347, Val Acc = 0.8331\n",
      "Mean Validation Accuracy: 0.9361 (93.61%)\n",
      "Mean Validation Loss: 0.2188\n",
      "\n",
      "[29/36] Testing configuration:\n",
      "Architecture: [784, 128, 128, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.5477, Val Acc = 0.5533\n",
      "Fold 2, Epoch 0: Train Acc = 0.4887, Val Acc = 0.4782\n",
      "Fold 3, Epoch 0: Train Acc = 0.4969, Val Acc = 0.4892\n",
      "Mean Validation Accuracy: 0.8947 (89.47%)\n",
      "Mean Validation Loss: 0.3730\n",
      "\n",
      "[30/36] Testing configuration:\n",
      "Architecture: [784, 128, 128, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.3320, Val Acc = 0.3390\n",
      "Fold 2, Epoch 0: Train Acc = 0.2763, Val Acc = 0.2683\n",
      "Fold 3, Epoch 0: Train Acc = 0.3131, Val Acc = 0.3060\n",
      "Mean Validation Accuracy: 0.8680 (86.80%)\n",
      "Mean Validation Loss: 0.4960\n",
      "\n",
      "[31/36] Testing configuration:\n",
      "Architecture: [784, 128, 128, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.9284, Val Acc = 0.9231\n",
      "Fold 2, Epoch 0: Train Acc = 0.9229, Val Acc = 0.9197\n",
      "Fold 3, Epoch 0: Train Acc = 0.9140, Val Acc = 0.9018\n",
      "Mean Validation Accuracy: 0.9694 (96.94%)\n",
      "Mean Validation Loss: 0.1051\n",
      "\n",
      "[32/36] Testing configuration:\n",
      "Architecture: [784, 128, 128, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.9132, Val Acc = 0.9112\n",
      "Fold 2, Epoch 0: Train Acc = 0.9125, Val Acc = 0.9095\n",
      "Fold 3, Epoch 0: Train Acc = 0.9111, Val Acc = 0.9003\n",
      "Mean Validation Accuracy: 0.9660 (96.60%)\n",
      "Mean Validation Loss: 0.1116\n",
      "\n",
      "[33/36] Testing configuration:\n",
      "Architecture: [784, 128, 128, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.8732, Val Acc = 0.8717\n",
      "Fold 2, Epoch 0: Train Acc = 0.8719, Val Acc = 0.8705\n",
      "Fold 3, Epoch 0: Train Acc = 0.8745, Val Acc = 0.8685\n",
      "Mean Validation Accuracy: 0.9425 (94.25%)\n",
      "Mean Validation Loss: 0.1979\n",
      "\n",
      "[34/36] Testing configuration:\n",
      "Architecture: [784, 128, 128, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.01\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.8387, Val Acc = 0.8369\n",
      "Fold 2, Epoch 0: Train Acc = 0.8387, Val Acc = 0.8340\n",
      "Fold 3, Epoch 0: Train Acc = 0.8450, Val Acc = 0.8400\n",
      "Mean Validation Accuracy: 0.9261 (92.61%)\n",
      "Mean Validation Loss: 0.2539\n",
      "\n",
      "[35/36] Testing configuration:\n",
      "Architecture: [784, 128, 128, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.6320, Val Acc = 0.6302\n",
      "Fold 2, Epoch 0: Train Acc = 0.6422, Val Acc = 0.6301\n",
      "Fold 3, Epoch 0: Train Acc = 0.6307, Val Acc = 0.6271\n",
      "Mean Validation Accuracy: 0.8919 (89.19%)\n",
      "Mean Validation Loss: 0.3924\n",
      "\n",
      "[36/36] Testing configuration:\n",
      "Architecture: [784, 128, 128, 10]\n",
      "Activation: tanh\n",
      "Learning Rate: 0.001\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Acc = 0.4922, Val Acc = 0.4950\n",
      "Fold 2, Epoch 0: Train Acc = 0.4845, Val Acc = 0.4676\n",
      "Fold 3, Epoch 0: Train Acc = 0.4527, Val Acc = 0.4478\n",
      "Mean Validation Accuracy: 0.8717 (87.17%)\n",
      "Mean Validation Loss: 0.4983\n",
      "\n",
      "================================================================================\n",
      "Grid Search Complete!\n",
      "Best Configuration:\n",
      "Architecture: [784, 512, 10]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Best Mean Validation Accuracy: 0.9723 (97.23%)\n",
      "================================================================================\n",
      "The best configuration is:\n",
      "{'layer_widths': [784, 512, 10], 'activation': 'relu', 'learning_rate': 0.1, 'batch_size': 64, 'epochs': 20}\n",
      "Best K-fold Mean Accuracy: 0.97 (97.23%)\n",
      "Best K-fold Mean Loss: 0.09\n"
     ]
    }
   ],
   "source": [
    "# Run to perform grid search\n",
    "x = mnist.data.to_numpy()\n",
    "y = mnist.target.astype(int).to_numpy()\n",
    "x_train, y_train, x_test, y_test = get_splits(x, y)\n",
    "\n",
    "# Run grid search to find best configs\n",
    "best_config, best_acc, best_loss, best_learning_curves, best_fold_results = grid_search(\n",
    "    x_train, y_train, \n",
    "    grid_search_configs, \n",
    "    k=3\n",
    ")\n",
    "\n",
    "print(\"The best configuration is:\")\n",
    "print(best_config)\n",
    "print(f\"Best K-fold Mean Accuracy: {best_acc:.2f} ({best_acc*100:.2f}%)\")\n",
    "print(f\"Best K-fold Mean Loss: {best_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85b3ed26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training best model on full training set...\n",
      "Configuration: {'layer_widths': [784, 128, 128, 10], 'activation': 'relu', 'learning_rate': 0.1, 'batch_size': 64, 'epochs': 250}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train best model on the best params\u001b[39;00m\n\u001b[1;32m      2\u001b[0m best_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer_widths\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m784\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m250\u001b[39m\n\u001b[1;32m      8\u001b[0m }\n\u001b[0;32m---> 10\u001b[0m params, test_acc, test_loss, learning_curve \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_config\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOur best model trained on the full training set has an accuracy of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOur best model trained on the full training set has a loss of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 80\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(x_train, y_train, x_test, y_test, best_config, classification)\u001b[0m\n\u001b[1;32m     77\u001b[0m batches \u001b[38;5;241m=\u001b[39m get_batches(x_train, y_train, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[0;32m---> 80\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassification\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Evaluate periodically\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m, in \u001b[0;36mupdate\u001b[0;34m(params, x, y, activation, lr, classification)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mUpdate function for the network parameters (basic gradient descent).\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m class_loss \u001b[38;5;28;01mif\u001b[39;00m classification \u001b[38;5;28;01melse\u001b[39;00m mse_loss\n\u001b[0;32m----> 7\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m new_params \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m p, g: p \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m g, params, grads)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_params\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:399\u001b[0m, in \u001b[0;36mgrad.<locals>.grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fun, docstr\u001b[38;5;241m=\u001b[39mdocstr, argnums\u001b[38;5;241m=\u001b[39margnums)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgrad_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 399\u001b[0m   _, g \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_and_grad_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:462\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_argnum \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args):\n\u001b[1;32m    459\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiating with respect to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margnums\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    460\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_argnum\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional arguments to be passed by the caller, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got only \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 462\u001b[0m dbg \u001b[38;5;241m=\u001b[39m \u001b[43mdebug_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue_and_grad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m f \u001b[38;5;241m=\u001b[39m lu\u001b[38;5;241m.\u001b[39mwrap_init(fun, params\u001b[38;5;241m=\u001b[39mkwargs, debug_info\u001b[38;5;241m=\u001b[39mdbg)\n\u001b[1;32m    465\u001b[0m f_partial, dyn_args \u001b[38;5;241m=\u001b[39m argnums_partial(f, argnums, args,\n\u001b[1;32m    466\u001b[0m                                       require_static_args_hashable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api_util.py:610\u001b[0m, in \u001b[0;36mdebug_info\u001b[0;34m(traced_for, fun, args, kwargs, static_argnums, static_argnames, result_paths_thunk, sourceinfo, signature)\u001b[0m\n\u001b[1;32m    608\u001b[0m   sourceinfo \u001b[38;5;241m=\u001b[39m fun_sourceinfo(fun)\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 610\u001b[0m   signature \u001b[38;5;241m=\u001b[39m \u001b[43mfun_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    611\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m _non_static_arg_names(signature, args, kwargs, static_argnums,\n\u001b[1;32m    612\u001b[0m                                   static_argnames)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m core\u001b[38;5;241m.\u001b[39mDebugInfo(traced_for, sourceinfo, arg_names, result_paths_thunk)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api_util.py:618\u001b[0m, in \u001b[0;36mfun_signature\u001b[0;34m(fun)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfun_signature\u001b[39m(fun: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m inspect\u001b[38;5;241m.\u001b[39mSignature \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    617\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/inspect.py:3254\u001b[0m, in \u001b[0;36msignature\u001b[0;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   3252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msignature\u001b[39m(obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   3253\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3255\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/inspect.py:3002\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[0;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[1;32m   2998\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   2999\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfrom_callable\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   3000\u001b[0m                   follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   3001\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 3002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigcls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3003\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3004\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/inspect.py:2460\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[1;32m   2457\u001b[0m             new_params \u001b[38;5;241m=\u001b[39m (first_wrapped_param,) \u001b[38;5;241m+\u001b[39m sig_params\n\u001b[1;32m   2458\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m sig\u001b[38;5;241m.\u001b[39mreplace(parameters\u001b[38;5;241m=\u001b[39mnew_params)\n\u001b[0;32m-> 2460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43misfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m _signature_is_functionlike(obj):\n\u001b[1;32m   2461\u001b[0m     \u001b[38;5;66;03m# If it's a pure Python function, or an object that is duck type\u001b[39;00m\n\u001b[1;32m   2462\u001b[0m     \u001b[38;5;66;03m# of a Python function (Cython functions, for instance), then:\u001b[39;00m\n\u001b[1;32m   2463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _signature_from_function(sigcls, obj,\n\u001b[1;32m   2464\u001b[0m                                     skip_bound_arg\u001b[38;5;241m=\u001b[39mskip_bound_arg,\n\u001b[1;32m   2465\u001b[0m                                     \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mglobals\u001b[39m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlocals\u001b[39m, eval_str\u001b[38;5;241m=\u001b[39meval_str)\n\u001b[1;32m   2467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _signature_is_builtin(obj):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/inspect.py:277\u001b[0m, in \u001b[0;36misfunction\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;250m        \u001b[39m\u001b[38;5;124;03m\"\"\"Return true if the object is a getset descriptor.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03m        getset descriptors are specialized descriptors defined in extension\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m        modules.\"\"\"\u001b[39;00m\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21misfunction\u001b[39m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    278\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return true if the object is a user-defined function.\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m    Function objects provide these attributes:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m        __annotations__ dict of parameter annotations\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;124;03m        __kwdefaults__  dict of keyword only parameters with defaults\"\"\"\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mobject\u001b[39m, types\u001b[38;5;241m.\u001b[39mFunctionType)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train best model on the best params\n",
    "best_config = {\n",
    "    'layer_widths': [784, 128, 128, 10],\n",
    "    'activation': 'relu',\n",
    "    'learning_rate': 0.1,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 250\n",
    "}\n",
    "\n",
    "params, test_acc, test_loss, learning_curve = train_model(\n",
    "    x_train, y_train, x_test, y_test, best_config\n",
    ")\n",
    "\n",
    "print(f\"Our best model trained on the full training set has an accuracy of {test_acc}%\")\n",
    "print(f\"Our best model trained on the full training set has a loss of {test_loss:.2f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(learning_curve['train_acc'], label='Training Accuracy')\n",
    "plt.plot(learning_curve['test_acc'], label='Test Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(learning_curve['train_loss'], label='Training Loss')\n",
    "plt.plot(learning_curve['test_loss'], label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "save_params(params, filename='../assets/mnist_params.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ead2d0",
   "metadata": {},
   "source": [
    "   (b) Study how optimizer hyperparameters (batch size, learning rate) affect convergence speed and final performance, and discuss your observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c309297a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d94dd50e",
   "metadata": {},
   "source": [
    " (c) Identify and visualize misclassified images for your best model, and provide possible explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34344d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters loaded from ../assets/mnist_params.pkl\n",
      "\n",
      "Final Test Accuracy: 0.9771 (97.71%)\n",
      "We have 320 misclassified images\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load params\n",
    "params = load_params('../assets/mnist_params.pkl')\n",
    "\n",
    "# get predictions\n",
    "batched_forward = vmap(forward, in_axes=(None, 0, None))\n",
    "logits = batched_forward(params, x_test, 'relu')\n",
    "preds = jnp.argmax(logits, axis=1)\n",
    "\n",
    "test_acc, test_loss = evaluate_model(params, x_test, y_test, 'relu', classification=True)\n",
    "print(f\"\\nFinal Test Accuracy: {test_acc:.4f} ({test_acc*100:.2f}%)\")\n",
    "\n",
    "# get misclassified images\n",
    "misclassified = jnp.where(preds != y_test)[0]\n",
    "\n",
    "print(f\"We have {len(misclassified)} misclassified images\")\n",
    "\n",
    "# plot misclassified images with correct and predicted labels\n",
    "num_figures = 10\n",
    "rows = 4\n",
    "cols = 5  # rows * cols should be >= num_figures\n",
    "\n",
    "plt.figure(figsize=(cols * 3, rows * 3))\n",
    "for i in range(num_figures):\n",
    "    plt.subplot(rows, cols, i + 1)\n",
    "    plt.imshow(x_test[misclassified[i]].reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"True: {y_test[misclassified[i]]}, Pred: {preds[misclassified[i]]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd3db43",
   "metadata": {},
   "source": [
    "Next, test the performance of your neural network implementation on a simple regression problem. Fit functions of the form\n",
    "\n",
    "$$f_k(x) := \\sin(k\\pi x), \\quad x \\in [-1, 1],$$\n",
    "\n",
    "with $k \\in \\mathbb{N}$ using your neural network implementation. Use mean squared error (MSE) as the loss. Generate a sufficient number of training samples yourself, balancing approximation quality and computational cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14bee00",
   "metadata": {},
   "source": [
    "(a) Perform a grid search to find the best hyperparameters for fitting $f_1$, varying at least the parameters that you also tested in Question 2. Discuss your findings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "965e947e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search configurations for regression\n",
    "grid_search_configs = {\n",
    "    'architectures': [\n",
    "        # hidden layers\n",
    "        [1, 128, 1],\n",
    "        [1, 512, 1],\n",
    "        [1, 128, 128, 1],\n",
    "    ],\n",
    "    \n",
    "    # Activation functions\n",
    "    'activations': ['relu'],\n",
    "    \n",
    "    # Learning rates\n",
    "    'learning_rates': [0.1, 0.01],\n",
    "    \n",
    "    # Batch sizes\n",
    "    'batch_sizes': [64, 128],\n",
    "    \n",
    "    # Epochs\n",
    "    'epochs': [20]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c89ec276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We start by generating a sufficient number of training samples.\n",
    "n_samples = 50000\n",
    "k = 10\n",
    "x = jnp.linspace(-1, 1, n_samples).reshape(-1, 1)\n",
    "y = jnp.sin(k * jnp.pi * x)\n",
    "\n",
    "key = random.PRNGKey(42)\n",
    "indices = jnp.arange(n_samples)\n",
    "shuffled_indices = random.permutation(key, indices)\n",
    "x_shuffled = x[shuffled_indices]\n",
    "y_shuffled = y[shuffled_indices]\n",
    "\n",
    "x_train, y_train, x_test, y_test = get_splits(x_shuffled, y_shuffled, classification=False)\n",
    "\n",
    "# sort the x_test and y_test to plot\n",
    "sort_idx = jnp.argsort(x_test.flatten())\n",
    "x_test = x_test[sort_idx]\n",
    "y_test = y_test[sort_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a543bc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total configurations to test: 6\n",
      "With k=3 folds, total training runs: 18\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[1/6] Testing configuration:\n",
      "Architecture: [1, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.5012, Val Loss = 0.5050\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# We do the same grid search as in Question 2.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m best_config, best_acc, best_loss, best_learning_curves, best_fold_results \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrid_search_configs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe best configuration is:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_config)\n",
      "Cell \u001b[0;32mIn[25], line 35\u001b[0m, in \u001b[0;36mgrid_search\u001b[0;34m(x_train, y_train, configs, k, classification)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatch Size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m mean_val_acc, mean_val_loss, fold_results, learning_curves \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_kfold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_widths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassification\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# result\u001b[39;00m\n\u001b[1;32m     40\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer_widths\u001b[39m\u001b[38;5;124m'\u001b[39m: layer_widths,\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m: activation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: epochs\n\u001b[1;32m     46\u001b[0m }\n",
      "Cell \u001b[0;32mIn[23], line 24\u001b[0m, in \u001b[0;36mtrain_model_kfold\u001b[0;34m(x_train, y_train, layer_widths, activation, lr, batch_size, epochs, k, classification)\u001b[0m\n\u001b[1;32m     21\u001b[0m batches \u001b[38;5;241m=\u001b[39m get_batches(x_train_fold, y_train_fold, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[0;32m---> 24\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassification\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m train_acc, train_loss \u001b[38;5;241m=\u001b[39m evaluate_model(params, x_train_fold, y_train_fold, activation, classification\u001b[38;5;241m=\u001b[39mclassification)\n\u001b[1;32m     27\u001b[0m val_acc, val_loss \u001b[38;5;241m=\u001b[39m evaluate_model(params, x_val_fold, y_val_fold, activation, classification\u001b[38;5;241m=\u001b[39mclassification)\n",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m, in \u001b[0;36mupdate\u001b[0;34m(params, x, y, activation, lr, classification)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mUpdate function for the network parameters (basic gradient descent).\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m class_loss \u001b[38;5;28;01mif\u001b[39;00m classification \u001b[38;5;28;01melse\u001b[39;00m mse_loss\n\u001b[0;32m----> 7\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m new_params \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m p, g: p \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m g, params, grads)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_params\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:399\u001b[0m, in \u001b[0;36mgrad.<locals>.grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fun, docstr\u001b[38;5;241m=\u001b[39mdocstr, argnums\u001b[38;5;241m=\u001b[39margnums)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgrad_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 399\u001b[0m   _, g \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_and_grad_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:470\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m   _check_input_dtype_grad(holomorphic, allow_int, leaf)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 470\u001b[0m   ans, vjp_py \u001b[38;5;241m=\u001b[39m \u001b[43m_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_partial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdyn_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    472\u001b[0m   ans, vjp_py, aux \u001b[38;5;241m=\u001b[39m _vjp(\n\u001b[1;32m    473\u001b[0m       f_partial, \u001b[38;5;241m*\u001b[39mdyn_args, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:2015\u001b[0m, in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, *primals)\u001b[0m\n\u001b[1;32m   2013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[1;32m   2014\u001b[0m   flat_fun, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun_nokwargs(fun, in_tree)\n\u001b[0;32m-> 2015\u001b[0m   out_primals, vjp \u001b[38;5;241m=\u001b[39m \u001b[43mad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2016\u001b[0m   out_tree \u001b[38;5;241m=\u001b[39m out_tree()\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:260\u001b[0m, in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvjp\u001b[39m(traceable: lu\u001b[38;5;241m.\u001b[39mWrappedFun, primals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    259\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 260\u001b[0m     out_primals, pvals, jaxpr, consts \u001b[38;5;241m=\u001b[39m \u001b[43mlinearize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraceable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m     out_primals, pvals, jaxpr, consts, aux \u001b[38;5;241m=\u001b[39m linearize(traceable, \u001b[38;5;241m*\u001b[39mprimals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:245\u001b[0m, in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m _, in_tree \u001b[38;5;241m=\u001b[39m tree_flatten(((primals, primals), {}))\n\u001b[1;32m    244\u001b[0m jvpfun_flat, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun(jvpfun, in_tree)\n\u001b[0;32m--> 245\u001b[0m jaxpr, out_pvals, consts \u001b[38;5;241m=\u001b[39m \u001b[43mpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_to_jaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjvpfun_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m out_primals_pvals, out_tangents_pvals \u001b[38;5;241m=\u001b[39m tree_unflatten(out_tree(), out_pvals)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m out_primal_pval\u001b[38;5;241m.\u001b[39mis_known() \u001b[38;5;28;01mfor\u001b[39;00m out_primal_pval \u001b[38;5;129;01min\u001b[39;00m out_primals_pvals):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/profiler.py:334\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    333\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:576\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_nounits\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    574\u001b[0m fun \u001b[38;5;241m=\u001b[39m trace_to_subjaxpr_nounits(fun, trace, instantiate, fun\u001b[38;5;241m.\u001b[39mdebug_info)\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m--> 576\u001b[0m   jaxpr, (out_pvals, consts, env) \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m trace, fun\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/linear_util.py:210\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    209\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the transformed function\"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_transformed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:590\u001b[0m, in \u001b[0;36mtrace_to_subjaxpr_nounits\u001b[0;34m(f, trace, instantiate, debug_info, in_pvals)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation2\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrace_to_subjaxpr_nounits\u001b[39m(\n\u001b[1;32m    584\u001b[0m     f: Callable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    587\u001b[0m     debug_info: core\u001b[38;5;241m.\u001b[39mDebugInfo,\n\u001b[1;32m    588\u001b[0m     in_pvals: Sequence[PartialVal]):\n\u001b[1;32m    589\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(pv, PartialVal) \u001b[38;5;28;01mfor\u001b[39;00m pv \u001b[38;5;129;01min\u001b[39;00m in_pvals), in_pvals\n\u001b[0;32m--> 590\u001b[0m   out_tracers, jaxpr, out_consts, env \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_to_subjaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m      \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstantiate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m   out_pvals \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mpval \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m out_tracers]\n\u001b[1;32m    593\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m out_tracers\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:623\u001b[0m, in \u001b[0;36m_trace_to_subjaxpr_nounits\u001b[0;34m(f, trace, instantiate, in_pvals, debug_info)\u001b[0m\n\u001b[1;32m    621\u001b[0m in_args \u001b[38;5;241m=\u001b[39m merge_lists(in_knowns, in_tracers, in_consts)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m--> 623\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ans, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)), (\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected return type when tracing function to jaxpr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mans\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, core\u001b[38;5;241m.\u001b[39mTracer) \u001b[38;5;129;01mor\u001b[39;00m core\u001b[38;5;241m.\u001b[39mvalid_jaxtype(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m ans), (\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected return type when tracing function to jaxpr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mans\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api_util.py:73\u001b[0m, in \u001b[0;36mflatten_fun\u001b[0;34m(f, store, in_tree, *args_flat)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_with_aux2\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflatten_fun\u001b[39m(f: Callable, store: lu\u001b[38;5;241m.\u001b[39mStore,\n\u001b[1;32m     71\u001b[0m                 in_tree: PyTreeDef, \u001b[38;5;241m*\u001b[39margs_flat):\n\u001b[1;32m     72\u001b[0m   py_args, py_kwargs \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, args_flat)\n\u001b[0;32m---> 73\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m   ans, out_tree \u001b[38;5;241m=\u001b[39m tree_flatten(ans)\n\u001b[1;32m     75\u001b[0m   store\u001b[38;5;241m.\u001b[39mstore(out_tree)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:80\u001b[0m, in \u001b[0;36mjvpfun\u001b[0;34m(f, instantiate, transform_stack, primals, tangents)\u001b[0m\n\u001b[1;32m     77\u001b[0m ctx \u001b[38;5;241m=\u001b[39m (source_info_util\u001b[38;5;241m.\u001b[39mtransform_name_stack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjvp\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m transform_stack\n\u001b[1;32m     78\u001b[0m        \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext())\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[0;32m---> 80\u001b[0m   out_primals, out_tangents \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtangents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(instantiate) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     82\u001b[0m   instantiate \u001b[38;5;241m=\u001b[39m [instantiate] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(out_tangents)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:120\u001b[0m, in \u001b[0;36mjvp_subtrace\u001b[0;34m(f, tag, primals, tangents)\u001b[0m\n\u001b[1;32m    117\u001b[0m   in_tracers \u001b[38;5;241m=\u001b[39m [maybe_jvp_tracer(trace, x, t)\n\u001b[1;32m    118\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m x, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(primals, tangents)]\n\u001b[1;32m    119\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m--> 120\u001b[0m     ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_tracers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m   out \u001b[38;5;241m=\u001b[39m unzip2(\u001b[38;5;28mmap\u001b[39m(trace\u001b[38;5;241m.\u001b[39mto_primal_tangent_pair, ans))\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api_util.py:90\u001b[0m, in \u001b[0;36mflatten_fun_nokwargs\u001b[0;34m(f, store, in_tree, *args_flat)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_with_aux2\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflatten_fun_nokwargs\u001b[39m(f: Callable, store: lu\u001b[38;5;241m.\u001b[39mStore,\n\u001b[1;32m     88\u001b[0m                          in_tree: PyTreeDef, \u001b[38;5;241m*\u001b[39margs_flat):\n\u001b[1;32m     89\u001b[0m   py_args \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, args_flat)\n\u001b[0;32m---> 90\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m   ans, out_tree \u001b[38;5;241m=\u001b[39m tree_flatten(ans)\n\u001b[1;32m     92\u001b[0m   store\u001b[38;5;241m.\u001b[39mstore(out_tree)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api_util.py:284\u001b[0m, in \u001b[0;36m_argnums_partial\u001b[0;34m(_fun, _dyn_argnums, _fixed_args, *dyn_args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m args \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mnext\u001b[39m(fixed_args_)\u001b[38;5;241m.\u001b[39mval \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m sentinel \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(fixed_args_, sentinel) \u001b[38;5;129;01mis\u001b[39;00m sentinel\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/linear_util.py:370\u001b[0m, in \u001b[0;36m_get_result_paths_thunk\u001b[0;34m(_fun, _store, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;129m@transformation_with_aux2\u001b[39m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_result_paths_thunk\u001b[39m(_fun: Callable, _store: Store, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 370\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m   result_paths \u001b[38;5;241m=\u001b[39m [_clean_keystr_arg_names(path) \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m generate_key_paths(ans)]\n\u001b[1;32m    372\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _store:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# In some instances a lu.WrappedFun is called multiple times, e.g.,\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# the bwd function in a custom_vjp\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(params, x, y, activation)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mMSE loss function for the network.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m batched_forward \u001b[38;5;241m=\u001b[39m vmap(forward, in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m----> 7\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mbatched_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mmean((preds \u001b[38;5;241m-\u001b[39m y) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:1015\u001b[0m, in \u001b[0;36mvmap.<locals>.vmap_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1013\u001b[0m   axis_data \u001b[38;5;241m=\u001b[39m batching\u001b[38;5;241m.\u001b[39mAxisData(axis_name, axis_size_, spmd_axis_name,\n\u001b[1;32m   1014\u001b[0m                                 explicit_mesh_axis)\n\u001b[0;32m-> 1015\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mbatching\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m      \u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvmap out_axes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_axes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m batching\u001b[38;5;241m.\u001b[39mSpecMatchError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1020\u001b[0m   out_axes_flat \u001b[38;5;241m=\u001b[39m flatten_axes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap out_axes\u001b[39m\u001b[38;5;124m\"\u001b[39m, out_tree(), out_axes)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/linear_util.py:210\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    209\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the transformed function\"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_transformed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/batching.py:604\u001b[0m, in \u001b[0;36m_batch_outer\u001b[0;34m(f, axis_data, in_dims, *in_vals)\u001b[0m\n\u001b[1;32m    602\u001b[0m tag \u001b[38;5;241m=\u001b[39m TraceTag()\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m source_info_util\u001b[38;5;241m.\u001b[39mtransform_name_stack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvmap\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 604\u001b[0m   outs, trace \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_vals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mensure_no_leaks(trace): \u001b[38;5;28;01mdel\u001b[39;00m trace\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/batching.py:619\u001b[0m, in \u001b[0;36m_batch_inner\u001b[0;34m(f, axis_data, out_dim_dests, tag, in_dims, *in_vals)\u001b[0m\n\u001b[1;32m    615\u001b[0m   in_tracers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(partial(to_elt, trace, idx), in_vals, in_dims)\n\u001b[1;32m    616\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m (core\u001b[38;5;241m.\u001b[39mset_current_trace(trace),\n\u001b[1;32m    617\u001b[0m         core\u001b[38;5;241m.\u001b[39mextend_axis_env_nd([(axis_data\u001b[38;5;241m.\u001b[39mname, axis_data\u001b[38;5;241m.\u001b[39msize)]),\n\u001b[1;32m    618\u001b[0m         core\u001b[38;5;241m.\u001b[39madd_spmd_axis_names(axis_data\u001b[38;5;241m.\u001b[39mspmd_name)):\n\u001b[0;32m--> 619\u001b[0m     outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_tracers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    621\u001b[0m out_dim_dests \u001b[38;5;241m=\u001b[39m out_dim_dests() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(out_dim_dests) \u001b[38;5;28;01melse\u001b[39;00m out_dim_dests\n\u001b[1;32m    622\u001b[0m out_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(partial(from_elt, trace, axis_data\u001b[38;5;241m.\u001b[39msize,\n\u001b[1;32m    623\u001b[0m                        axis_data\u001b[38;5;241m.\u001b[39mexplicit_mesh_axis),\n\u001b[1;32m    624\u001b[0m                \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(outs)), outs, out_dim_dests)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/batching.py:339\u001b[0m, in \u001b[0;36mflatten_fun_for_vmap\u001b[0;34m(f, store, in_tree, *args_flat)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_with_aux2\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflatten_fun_for_vmap\u001b[39m(f: Callable,\n\u001b[1;32m    337\u001b[0m                          store: lu\u001b[38;5;241m.\u001b[39mStore, in_tree: PyTreeDef, \u001b[38;5;241m*\u001b[39margs_flat):\n\u001b[1;32m    338\u001b[0m   py_args, py_kwargs \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, args_flat)\n\u001b[0;32m--> 339\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m   ans, out_tree \u001b[38;5;241m=\u001b[39m tree_flatten(ans, is_leaf\u001b[38;5;241m=\u001b[39mis_vmappable)\n\u001b[1;32m    341\u001b[0m   store\u001b[38;5;241m.\u001b[39mstore(out_tree)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/linear_util.py:370\u001b[0m, in \u001b[0;36m_get_result_paths_thunk\u001b[0;34m(_fun, _store, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;129m@transformation_with_aux2\u001b[39m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_result_paths_thunk\u001b[39m(_fun: Callable, _store: Store, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 370\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m   result_paths \u001b[38;5;241m=\u001b[39m [_clean_keystr_arg_names(path) \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m generate_key_paths(ans)]\n\u001b[1;32m    372\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _store:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# In some instances a lu.WrappedFun is called multiple times, e.g.,\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# the bwd function in a custom_vjp\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 17\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(params, x, activation)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m params[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m@\u001b[39m layer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m layer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# output layer, no activation function\u001b[39;00m\n\u001b[1;32m     20\u001b[0m final_layer \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/custom_derivatives.py:280\u001b[0m, in \u001b[0;36mcustom_jvp.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m flat_fun, out_type1 \u001b[38;5;241m=\u001b[39m _flatten_fun_nokwargs(f_, in_tree)\n\u001b[1;32m    278\u001b[0m flat_jvp, out_type2 \u001b[38;5;241m=\u001b[39m _flatten_jvp(jvp, primal_name, debug_jvp\u001b[38;5;241m.\u001b[39mfunc_name,\n\u001b[1;32m    279\u001b[0m                                    in_tree, out_type1)\n\u001b[0;32m--> 280\u001b[0m out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_jvp_call_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_jvp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43msymbolic_zeros\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymbolic_zeros\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m _, (out_tree, _) \u001b[38;5;241m=\u001b[39m lu\u001b[38;5;241m.\u001b[39mmerge_linear_aux(out_type1, out_type2)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree_unflatten(out_tree, out_flat)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/custom_derivatives.py:368\u001b[0m, in \u001b[0;36mCustomJVPCallPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m--> 368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:520\u001b[0m, in \u001b[0;36mPrimitive._true_bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    518\u001b[0m trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(eval_trace)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 520\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m   trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(prev_trace)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/custom_derivatives.py:372\u001b[0m, in \u001b[0;36mCustomJVPCallPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[1;32m    371\u001b[0m   fun, jvp, tracers \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m], args[\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m--> 372\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_custom_jvp_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjvp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/batching.py:564\u001b[0m, in \u001b[0;36mBatchTrace.process_custom_jvp_call\u001b[0;34m(self, prim, fun, jvp, tracers, symbolic_zeros)\u001b[0m\n\u001b[1;32m    562\u001b[0m fun, out_dims1 \u001b[38;5;241m=\u001b[39m batch_subtrace(fun, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtag, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis_data, in_dims)\n\u001b[1;32m    563\u001b[0m jvp, out_dims2 \u001b[38;5;241m=\u001b[39m batch_custom_jvp_subtrace(jvp, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtag, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis_data, in_dims)\n\u001b[0;32m--> 564\u001b[0m out_vals \u001b[38;5;241m=\u001b[39m \u001b[43mprim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjvp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43min_vals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msymbolic_zeros\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msymbolic_zeros\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m fst, out_dims \u001b[38;5;241m=\u001b[39m lu\u001b[38;5;241m.\u001b[39mmerge_linear_aux(out_dims1, out_dims2)\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fst:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/custom_derivatives.py:372\u001b[0m, in \u001b[0;36mCustomJVPCallPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[1;32m    371\u001b[0m   fun, jvp, tracers \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m], args[\u001b[38;5;241m2\u001b[39m:]\n\u001b[0;32m--> 372\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_custom_jvp_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjvp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:492\u001b[0m, in \u001b[0;36mJVPTrace.process_custom_jvp_call\u001b[0;34m(self, prim, fun, f_jvp, tracers, symbolic_zeros)\u001b[0m\n\u001b[1;32m    490\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m     tangents_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(replace_internal_symbolic_zeros, tangents_in)\n\u001b[0;32m--> 492\u001b[0m   outs \u001b[38;5;241m=\u001b[39m \u001b[43mf_jvp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprimals_in\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtangents_in\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m primals_out, tangents_out \u001b[38;5;241m=\u001b[39m split_list(outs, [\u001b[38;5;28mlen\u001b[39m(outs) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    495\u001b[0m tangents_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(replace_rule_output_symbolic_zeros, tangents_out)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/linear_util.py:210\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    209\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the transformed function\"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_transformed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/batching.py:887\u001b[0m, in \u001b[0;36mbatch_custom_jvp_subtrace\u001b[0;34m(f, store, tag, axis_data, in_dims, *in_vals)\u001b[0m\n\u001b[1;32m    882\u001b[0m in_tracers \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m    883\u001b[0m               SymbolicZero(core\u001b[38;5;241m.\u001b[39mmapped_aval(size, dim, val\u001b[38;5;241m.\u001b[39maval))\n\u001b[1;32m    884\u001b[0m               \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(val) \u001b[38;5;129;01mis\u001b[39;00m SymbolicZero \u001b[38;5;28;01melse\u001b[39;00m BatchTracer(trace, val, dim)\n\u001b[1;32m    885\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m val, dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(in_vals, in_dims \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)]\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m--> 887\u001b[0m   outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_tracers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    888\u001b[0m   \u001b[38;5;66;03m# TODO(mattjj,frostig): instantiating any SymbolicZero output is easy, but can\u001b[39;00m\n\u001b[1;32m    889\u001b[0m   \u001b[38;5;66;03m# be wasteful in the rare case it actually triggers; handle symbolically!\u001b[39;00m\n\u001b[1;32m    890\u001b[0m   outs \u001b[38;5;241m=\u001b[39m [instantiate(replace_rule_output_symbolic_zeros(x)) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m outs]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/custom_derivatives.py:290\u001b[0m, in \u001b[0;36m_flatten_jvp\u001b[0;34m(f, store, primal_name, jvp_name, in_tree, maybe_out_type, *args)\u001b[0m\n\u001b[1;32m    288\u001b[0m py_primals \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, primals_in)\n\u001b[1;32m    289\u001b[0m py_tangents \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, tangents_in)\n\u001b[0;32m--> 290\u001b[0m pair_out \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpy_primals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpy_tangents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pair_out, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pair_out) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    292\u001b[0m   msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCustom JVP rule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjvp_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprimal_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    293\u001b[0m          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmust produce a pair (list or tuple of length two) representing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprimal and tangent outputs, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpair_out\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/linear_util.py:370\u001b[0m, in \u001b[0;36m_get_result_paths_thunk\u001b[0;34m(_fun, _store, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;129m@transformation_with_aux2\u001b[39m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_result_paths_thunk\u001b[39m(_fun: Callable, _store: Store, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 370\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m   result_paths \u001b[38;5;241m=\u001b[39m [_clean_keystr_arg_names(path) \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m generate_key_paths(ans)]\n\u001b[1;32m    372\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _store:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# In some instances a lu.WrappedFun is called multiple times, e.g.,\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# the bwd function in a custom_vjp\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/custom_derivatives.py:237\u001b[0m, in \u001b[0;36mcustom_jvp.defjvps.<locals>.jvp\u001b[0;34m(primals, tangents)\u001b[0m\n\u001b[1;32m    235\u001b[0m primal_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39mprimals)\n\u001b[1;32m    236\u001b[0m zeros \u001b[38;5;241m=\u001b[39m _zeros_like_pytree(primal_out)\n\u001b[0;32m--> 237\u001b[0m all_tangents_out \u001b[38;5;241m=\u001b[39m [jvp(t, primal_out, \u001b[38;5;241m*\u001b[39mprimals) \u001b[38;5;28;01mif\u001b[39;00m jvp \u001b[38;5;28;01melse\u001b[39;00m zeros\n\u001b[1;32m    238\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m t, jvp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tangents, jvps)]\n\u001b[1;32m    239\u001b[0m tangent_out \u001b[38;5;241m=\u001b[39m tree_map(_sum_tangents, primal_out, \u001b[38;5;241m*\u001b[39mall_tangents_out)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m primal_out, tangent_out\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/custom_derivatives.py:237\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    235\u001b[0m primal_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39mprimals)\n\u001b[1;32m    236\u001b[0m zeros \u001b[38;5;241m=\u001b[39m _zeros_like_pytree(primal_out)\n\u001b[0;32m--> 237\u001b[0m all_tangents_out \u001b[38;5;241m=\u001b[39m [\u001b[43mjvp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimal_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m jvp \u001b[38;5;28;01melse\u001b[39;00m zeros\n\u001b[1;32m    238\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m t, jvp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tangents, jvps)]\n\u001b[1;32m    239\u001b[0m tangent_out \u001b[38;5;241m=\u001b[39m tree_map(_sum_tangents, primal_out, \u001b[38;5;241m*\u001b[39mall_tangents_out)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m primal_out, tangent_out\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/nn/functions.py:89\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(g, ans, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mmaximum(x, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# For behavior at 0, see https://dl.acm.org/doi/10.5555/3540261.3540297\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m relu\u001b[38;5;241m.\u001b[39mdefjvps(\u001b[38;5;28;01mlambda\u001b[39;00m g, ans, x: lax\u001b[38;5;241m.\u001b[39mselect(x \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, g, \u001b[43mlax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     91\u001b[0m \u001b[38;5;129m@jax\u001b[39m\u001b[38;5;241m.\u001b[39mjit\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msquareplus\u001b[39m(x: ArrayLike, b: ArrayLike \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[1;32m     93\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Squareplus activation function.\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m  Computes the element-wise function\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    b : smoothness parameter\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# We do the same grid search as in Question 2.\n",
    "best_config, best_acc, best_loss, best_learning_curves, best_fold_results = grid_search(\n",
    "    x_train, y_train, \n",
    "    grid_search_configs, \n",
    "    k=3,\n",
    "    classification=False\n",
    ")\n",
    "\n",
    "print(\"The best configuration is:\")\n",
    "print(best_config)\n",
    "print(f\"Best K-fold Mean Accuracy: {best_acc:.2f} ({best_acc*100:.2f}%)\")\n",
    "print(f\"Best K-fold Mean Loss: {best_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c648093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training best model on full training set...\n",
      "Configuration: {'layer_widths': [1, 128, 128, 1], 'activation': 'relu', 'learning_rate': 0.1, 'batch_size': 64, 'epochs': 50}\n",
      "Epoch 0: Train Loss = 0.4503, Test Loss = 0.4529\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# We now train the best model on the full training set.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m best_config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlayer_widths\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m      8\u001b[0m }\n\u001b[0;32m---> 10\u001b[0m params, test_acc, test_loss, learning_curve \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbest_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(learning_curve[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining MSE Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 80\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(x_train, y_train, x_test, y_test, best_config, classification)\u001b[0m\n\u001b[1;32m     77\u001b[0m batches \u001b[38;5;241m=\u001b[39m get_batches(x_train, y_train, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_batch, y_batch \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[0;32m---> 80\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassification\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Evaluate periodically\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m epoch \u001b[38;5;241m==\u001b[39m epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m, in \u001b[0;36mupdate\u001b[0;34m(params, x, y, activation, lr, classification)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mUpdate function for the network parameters (basic gradient descent).\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m class_loss \u001b[38;5;28;01mif\u001b[39;00m classification \u001b[38;5;28;01melse\u001b[39;00m mse_loss\n\u001b[0;32m----> 7\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m new_params \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m p, g: p \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m g, params, grads)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_params\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:399\u001b[0m, in \u001b[0;36mgrad.<locals>.grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fun, docstr\u001b[38;5;241m=\u001b[39mdocstr, argnums\u001b[38;5;241m=\u001b[39margnums)\n\u001b[1;32m    397\u001b[0m \u001b[38;5;129m@api_boundary\u001b[39m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgrad_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 399\u001b[0m   _, g \u001b[38;5;241m=\u001b[39m \u001b[43mvalue_and_grad_f\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m g\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:470\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m   _check_input_dtype_grad(holomorphic, allow_int, leaf)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 470\u001b[0m   ans, vjp_py \u001b[38;5;241m=\u001b[39m \u001b[43m_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_partial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdyn_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    472\u001b[0m   ans, vjp_py, aux \u001b[38;5;241m=\u001b[39m _vjp(\n\u001b[1;32m    473\u001b[0m       f_partial, \u001b[38;5;241m*\u001b[39mdyn_args, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:2015\u001b[0m, in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, *primals)\u001b[0m\n\u001b[1;32m   2013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[1;32m   2014\u001b[0m   flat_fun, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun_nokwargs(fun, in_tree)\n\u001b[0;32m-> 2015\u001b[0m   out_primals, vjp \u001b[38;5;241m=\u001b[39m \u001b[43mad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2016\u001b[0m   out_tree \u001b[38;5;241m=\u001b[39m out_tree()\n\u001b[1;32m   2017\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:260\u001b[0m, in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvjp\u001b[39m(traceable: lu\u001b[38;5;241m.\u001b[39mWrappedFun, primals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    259\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 260\u001b[0m     out_primals, pvals, jaxpr, consts \u001b[38;5;241m=\u001b[39m \u001b[43mlinearize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraceable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m     out_primals, pvals, jaxpr, consts, aux \u001b[38;5;241m=\u001b[39m linearize(traceable, \u001b[38;5;241m*\u001b[39mprimals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:245\u001b[0m, in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m _, in_tree \u001b[38;5;241m=\u001b[39m tree_flatten(((primals, primals), {}))\n\u001b[1;32m    244\u001b[0m jvpfun_flat, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun(jvpfun, in_tree)\n\u001b[0;32m--> 245\u001b[0m jaxpr, out_pvals, consts \u001b[38;5;241m=\u001b[39m \u001b[43mpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_to_jaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjvpfun_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m out_primals_pvals, out_tangents_pvals \u001b[38;5;241m=\u001b[39m tree_unflatten(out_tree(), out_pvals)\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m out_primal_pval\u001b[38;5;241m.\u001b[39mis_known() \u001b[38;5;28;01mfor\u001b[39;00m out_primal_pval \u001b[38;5;129;01min\u001b[39;00m out_primals_pvals):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/profiler.py:334\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    333\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:576\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_nounits\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    574\u001b[0m fun \u001b[38;5;241m=\u001b[39m trace_to_subjaxpr_nounits(fun, trace, instantiate, fun\u001b[38;5;241m.\u001b[39mdebug_info)\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m--> 576\u001b[0m   jaxpr, (out_pvals, consts, env) \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m trace, fun\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/linear_util.py:210\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    209\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the transformed function\"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_transformed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:590\u001b[0m, in \u001b[0;36mtrace_to_subjaxpr_nounits\u001b[0;34m(f, trace, instantiate, debug_info, in_pvals)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation2\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrace_to_subjaxpr_nounits\u001b[39m(\n\u001b[1;32m    584\u001b[0m     f: Callable,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    587\u001b[0m     debug_info: core\u001b[38;5;241m.\u001b[39mDebugInfo,\n\u001b[1;32m    588\u001b[0m     in_pvals: Sequence[PartialVal]):\n\u001b[1;32m    589\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(pv, PartialVal) \u001b[38;5;28;01mfor\u001b[39;00m pv \u001b[38;5;129;01min\u001b[39;00m in_pvals), in_pvals\n\u001b[0;32m--> 590\u001b[0m   out_tracers, jaxpr, out_consts, env \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_to_subjaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m      \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstantiate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug_info\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m   out_pvals \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39mpval \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m out_tracers]\n\u001b[1;32m    593\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m out_tracers\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:623\u001b[0m, in \u001b[0;36m_trace_to_subjaxpr_nounits\u001b[0;34m(f, trace, instantiate, in_pvals, debug_info)\u001b[0m\n\u001b[1;32m    621\u001b[0m in_args \u001b[38;5;241m=\u001b[39m merge_lists(in_knowns, in_tracers, in_consts)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m--> 623\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ans, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)), (\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected return type when tracing function to jaxpr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mans\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, core\u001b[38;5;241m.\u001b[39mTracer) \u001b[38;5;129;01mor\u001b[39;00m core\u001b[38;5;241m.\u001b[39mvalid_jaxtype(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m ans), (\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot unexpected return type when tracing function to jaxpr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mans\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api_util.py:73\u001b[0m, in \u001b[0;36mflatten_fun\u001b[0;34m(f, store, in_tree, *args_flat)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_with_aux2\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflatten_fun\u001b[39m(f: Callable, store: lu\u001b[38;5;241m.\u001b[39mStore,\n\u001b[1;32m     71\u001b[0m                 in_tree: PyTreeDef, \u001b[38;5;241m*\u001b[39margs_flat):\n\u001b[1;32m     72\u001b[0m   py_args, py_kwargs \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, args_flat)\n\u001b[0;32m---> 73\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m   ans, out_tree \u001b[38;5;241m=\u001b[39m tree_flatten(ans)\n\u001b[1;32m     75\u001b[0m   store\u001b[38;5;241m.\u001b[39mstore(out_tree)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:80\u001b[0m, in \u001b[0;36mjvpfun\u001b[0;34m(f, instantiate, transform_stack, primals, tangents)\u001b[0m\n\u001b[1;32m     77\u001b[0m ctx \u001b[38;5;241m=\u001b[39m (source_info_util\u001b[38;5;241m.\u001b[39mtransform_name_stack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjvp\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m transform_stack\n\u001b[1;32m     78\u001b[0m        \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext())\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx:\n\u001b[0;32m---> 80\u001b[0m   out_primals, out_tangents \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtangents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(instantiate) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     82\u001b[0m   instantiate \u001b[38;5;241m=\u001b[39m [instantiate] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(out_tangents)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:120\u001b[0m, in \u001b[0;36mjvp_subtrace\u001b[0;34m(f, tag, primals, tangents)\u001b[0m\n\u001b[1;32m    117\u001b[0m   in_tracers \u001b[38;5;241m=\u001b[39m [maybe_jvp_tracer(trace, x, t)\n\u001b[1;32m    118\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m x, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(primals, tangents)]\n\u001b[1;32m    119\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(trace):\n\u001b[0;32m--> 120\u001b[0m     ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_tracers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m   out \u001b[38;5;241m=\u001b[39m unzip2(\u001b[38;5;28mmap\u001b[39m(trace\u001b[38;5;241m.\u001b[39mto_primal_tangent_pair, ans))\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api_util.py:90\u001b[0m, in \u001b[0;36mflatten_fun_nokwargs\u001b[0;34m(f, store, in_tree, *args_flat)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_with_aux2\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflatten_fun_nokwargs\u001b[39m(f: Callable, store: lu\u001b[38;5;241m.\u001b[39mStore,\n\u001b[1;32m     88\u001b[0m                          in_tree: PyTreeDef, \u001b[38;5;241m*\u001b[39margs_flat):\n\u001b[1;32m     89\u001b[0m   py_args \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, args_flat)\n\u001b[0;32m---> 90\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m   ans, out_tree \u001b[38;5;241m=\u001b[39m tree_flatten(ans)\n\u001b[1;32m     92\u001b[0m   store\u001b[38;5;241m.\u001b[39mstore(out_tree)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api_util.py:284\u001b[0m, in \u001b[0;36m_argnums_partial\u001b[0;34m(_fun, _dyn_argnums, _fixed_args, *dyn_args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m args \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mnext\u001b[39m(fixed_args_)\u001b[38;5;241m.\u001b[39mval \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m sentinel \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(fixed_args_, sentinel) \u001b[38;5;129;01mis\u001b[39;00m sentinel\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/linear_util.py:370\u001b[0m, in \u001b[0;36m_get_result_paths_thunk\u001b[0;34m(_fun, _store, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;129m@transformation_with_aux2\u001b[39m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_result_paths_thunk\u001b[39m(_fun: Callable, _store: Store, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 370\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m   result_paths \u001b[38;5;241m=\u001b[39m [_clean_keystr_arg_names(path) \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m generate_key_paths(ans)]\n\u001b[1;32m    372\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _store:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# In some instances a lu.WrappedFun is called multiple times, e.g.,\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# the bwd function in a custom_vjp\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(params, x, y, activation)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mMSE loss function for the network.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m batched_forward \u001b[38;5;241m=\u001b[39m vmap(forward, in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m----> 7\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mbatched_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m jnp\u001b[38;5;241m.\u001b[39mmean((preds \u001b[38;5;241m-\u001b[39m y) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/api.py:1015\u001b[0m, in \u001b[0;36mvmap.<locals>.vmap_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1013\u001b[0m   axis_data \u001b[38;5;241m=\u001b[39m batching\u001b[38;5;241m.\u001b[39mAxisData(axis_name, axis_size_, spmd_axis_name,\n\u001b[1;32m   1014\u001b[0m                                 explicit_mesh_axis)\n\u001b[0;32m-> 1015\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mbatching\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m      \u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_axes_flat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvmap out_axes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_axes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m batching\u001b[38;5;241m.\u001b[39mSpecMatchError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1020\u001b[0m   out_axes_flat \u001b[38;5;241m=\u001b[39m flatten_axes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvmap out_axes\u001b[39m\u001b[38;5;124m\"\u001b[39m, out_tree(), out_axes)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/linear_util.py:210\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    209\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the transformed function\"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_transformed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/batching.py:604\u001b[0m, in \u001b[0;36m_batch_outer\u001b[0;34m(f, axis_data, in_dims, *in_vals)\u001b[0m\n\u001b[1;32m    602\u001b[0m tag \u001b[38;5;241m=\u001b[39m TraceTag()\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m source_info_util\u001b[38;5;241m.\u001b[39mtransform_name_stack(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvmap\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 604\u001b[0m   outs, trace \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_vals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mensure_no_leaks(trace): \u001b[38;5;28;01mdel\u001b[39;00m trace\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/batching.py:619\u001b[0m, in \u001b[0;36m_batch_inner\u001b[0;34m(f, axis_data, out_dim_dests, tag, in_dims, *in_vals)\u001b[0m\n\u001b[1;32m    615\u001b[0m   in_tracers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(partial(to_elt, trace, idx), in_vals, in_dims)\n\u001b[1;32m    616\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m (core\u001b[38;5;241m.\u001b[39mset_current_trace(trace),\n\u001b[1;32m    617\u001b[0m         core\u001b[38;5;241m.\u001b[39mextend_axis_env_nd([(axis_data\u001b[38;5;241m.\u001b[39mname, axis_data\u001b[38;5;241m.\u001b[39msize)]),\n\u001b[1;32m    618\u001b[0m         core\u001b[38;5;241m.\u001b[39madd_spmd_axis_names(axis_data\u001b[38;5;241m.\u001b[39mspmd_name)):\n\u001b[0;32m--> 619\u001b[0m     outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_tracers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    621\u001b[0m out_dim_dests \u001b[38;5;241m=\u001b[39m out_dim_dests() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(out_dim_dests) \u001b[38;5;28;01melse\u001b[39;00m out_dim_dests\n\u001b[1;32m    622\u001b[0m out_vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(partial(from_elt, trace, axis_data\u001b[38;5;241m.\u001b[39msize,\n\u001b[1;32m    623\u001b[0m                        axis_data\u001b[38;5;241m.\u001b[39mexplicit_mesh_axis),\n\u001b[1;32m    624\u001b[0m                \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(outs)), outs, out_dim_dests)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/batching.py:339\u001b[0m, in \u001b[0;36mflatten_fun_for_vmap\u001b[0;34m(f, store, in_tree, *args_flat)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;129m@lu\u001b[39m\u001b[38;5;241m.\u001b[39mtransformation_with_aux2\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mflatten_fun_for_vmap\u001b[39m(f: Callable,\n\u001b[1;32m    337\u001b[0m                          store: lu\u001b[38;5;241m.\u001b[39mStore, in_tree: PyTreeDef, \u001b[38;5;241m*\u001b[39margs_flat):\n\u001b[1;32m    338\u001b[0m   py_args, py_kwargs \u001b[38;5;241m=\u001b[39m tree_unflatten(in_tree, args_flat)\n\u001b[0;32m--> 339\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpy_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m   ans, out_tree \u001b[38;5;241m=\u001b[39m tree_flatten(ans, is_leaf\u001b[38;5;241m=\u001b[39mis_vmappable)\n\u001b[1;32m    341\u001b[0m   store\u001b[38;5;241m.\u001b[39mstore(out_tree)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/linear_util.py:370\u001b[0m, in \u001b[0;36m_get_result_paths_thunk\u001b[0;34m(_fun, _store, *args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;129m@transformation_with_aux2\u001b[39m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_result_paths_thunk\u001b[39m(_fun: Callable, _store: Store, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 370\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[43m_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m   result_paths \u001b[38;5;241m=\u001b[39m [_clean_keystr_arg_names(path) \u001b[38;5;28;01mfor\u001b[39;00m path, _ \u001b[38;5;129;01min\u001b[39;00m generate_key_paths(ans)]\n\u001b[1;32m    372\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m _store:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;66;03m# In some instances a lu.WrappedFun is called multiple times, e.g.,\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# the bwd function in a custom_vjp\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 16\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(params, x, activation)\u001b[0m\n\u001b[1;32m     13\u001b[0m activation \u001b[38;5;241m=\u001b[39m activations[activation]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m params[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m---> 16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m layer[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m activation(x)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# output layer, no activation function\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:1060\u001b[0m, in \u001b[0;36m_forward_operator_to_aval.<locals>.op\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mop\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m-> 1060\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:579\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    577\u001b[0m args \u001b[38;5;241m=\u001b[39m (other, \u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m swap \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m    578\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[0;32m--> 579\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(other) \u001b[38;5;129;01min\u001b[39;00m _rejected_binop_types:\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/pjit.py:341\u001b[0m, in \u001b[0;36m_cpp_pjit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mno_tracing\u001b[38;5;241m.\u001b[39mvalue:\n\u001b[1;32m    337\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mre-tracing function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjit_info\u001b[38;5;241m.\u001b[39mfun_sourceinfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    338\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`jit`, but \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno_tracing\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    340\u001b[0m (outs, out_flat, out_tree, args_flat, jaxpr, attrs_tracked, executable,\n\u001b[0;32m--> 341\u001b[0m  pgle_profiler) \u001b[38;5;241m=\u001b[39m \u001b[43m_python_pjit_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m maybe_fastpath_data \u001b[38;5;241m=\u001b[39m _get_fastpath_data(\n\u001b[1;32m    344\u001b[0m     executable, out_tree, args_flat, out_flat, attrs_tracked, jaxpr\u001b[38;5;241m.\u001b[39meffects,\n\u001b[1;32m    345\u001b[0m     jaxpr\u001b[38;5;241m.\u001b[39mconsts, jit_info\u001b[38;5;241m.\u001b[39mabstracted_axes,\n\u001b[1;32m    346\u001b[0m     pgle_profiler)\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs, maybe_fastpath_data, _need_to_rebuild_with_fdo(pgle_profiler)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/pjit.py:197\u001b[0m, in \u001b[0;36m_python_pjit_helper\u001b[0;34m(fun, jit_info, *args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m   out_flat, compiled, profiler \u001b[38;5;241m=\u001b[39m _pjit_call_impl_python(\u001b[38;5;241m*\u001b[39margs_flat, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mp\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m   out_flat \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m   compiled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    199\u001b[0m   profiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:502\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    501\u001b[0m   args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_canonicalization \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(canonicalize_value, args)\n\u001b[0;32m--> 502\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:520\u001b[0m, in \u001b[0;36mPrimitive._true_bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    518\u001b[0m trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(eval_trace)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 520\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m   trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(prev_trace)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:525\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 525\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/batching.py:488\u001b[0m, in \u001b[0;36mBatchTrace.process_primitive\u001b[0;34m(self, p, tracers, params)\u001b[0m\n\u001b[1;32m    486\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_trace):\n\u001b[0;32m--> 488\u001b[0m       val_out, dim_out \u001b[38;5;241m=\u001b[39m \u001b[43mfancy_primitive_batchers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvals_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdims_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m args_not_mapped:\n\u001b[1;32m    491\u001b[0m   \u001b[38;5;66;03m# no-op shortcut\u001b[39;00m\n\u001b[1;32m    492\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m p\u001b[38;5;241m.\u001b[39mbind_with_trace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_trace, vals_in, params)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/pjit.py:1964\u001b[0m, in \u001b[0;36m_pjit_batcher\u001b[0;34m(axis_data, vals_in, dims_in, jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, name, keep_unused, inline, compiler_options_kvs)\u001b[0m\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mall\u001b[39m(l \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m in_layouts) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1960\u001b[0m         \u001b[38;5;28mall\u001b[39m(l \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m out_layouts)):\n\u001b[1;32m   1961\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1962\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConcrete layouts are not supported for vmap(jit).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1964\u001b[0m vals_out \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1965\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvals_in\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1966\u001b[0m \u001b[43m  \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_jaxpr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1967\u001b[0m \u001b[43m  \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1968\u001b[0m \u001b[43m  \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m  \u001b[49m\u001b[43min_layouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_layouts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1970\u001b[0m \u001b[43m  \u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_layouts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[43m  \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1972\u001b[0m \u001b[43m  \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1973\u001b[0m \u001b[43m  \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1974\u001b[0m \u001b[43m  \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1975\u001b[0m \u001b[43m  \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1976\u001b[0m \u001b[43m  \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1978\u001b[0m resolved_axes_out \u001b[38;5;241m=\u001b[39m batching\u001b[38;5;241m.\u001b[39mresolve_ragged_axes_against_inputs_outputs(\n\u001b[1;32m   1979\u001b[0m     vals_in, vals_out, axes_out)\n\u001b[1;32m   1980\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vals_out, resolved_axes_out\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:502\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    501\u001b[0m   args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_canonicalization \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(canonicalize_value, args)\n\u001b[0;32m--> 502\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:520\u001b[0m, in \u001b[0;36mPrimitive._true_bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    518\u001b[0m trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(eval_trace)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 520\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m   trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(prev_trace)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:525\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 525\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:440\u001b[0m, in \u001b[0;36mJVPTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    438\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mset_current_trace(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_trace):\n\u001b[0;32m--> 440\u001b[0m   primal_out, tangent_out \u001b[38;5;241m=\u001b[39m \u001b[43mjvp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprimals_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtangents_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m primitive\u001b[38;5;241m.\u001b[39mmultiple_results:\n\u001b[1;32m    443\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [maybe_jvp_tracer(\u001b[38;5;28mself\u001b[39m, x, t) \u001b[38;5;28;01mfor\u001b[39;00m x, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(primal_out, tangent_out)]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/pjit.py:2050\u001b[0m, in \u001b[0;36m_pjit_jvp\u001b[0;34m(primals_in, tangents_in, jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, name, keep_unused, inline, compiler_options_kvs)\u001b[0m\n\u001b[1;32m   2048\u001b[0m _filter_zeros_in \u001b[38;5;241m=\u001b[39m partial(_filter_zeros, is_nz_tangents_in)\n\u001b[1;32m   2049\u001b[0m _filter_zeros_out \u001b[38;5;241m=\u001b[39m partial(_filter_zeros, is_nz_tangents_out)\n\u001b[0;32m-> 2050\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpjit_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2051\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_filter_zeros_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtangents_in\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjaxpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjaxpr_jvp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_filter_zeros_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_shardings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_shardings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_filter_zeros_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_shardings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_layouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43min_layouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_filter_zeros_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_layouts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_layouts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_filter_zeros_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_layouts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresource_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresource_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdonated_invars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_filter_zeros_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdonated_invars\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2060\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2061\u001b[0m \u001b[43m    \u001b[49m\u001b[43minline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompiler_options_kvs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2064\u001b[0m primals_out, tangents_out \u001b[38;5;241m=\u001b[39m split_list(outputs, [\u001b[38;5;28mlen\u001b[39m(jaxpr\u001b[38;5;241m.\u001b[39mjaxpr\u001b[38;5;241m.\u001b[39moutvars)])\n\u001b[1;32m   2065\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(primals_out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(jaxpr\u001b[38;5;241m.\u001b[39mjaxpr\u001b[38;5;241m.\u001b[39moutvars)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:502\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    501\u001b[0m   args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_canonicalization \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(canonicalize_value, args)\n\u001b[0;32m--> 502\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_true_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:520\u001b[0m, in \u001b[0;36mPrimitive._true_bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    518\u001b[0m trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(eval_trace)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 520\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m   trace_ctx\u001b[38;5;241m.\u001b[39mset_trace(prev_trace)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/core.py:525\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 525\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:209\u001b[0m, in \u001b[0;36mJaxprTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m primitive \u001b[38;5;129;01min\u001b[39;00m custom_partial_eval_rules:\n\u001b[1;32m    208\u001b[0m   tracers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_jaxpr_tracer, tracers)\n\u001b[0;32m--> 209\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcustom_partial_eval_rules\u001b[49m\u001b[43m[\u001b[49m\u001b[43mprimitive\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_process_primitive(primitive, tracers, params)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/pjit.py:2238\u001b[0m, in \u001b[0;36m_pjit_partial_eval\u001b[0;34m(trace, jaxpr, in_shardings, out_shardings, in_layouts, out_layouts, resource_env, donated_invars, name, keep_unused, inline, compiler_options_kvs, *in_tracers)\u001b[0m\n\u001b[1;32m   2233\u001b[0m unknown_out_avals \u001b[38;5;241m=\u001b[39m unknown_jaxpr\u001b[38;5;241m.\u001b[39mout_avals\n\u001b[1;32m   2234\u001b[0m unknown_tracers_out \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   2235\u001b[0m     pe\u001b[38;5;241m.\u001b[39mJaxprTracer(trace, pe\u001b[38;5;241m.\u001b[39mPartialVal\u001b[38;5;241m.\u001b[39munknown(aval), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   2236\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m aval \u001b[38;5;129;01min\u001b[39;00m unknown_out_avals\n\u001b[1;32m   2237\u001b[0m ]\n\u001b[0;32m-> 2238\u001b[0m eqn \u001b[38;5;241m=\u001b[39m \u001b[43mpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_eqn_recipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43munknown_tracers_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresidual_tracers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2239\u001b[0m \u001b[43m                        \u001b[49m\u001b[43munknown_tracers_out\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2240\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpjit_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2241\u001b[0m \u001b[43m                        \u001b[49m\u001b[43munknown_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m                        \u001b[49m\u001b[43munknown_jaxpr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msource_info_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m unknown_tracers_out: t\u001b[38;5;241m.\u001b[39mrecipe \u001b[38;5;241m=\u001b[39m eqn\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m merge_lists(unknown_outs, known_out_vals, unknown_tracers_out)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/jax_env/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:739\u001b[0m, in \u001b[0;36mnew_eqn_recipe\u001b[0;34m(in_tracers, out_tracers, primitive, params, effects, source_info, ctx)\u001b[0m\n\u001b[1;32m    733\u001b[0m out_avals \u001b[38;5;241m=\u001b[39m [t\u001b[38;5;241m.\u001b[39maval \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m out_tracers]\n\u001b[1;32m    734\u001b[0m ctx \u001b[38;5;241m=\u001b[39m ctx \u001b[38;5;129;01mor\u001b[39;00m JaxprEqnContext(\n\u001b[1;32m    735\u001b[0m     compute_on\u001b[38;5;241m.\u001b[39mcurrent_compute_type(),\n\u001b[1;32m    736\u001b[0m     config\u001b[38;5;241m.\u001b[39mthreefry_partitionable\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[1;32m    737\u001b[0m     xla_metadata_lib\u001b[38;5;241m.\u001b[39mcurrent_xla_metadata(),\n\u001b[1;32m    738\u001b[0m )\n\u001b[0;32m--> 739\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mJaxprEqnRecipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43min_tracers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_tracers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout_avals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimitive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# We now train the best model on the full training set.\n",
    "best_config = {\n",
    "    'layer_widths': [1, 128, 128, 1],\n",
    "    'activation': 'relu',\n",
    "    'learning_rate': 0.1,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 50\n",
    "}\n",
    "\n",
    "params, test_acc, test_loss, learning_curve = train_model(\n",
    "    x_train, y_train, x_test, y_test, best_config, classification=False\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(learning_curve['train_loss'], label='Training MSE Loss')\n",
    "plt.plot(learning_curve['test_loss'], label='Test MSE Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "save_params(params, filename=f'../assets/{k}_reg_params.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ef28ecbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x364a37fd0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the true function and the predicted function\n",
    "y_pred = forward(params, x_test, best_config['activation'])\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(x_test, y_test, label='True Function')\n",
    "plt.plot(x_test, y_pred, label='Predicted Function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b26135db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search configurations for finding best k\n",
    "grid_search_configs = {\n",
    "    'architectures': [\n",
    "        # hidden layers\n",
    "        [1, 128, 1],\n",
    "        [1, 512, 1],\n",
    "        [1, 128, 128, 1],\n",
    "    ],\n",
    "    \n",
    "    # Activation functions\n",
    "    'activations': ['relu'],\n",
    "    \n",
    "    # Learning rates\n",
    "    'learning_rates': [0.1],\n",
    "    \n",
    "    # Batch sizes\n",
    "    'batch_sizes': [64, 128],\n",
    "    \n",
    "    # Epochs\n",
    "    'epochs': [20]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d482da",
   "metadata": {},
   "source": [
    "(b) Try to fit $f_k$ for different values of $k$. How do you need to change the hyperparameters when increasing $k$? Discuss your findings. How far can you increase $k$?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4424d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing k = 1\n",
      "Total configurations to test: 6\n",
      "With k=3 folds, total training runs: 18\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[1/6] Testing configuration:\n",
      "Architecture: [1, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.0365, Val Loss = 0.0376\n",
      "Fold 2, Epoch 0: Train Loss = 0.1466, Val Loss = 0.1445\n",
      "Fold 3, Epoch 0: Train Loss = 0.0382, Val Loss = 0.0380\n",
      "Mean Validation Accuracy: 0.0541 (5.41%)\n",
      "Mean Validation Loss: 0.0541\n",
      "New best configuration!\n",
      "\n",
      "[2/6] Testing configuration:\n",
      "Architecture: [1, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.4979, Val Loss = 0.5058\n",
      "Fold 2, Epoch 0: Train Loss = 0.5025, Val Loss = 0.4993\n",
      "Fold 3, Epoch 0: Train Loss = 0.5035, Val Loss = 0.4988\n",
      "Mean Validation Accuracy: 0.2303 (23.03%)\n",
      "Mean Validation Loss: 0.2303\n",
      "New best configuration!\n",
      "\n",
      "[3/6] Testing configuration:\n",
      "Architecture: [1, 512, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.1586, Val Loss = 0.1619\n",
      "Fold 2, Epoch 0: Train Loss = 0.5016, Val Loss = 0.4983\n",
      "Fold 3, Epoch 0: Train Loss = 0.5033, Val Loss = 0.4986\n",
      "Mean Validation Accuracy: 0.3790 (37.90%)\n",
      "Mean Validation Loss: 0.3790\n",
      "New best configuration!\n",
      "\n",
      "[4/6] Testing configuration:\n",
      "Architecture: [1, 512, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.1767, Val Loss = 0.1798\n",
      "Fold 2, Epoch 0: Train Loss = 0.5015, Val Loss = 0.4984\n",
      "Fold 3, Epoch 0: Train Loss = 0.5030, Val Loss = 0.4983\n",
      "Mean Validation Accuracy: 0.3820 (38.20%)\n",
      "Mean Validation Loss: 0.3820\n",
      "New best configuration!\n",
      "\n",
      "[5/6] Testing configuration:\n",
      "Architecture: [1, 128, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.0182, Val Loss = 0.0185\n",
      "Fold 2, Epoch 0: Train Loss = 0.0089, Val Loss = 0.0086\n",
      "Fold 3, Epoch 0: Train Loss = 0.0874, Val Loss = 0.0866\n",
      "Mean Validation Accuracy: 0.0002 (0.02%)\n",
      "Mean Validation Loss: 0.0002\n",
      "\n",
      "[6/6] Testing configuration:\n",
      "Architecture: [1, 128, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.0305, Val Loss = 0.0316\n",
      "Fold 2, Epoch 0: Train Loss = 0.0102, Val Loss = 0.0099\n",
      "Fold 3, Epoch 0: Train Loss = 0.0966, Val Loss = 0.0957\n",
      "Mean Validation Accuracy: 0.0014 (0.14%)\n",
      "Mean Validation Loss: 0.0014\n",
      "\n",
      "================================================================================\n",
      "Grid Search Complete!\n",
      "Best Configuration:\n",
      "Architecture: [1, 512, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Best Mean Validation Accuracy: 0.3820 (38.20%)\n",
      "================================================================================\n",
      "Analyzing k = 5\n",
      "Total configurations to test: 6\n",
      "With k=3 folds, total training runs: 18\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[1/6] Testing configuration:\n",
      "Architecture: [1, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.4782, Val Loss = 0.4690\n",
      "Fold 2, Epoch 0: Train Loss = 0.4587, Val Loss = 0.4757\n",
      "Fold 3, Epoch 0: Train Loss = 0.5012, Val Loss = 0.4976\n",
      "Mean Validation Accuracy: 0.4132 (41.32%)\n",
      "Mean Validation Loss: 0.4132\n",
      "New best configuration!\n",
      "\n",
      "[2/6] Testing configuration:\n",
      "Architecture: [1, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.5015, Val Loss = 0.4904\n",
      "Fold 2, Epoch 0: Train Loss = 0.4616, Val Loss = 0.4782\n",
      "Fold 3, Epoch 0: Train Loss = 0.5006, Val Loss = 0.4968\n",
      "Mean Validation Accuracy: 0.4629 (46.29%)\n",
      "Mean Validation Loss: 0.4629\n",
      "New best configuration!\n",
      "\n",
      "[3/6] Testing configuration:\n",
      "Architecture: [1, 512, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.4790, Val Loss = 0.4703\n",
      "Fold 2, Epoch 0: Train Loss = 0.4935, Val Loss = 0.5098\n",
      "Fold 3, Epoch 0: Train Loss = 0.6608, Val Loss = 0.6683\n",
      "Mean Validation Accuracy: 0.4879 (48.79%)\n",
      "Mean Validation Loss: 0.4879\n",
      "New best configuration!\n",
      "\n",
      "[4/6] Testing configuration:\n",
      "Architecture: [1, 512, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.4795, Val Loss = 0.4698\n",
      "Fold 2, Epoch 0: Train Loss = 0.4937, Val Loss = 0.5100\n",
      "Fold 3, Epoch 0: Train Loss = 0.5014, Val Loss = 0.4974\n",
      "Mean Validation Accuracy: 0.4643 (46.43%)\n",
      "Mean Validation Loss: 0.4643\n",
      "\n",
      "[5/6] Testing configuration:\n",
      "Architecture: [1, 128, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.4032, Val Loss = 0.3976\n",
      "Fold 2, Epoch 0: Train Loss = 0.3981, Val Loss = 0.4083\n",
      "Fold 3, Epoch 0: Train Loss = 0.3564, Val Loss = 0.3560\n",
      "Mean Validation Accuracy: 0.1461 (14.61%)\n",
      "Mean Validation Loss: 0.1461\n",
      "\n",
      "[6/6] Testing configuration:\n",
      "Architecture: [1, 128, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.4400, Val Loss = 0.4336\n",
      "Fold 2, Epoch 0: Train Loss = 0.4266, Val Loss = 0.4417\n",
      "Fold 3, Epoch 0: Train Loss = 0.3874, Val Loss = 0.3893\n",
      "Mean Validation Accuracy: 0.1459 (14.59%)\n",
      "Mean Validation Loss: 0.1459\n",
      "\n",
      "================================================================================\n",
      "Grid Search Complete!\n",
      "Best Configuration:\n",
      "Architecture: [1, 512, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Best Mean Validation Accuracy: 0.4879 (48.79%)\n",
      "================================================================================\n",
      "Analyzing k = 10\n",
      "Total configurations to test: 6\n",
      "With k=3 folds, total training runs: 18\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[1/6] Testing configuration:\n",
      "Architecture: [1, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.4851, Val Loss = 0.4833\n",
      "Fold 2, Epoch 0: Train Loss = 0.4995, Val Loss = 0.4986\n",
      "Fold 3, Epoch 0: Train Loss = 0.4835, Val Loss = 0.4909\n",
      "Mean Validation Accuracy: 0.4834 (48.34%)\n",
      "Mean Validation Loss: 0.4834\n",
      "New best configuration!\n",
      "\n",
      "[2/6] Testing configuration:\n",
      "Architecture: [1, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.4960, Val Loss = 0.4950\n",
      "Fold 2, Epoch 0: Train Loss = 0.4896, Val Loss = 0.4874\n",
      "Fold 3, Epoch 0: Train Loss = 0.4825, Val Loss = 0.4893\n",
      "Mean Validation Accuracy: 0.4859 (48.59%)\n",
      "Mean Validation Loss: 0.4859\n",
      "New best configuration!\n",
      "\n",
      "[3/6] Testing configuration:\n",
      "Architecture: [1, 512, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.5418, Val Loss = 0.5432\n",
      "Fold 2, Epoch 0: Train Loss = 0.5057, Val Loss = 0.5049\n",
      "Fold 3, Epoch 0: Train Loss = 0.5017, Val Loss = 0.5063\n",
      "Mean Validation Accuracy: 0.4986 (49.86%)\n",
      "Mean Validation Loss: 0.4986\n",
      "New best configuration!\n",
      "\n",
      "[4/6] Testing configuration:\n",
      "Architecture: [1, 512, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.4954, Val Loss = 0.4947\n",
      "Fold 2, Epoch 0: Train Loss = 0.5038, Val Loss = 0.5025\n",
      "Fold 3, Epoch 0: Train Loss = 0.7608, Val Loss = 0.7762\n",
      "Mean Validation Accuracy: 0.5084 (50.84%)\n",
      "Mean Validation Loss: 0.5084\n",
      "New best configuration!\n",
      "\n",
      "[5/6] Testing configuration:\n",
      "Architecture: [1, 128, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.4828, Val Loss = 0.4809\n",
      "Fold 2, Epoch 0: Train Loss = 0.5016, Val Loss = 0.4996\n",
      "Fold 3, Epoch 0: Train Loss = 0.4779, Val Loss = 0.4845\n",
      "Mean Validation Accuracy: 0.3201 (32.01%)\n",
      "Mean Validation Loss: 0.3201\n",
      "\n",
      "[6/6] Testing configuration:\n",
      "Architecture: [1, 128, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.4874, Val Loss = 0.4862\n",
      "Fold 2, Epoch 0: Train Loss = 0.4888, Val Loss = 0.4878\n",
      "Fold 3, Epoch 0: Train Loss = 0.4851, Val Loss = 0.4919\n",
      "Mean Validation Accuracy: 0.4182 (41.82%)\n",
      "Mean Validation Loss: 0.4182\n",
      "\n",
      "================================================================================\n",
      "Grid Search Complete!\n",
      "Best Configuration:\n",
      "Architecture: [1, 512, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Best Mean Validation Accuracy: 0.5084 (50.84%)\n",
      "================================================================================\n",
      "Analyzing k = 20\n",
      "Total configurations to test: 6\n",
      "With k=3 folds, total training runs: 18\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[1/6] Testing configuration:\n",
      "Architecture: [1, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.5007, Val Loss = 0.5001\n",
      "Fold 2, Epoch 0: Train Loss = 0.5009, Val Loss = 0.5000\n",
      "Fold 3, Epoch 0: Train Loss = 0.5007, Val Loss = 0.5039\n",
      "Mean Validation Accuracy: 0.4995 (49.95%)\n",
      "Mean Validation Loss: 0.4995\n",
      "New best configuration!\n",
      "\n",
      "[2/6] Testing configuration:\n",
      "Architecture: [1, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.5091, Val Loss = 0.5105\n",
      "Fold 2, Epoch 0: Train Loss = 0.4985, Val Loss = 0.4980\n",
      "Fold 3, Epoch 0: Train Loss = 0.4943, Val Loss = 0.4967\n",
      "Mean Validation Accuracy: 0.4967 (49.67%)\n",
      "Mean Validation Loss: 0.4967\n",
      "\n",
      "[3/6] Testing configuration:\n",
      "Architecture: [1, 512, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.4995, Val Loss = 0.4977\n",
      "Fold 2, Epoch 0: Train Loss = 0.5000, Val Loss = 0.4992\n",
      "Fold 3, Epoch 0: Train Loss = 0.5003, Val Loss = 0.5034\n",
      "Mean Validation Accuracy: 0.4999 (49.99%)\n",
      "Mean Validation Loss: 0.4999\n",
      "New best configuration!\n",
      "\n",
      "[4/6] Testing configuration:\n",
      "Architecture: [1, 512, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.5004, Val Loss = 0.4974\n",
      "Fold 2, Epoch 0: Train Loss = 0.4989, Val Loss = 0.4985\n",
      "Fold 3, Epoch 0: Train Loss = 0.5059, Val Loss = 0.5104\n",
      "Mean Validation Accuracy: 0.5008 (50.08%)\n",
      "Mean Validation Loss: 0.5008\n",
      "New best configuration!\n",
      "\n",
      "[5/6] Testing configuration:\n",
      "Architecture: [1, 128, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.4989, Val Loss = 0.4971\n",
      "Fold 2, Epoch 0: Train Loss = 0.4980, Val Loss = 0.4974\n",
      "Fold 3, Epoch 0: Train Loss = 0.4972, Val Loss = 0.5020\n",
      "Mean Validation Accuracy: 0.4811 (48.11%)\n",
      "Mean Validation Loss: 0.4811\n",
      "\n",
      "[6/6] Testing configuration:\n",
      "Architecture: [1, 128, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.5024, Val Loss = 0.4992\n",
      "Fold 2, Epoch 0: Train Loss = 0.4987, Val Loss = 0.4990\n",
      "Fold 3, Epoch 0: Train Loss = 0.5027, Val Loss = 0.5072\n",
      "Mean Validation Accuracy: 0.4928 (49.28%)\n",
      "Mean Validation Loss: 0.4928\n",
      "\n",
      "================================================================================\n",
      "Grid Search Complete!\n",
      "Best Configuration:\n",
      "Architecture: [1, 512, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Best Mean Validation Accuracy: 0.5008 (50.08%)\n",
      "================================================================================\n",
      "Analyzing k = 100\n",
      "Total configurations to test: 6\n",
      "With k=3 folds, total training runs: 18\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[1/6] Testing configuration:\n",
      "Architecture: [1, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.5002, Val Loss = 0.5078\n",
      "Fold 2, Epoch 0: Train Loss = 0.5017, Val Loss = 0.5009\n",
      "Fold 3, Epoch 0: Train Loss = 0.5038, Val Loss = 0.4972\n",
      "Mean Validation Accuracy: 0.5018 (50.18%)\n",
      "Mean Validation Loss: 0.5018\n",
      "New best configuration!\n",
      "\n",
      "[2/6] Testing configuration:\n",
      "Architecture: [1, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.5001, Val Loss = 0.5081\n",
      "Fold 2, Epoch 0: Train Loss = 0.5019, Val Loss = 0.5007\n",
      "Fold 3, Epoch 0: Train Loss = 0.5036, Val Loss = 0.4974\n",
      "Mean Validation Accuracy: 0.5018 (50.18%)\n",
      "Mean Validation Loss: 0.5018\n",
      "New best configuration!\n",
      "\n",
      "[3/6] Testing configuration:\n",
      "Architecture: [1, 512, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.5361, Val Loss = 0.5420\n",
      "Fold 2, Epoch 0: Train Loss = 0.5026, Val Loss = 0.5007\n",
      "Fold 3, Epoch 0: Train Loss = 0.5038, Val Loss = 0.4973\n",
      "Mean Validation Accuracy: 0.5015 (50.15%)\n",
      "Mean Validation Loss: 0.5015\n",
      "\n",
      "[4/6] Testing configuration:\n",
      "Architecture: [1, 512, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.5019, Val Loss = 0.5082\n",
      "Fold 2, Epoch 0: Train Loss = 0.5281, Val Loss = 0.5219\n",
      "Fold 3, Epoch 0: Train Loss = 0.5036, Val Loss = 0.4974\n",
      "Mean Validation Accuracy: 0.5123 (51.23%)\n",
      "Mean Validation Loss: 0.5123\n",
      "New best configuration!\n",
      "\n",
      "[5/6] Testing configuration:\n",
      "Architecture: [1, 128, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 64\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.4997, Val Loss = 0.5073\n",
      "Fold 2, Epoch 0: Train Loss = 0.5022, Val Loss = 0.5009\n",
      "Fold 3, Epoch 0: Train Loss = 0.5037, Val Loss = 0.4973\n",
      "Mean Validation Accuracy: 0.5018 (50.18%)\n",
      "Mean Validation Loss: 0.5018\n",
      "\n",
      "[6/6] Testing configuration:\n",
      "Architecture: [1, 128, 128, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Fold 1, Epoch 0: Train Loss = 0.4994, Val Loss = 0.5070\n",
      "Fold 2, Epoch 0: Train Loss = 0.5041, Val Loss = 0.5017\n",
      "Fold 3, Epoch 0: Train Loss = 0.5039, Val Loss = 0.4976\n",
      "Mean Validation Accuracy: 0.5018 (50.18%)\n",
      "Mean Validation Loss: 0.5018\n",
      "\n",
      "================================================================================\n",
      "Grid Search Complete!\n",
      "Best Configuration:\n",
      "Architecture: [1, 512, 1]\n",
      "Activation: relu\n",
      "Learning Rate: 0.1\n",
      "Batch Size: 128\n",
      "Epochs: 20\n",
      "Best Mean Validation Accuracy: 0.5123 (51.23%)\n",
      "================================================================================\n",
      "{1: {'config': {'layer_widths': [1, 512, 1], 'activation': 'relu', 'learning_rate': 0.1, 'batch_size': 128, 'epochs': 20}, 'loss': np.float32(0.38200068)}, 5: {'config': {'layer_widths': [1, 512, 1], 'activation': 'relu', 'learning_rate': 0.1, 'batch_size': 64, 'epochs': 20}, 'loss': np.float32(0.48787796)}, 10: {'config': {'layer_widths': [1, 512, 1], 'activation': 'relu', 'learning_rate': 0.1, 'batch_size': 128, 'epochs': 20}, 'loss': np.float32(0.5084005)}, 20: {'config': {'layer_widths': [1, 512, 1], 'activation': 'relu', 'learning_rate': 0.1, 'batch_size': 128, 'epochs': 20}, 'loss': np.float32(0.50084466)}, 100: {'config': {'layer_widths': [1, 512, 1], 'activation': 'relu', 'learning_rate': 0.1, 'batch_size': 128, 'epochs': 20}, 'loss': np.float32(0.51227)}}\n"
     ]
    }
   ],
   "source": [
    "def analyze_k_impact(k_values):\n",
    "    \"\"\"\n",
    "    Runs grid search for different values of k to determine optimal hyperparameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Store best params for each k\n",
    "    heuristics = {}\n",
    "    \n",
    "    for k in k_values:\n",
    "        print(f\"Analyzing k = {k}\")\n",
    "        \n",
    "        # Generate Data for this specific k\n",
    "        n_samples = 20000\n",
    "        x = jnp.linspace(-1, 1, n_samples).reshape(-1, 1)\n",
    "        y = jnp.sin(k * jnp.pi * x)\n",
    "        \n",
    "        key = random.PRNGKey(k)\n",
    "        perm = random.permutation(key, n_samples)\n",
    "        x_shuffled, y_shuffled = x[perm], y[perm]\n",
    "        \n",
    "        x_train, y_train, x_test, y_test = get_splits(\n",
    "            x_shuffled, y_shuffled, train=0.8, classification=False\n",
    "        )\n",
    "        \n",
    "        # Run Grid Search\n",
    "        # We use k=3 folds to save time, but get reliable results\n",
    "        best_cfg, best_acc, best_loss, _, _ = grid_search(\n",
    "            x_train, y_train, \n",
    "            grid_search_configs, \n",
    "            k=3, \n",
    "            classification=False\n",
    "        )\n",
    "        \n",
    "        heuristics[k] = {\n",
    "            'config': best_cfg,\n",
    "            'loss': best_loss\n",
    "        }\n",
    "\n",
    "    return heuristics\n",
    "\n",
    "# We test low, medium, and high frequencies\n",
    "k_list = [1, 5, 10, 20, 100]\n",
    "k_heuristics = analyze_k_impact(k_list)\n",
    "print(k_heuristics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddeb51f",
   "metadata": {},
   "source": [
    "(c) Finally, propose an approach to approximate $f_k$ with higher values of $k$ and test it. Examples could include different function spaces than neural networks, architectural tweaks, activation changes, initialization strategies, or training approaches. Motivate your choice and discuss your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f00e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
