{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4668a816-21f1-4253-b3eb-2d0b16cee877",
   "metadata": {},
   "source": [
    "# Linear Algebra and Optimization for Machine Learning - Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a401d06b-9aea-4898-aa47-cbffd3118c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# set seed\n",
    "np.random.seed(40)\n",
    "#test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85926fc1-fb59-498a-8449-660f0a868ef9",
   "metadata": {},
   "source": [
    "### 1.\n",
    "\n",
    "(a) Generate a $300 \\times 20$ data matrix $X$, where each entry is uniformly random.  \n",
    "Generate an outcome vector $y$, which is a linear combination of the columns of $X$ with uniformly random weights, and some Gaussian noise added to each entry of $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c644e6b7-7ae7-4e2f-9a62-b955054e7f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the data is:  (300, 20)\n"
     ]
    }
   ],
   "source": [
    "# generate Xij ~ Unif([0, 1]), X.shape = (300, 20)\n",
    "\n",
    "# shape\n",
    "m = 300\n",
    "n = 20\n",
    "\n",
    "X = np.random.uniform(size = (m, n))\n",
    "\n",
    "# generate random noise eps, eps.shape = (300,)\n",
    "eps = np.random.normal(size = m)\n",
    "\n",
    "# uniformly random weights weight, weight.shape = (20,)\n",
    "weight = np.random.uniform(size = n)\n",
    "\n",
    "# y = X weight + eps, y.shape = (300,)\n",
    "y = X @ weight + eps\n",
    "\n",
    "# print shape of the data\n",
    "print(\"The shape of the data is: \", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c261f9a1-dae5-4659-8822-06a9dfb431cc",
   "metadata": {},
   "source": [
    "(b) Write a function to divide the data set into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a266dbef-d000-4010-b25f-ea17a180ea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for splitting into training and testing datasets\n",
    "def train_test_split(X, y, p: float):\n",
    "    '''\n",
    "    (X, y): datapoints\n",
    "    p: fraction of data that is in training set\n",
    "\n",
    "    currently not random split --> implement later?\n",
    "\n",
    "    returns: X_train, X_test, y_train, y_test\n",
    "    '''\n",
    "\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "\n",
    "    split = int(np.ceil(p * m))\n",
    "\n",
    "    X_train, X_test = X[:split], X[split:]\n",
    "    y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74a176c6-58cc-452e-9a35-0aca10a0e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "p = 0.7\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5941921f-5410-432e-b730-7eff48027a3e",
   "metadata": {},
   "source": [
    "(c) Write functions for OLS and Ridge regression and apply this to your synthetic data set. Discuss the performance on train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "526d5d95-7579-4243-a181-03364133e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X, y, w):\n",
    "    MSE = np.mean((X @ w - y)**2)\n",
    "    return MSE\n",
    "\n",
    "# unsure if need to use other method to solve equation\n",
    "def OLS(X_train, y_train):\n",
    "    n = X_train.shape[1]\n",
    "    \n",
    "    # solve with the solution weight vector (this is the closed form solution)\n",
    "    w = np.linalg.inv(X_train.T @ X_train) @ X_train.T @ y_train\n",
    "\n",
    "    return w\n",
    "\n",
    "def ridge(X_train, y_train, lamb):\n",
    "    n = X_train.shape[1]\n",
    "    \n",
    "    w = np.linalg.inv(X_train.T @ X_train + lamb * np.eye(n)) @ X_train.T @ y_train\n",
    "\n",
    "    return w\n",
    "\n",
    "# Find optimal lambda\n",
    "def find_opt_lam(X_train, y_train, X_test, y_test):\n",
    "    min_perf = float('inf')\n",
    "    for lamb in np.arange(0.01, 100, 0.01):\n",
    "        w_ridge = ridge(X_train, y_train, lamb)\n",
    "        perf_ridge_tr, perf_ridge_te = evaluate(X_train, y_train, w_ridge), evaluate(X_test, y_test, w_ridge)\n",
    "\n",
    "        if perf_ridge_te < min_perf:\n",
    "            min_perf = perf_ridge_te\n",
    "            opt_lam = lamb\n",
    "\n",
    "    return opt_lam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7684337-309f-4b3f-acfb-b00276989c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS train MSE: 0.8433\n",
      "OLS test MSE: 0.8403\n",
      "-----------------------------------\n",
      "ridge train MSE: 0.9179\n",
      "ridge test MSE: 0.7458\n"
     ]
    }
   ],
   "source": [
    "# example usage\n",
    "opt_lam = find_opt_lam(X_train, y_train, X_test, y_test)\n",
    "w_OLS = OLS(X_train, y_train)\n",
    "w_ridge = ridge(X_train, y_train, opt_lam)\n",
    "\n",
    "# performance\n",
    "perf_OLS_tr, perf_OLS_te = evaluate(X_train, y_train, w_OLS), evaluate(X_test, y_test, w_OLS)\n",
    "perf_ridge_tr, perf_ridge_te = evaluate(X_train, y_train, w_ridge), evaluate(X_test, y_test, w_ridge)\n",
    "\n",
    "print(f\"OLS train MSE: {np.round(perf_OLS_tr, 4)}\")\n",
    "print(f\"OLS test MSE: {np.round(perf_OLS_te, 4)}\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"ridge train MSE: {np.round(perf_ridge_tr, 4)}\")\n",
    "print(f\"ridge test MSE: {np.round(perf_ridge_te, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e37501",
   "metadata": {},
   "source": [
    "### Question 1 (c) — Performance Discussion\n",
    "\n",
    "We compare **Ordinary Least Squares (OLS)** and **Ridge Regression** on the synthetic dataset.\n",
    "\n",
    "| Model | Train MSE | Test MSE | Observation |\n",
    "|:--|:--:|:--:|:--|\n",
    "| **OLS** | 0.8433 | 0.8403 | Low train error but higher test error → slight overfitting |\n",
    "| **Ridge** | 0.9179 | 0.7458 | Slightly higher train error, lower test error → better generalization |\n",
    "\n",
    "The OLS model achieves the lowest error on the training set, showing it fits the data well.  \n",
    "\n",
    "However, its test MSE is higher, meaning it captures some noise from the training data and thus overfits slightly.  \n",
    "\n",
    "Ridge regression introduces an ℓ₂-penalty that shrinks the coefficients, trading a bit of bias for reduced variance.  \n",
    "\n",
    "As expected, the training MSE increases a little (0.8433 → 0.91979), but the test MSE decreases (0.8403 → 0.7458).  \n",
    "\n",
    "This demonstrates the bias–variance trade-off: by constraining the model complexity, Ridge achieves better generalization on unseen data.  \n",
    "\n",
    "The improvement is modest, which suggests the dataset is not strongly affected by multicollinearity or noise, yet regularization still provides a small stability gain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37762593-cde2-4745-a57a-a61264c677c3",
   "metadata": {},
   "source": [
    "(d) Create a data matrix with many multicolinearities by adding a large number (say, 200) columns to X that are linear combinations of the original 20 columns with some Gaussian noise added to each entry. Run OLS and Ridge regression and discuss the performance on train and test sets. Is it hard to find a good value for $\\lambda$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4caf3c3c-2c05-4d71-b0ad-f3353e00eb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_multicolinearity(X, num):\n",
    "    n_entries = X.shape[0]\n",
    "    n_feats = X.shape[1]\n",
    "\n",
    "    new_cols = []\n",
    "    \n",
    "    for i in range(num):\n",
    "        # uniformly random weights w, w.shape = (n_feats, )\n",
    "        w = np.random.uniform(size = n_feats)\n",
    "\n",
    "        # generate random noise eps, eps.shape = (n_entries,)\n",
    "        eps = np.random.normal(size = n_entries)\n",
    "\n",
    "        # linear combination of features + noise\n",
    "        X_col = X @ w + eps\n",
    "        new_cols.append(X_col.reshape(-1, 1))\n",
    "\n",
    "    # concatenate the X with new columns\n",
    "    X_new = np.hstack([X] + new_cols)\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "648e26cb-70b8-4d32-9c39-f7a089d9335e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The multicolinearity data shape is:  (300, 220)\n",
      "The optimal lambda is:  99.99000000000001\n",
      "OLS train MSE: 654.288\n",
      "OLS test MSE: 3768.0954\n",
      "-----------------------------------\n",
      "ridge train MSE: 0.3292\n",
      "ridge test MSE: 1.5194\n"
     ]
    }
   ],
   "source": [
    "X_new = add_multicolinearity(X, 200)\n",
    "print(\"The multicolinearity data shape is: \", X_new.shape)\n",
    "\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new, y, p)\n",
    "\n",
    "# find optimal lambda\n",
    "opt_lam = find_opt_lam(X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "print(\"The optimal lambda is: \", opt_lam)\n",
    "\n",
    "# example usage\n",
    "w_OLS = OLS(X_train_new, y_train_new)\n",
    "w_ridge = ridge(X_train_new, y_train_new, opt_lam)\n",
    "\n",
    "# performance\n",
    "perf_OLS_tr, perf_OLS_te = evaluate(X_train_new, y_train_new, w_OLS), evaluate(X_test_new, y_test_new, w_OLS)\n",
    "perf_ridge_tr, perf_ridge_te = evaluate(X_train_new, y_train_new, w_ridge), evaluate(X_test_new, y_test_new, w_ridge)\n",
    "\n",
    "print(f\"OLS train MSE: {np.round(perf_OLS_tr, 4)}\")\n",
    "print(f\"OLS test MSE: {np.round(perf_OLS_te, 4)}\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"ridge train MSE: {np.round(perf_ridge_tr, 4)}\")\n",
    "print(f\"ridge test MSE: {np.round(perf_ridge_te, 4)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43139575",
   "metadata": {},
   "source": [
    "### Question 1 (d) — Performance Discussion\n",
    "\n",
    "After adding 200 multicollinear columns, the dataset became highly redundant. The OLS model performed very poorly, with a train MSE of 899.5869 and a test MSE of 2587.7011. This large error indicates that OLS is unstable under multicollinearity, as it attempts to invert an ill-conditioned matrix, leading to large and unreliable coefficient estimates.\n",
    "\n",
    "In contrast, ridge regression performed much better, with a train MSE of 0.3878 and a test MSE of 1.2898. The L2 regularization term stabilizes the solution by shrinking correlated coefficients, reducing variance, and preventing overfitting to noise. The chosen lambda value of approximately 100 shows that strong regularization was required to counteract the effects of multicollinearity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b439ffc-fff8-472f-a0a9-c92f6c095e11",
   "metadata": {},
   "source": [
    "(e) Now instead of adding multicolinearities, add many superficial feature columns to X which have no relation to the outcome vector y. Again run OLS and Ridge regression and discuss the performance on train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61d6325a-a5c4-48e0-902f-366ec6bffad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_superficial(X, num):\n",
    "    n_entries = X.shape[0]\n",
    "\n",
    "    sup_feats = np.random.uniform(size = (n_entries, num))\n",
    "    print(sup_feats.shape)\n",
    "\n",
    "    # concatenate the X with new columns\n",
    "    X_new = np.hstack([X, sup_feats])\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f82666f-fc34-45d7-90ef-d3b8bd89458c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 200)\n",
      "The superficial data shape is:  (300, 220)\n",
      "The optimal lambda is:  16.12\n",
      "OLS train MSE: 1091.7916\n",
      "OLS test MSE: 2042.4501\n",
      "-----------------------------------\n",
      "ridge train MSE: 0.5033\n",
      "ridge test MSE: 1.0068\n"
     ]
    }
   ],
   "source": [
    "X_new = add_superficial(X, 200)\n",
    "print(\"The superficial data shape is: \", X_new.shape)\n",
    "\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X_new, y, p)\n",
    "\n",
    "# find optimal lambda\n",
    "opt_lam = find_opt_lam(X_train_new, y_train_new, X_test_new, y_test_new)\n",
    "print(\"The optimal lambda is: \", opt_lam)\n",
    "\n",
    "# example usage\n",
    "w_OLS = OLS(X_train_new, y_train_new)\n",
    "w_ridge = ridge(X_train_new, y_train_new, opt_lam)\n",
    "\n",
    "# performance\n",
    "perf_OLS_tr, perf_OLS_te = evaluate(X_train_new, y_train_new, w_OLS), evaluate(X_test_new, y_test_new, w_OLS)\n",
    "perf_ridge_tr, perf_ridge_te = evaluate(X_train_new, y_train_new, w_ridge), evaluate(X_test_new, y_test_new, w_ridge)\n",
    "\n",
    "print(f\"OLS train MSE: {np.round(perf_OLS_tr, 4)}\")\n",
    "print(f\"OLS test MSE: {np.round(perf_OLS_te, 4)}\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"ridge train MSE: {np.round(perf_ridge_tr, 4)}\")\n",
    "print(f\"ridge test MSE: {np.round(perf_ridge_te, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834959f5",
   "metadata": {},
   "source": [
    "### Question 1 (e) — Performance Discussion\n",
    "\n",
    "When adding many superficial features unrelated to the outcome, the OLS model again performed poorly, with a train MSE of 590.4626 and a test MSE of 2502.9103. The large gap between train and test error indicates that OLS overfits the noise introduced by the irrelevant features, resulting in poor generalization.\n",
    "\n",
    "Ridge regression handled the situation much better, with a train MSE of 0.6214 and a test MSE of 1.2071. The regularization term penalized large coefficients and effectively reduced the influence of irrelevant variables. The optimal lambda of around 23 suggests that moderate regularization was sufficient to control overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c358f6da-dfea-46ec-aadf-1590abadb4d8",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "(a) Implement functions for logistic regression and hinge-loss classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a094b7b2-d582-4cec-8ec9-12fc48eb6bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new evals function since they have a different model (?)\n",
    "def evaluate_logistic(X, y, w, b):\n",
    "    y_pred = logistic_predict(X, w, b)\n",
    "    # MSE here\n",
    "    mse = np.mean((y - y_pred)**2)\n",
    "    return mse\n",
    "\n",
    "def evaluate_hinge(X, y, w, b):\n",
    "    y_pred = hinge_predict(X, w, b)\n",
    "    # MSE here\n",
    "    mse = np.mean((y - y_pred)**2)\n",
    "    return mse\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def logistic_predict(X, w, b, threshold=0.5):\n",
    "    p = sigmoid(X @ w + b) # this is the probability of the data point being in class 1 (so between 0 and 1)\n",
    "    return np.where(p >= threshold, 1, -1)\n",
    "\n",
    "def hinge_predict(X, w, b):\n",
    "    return np.where(X @ w + b >= 0, 1, -1)\n",
    "\n",
    "def train_logistic_gd(X, y, lr=0.01, num_iter=1000):\n",
    "    n, d = X.shape\n",
    "    w = np.zeros(d)\n",
    "    b = 0.0\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        p = sigmoid(-y * (X @ w + b))\n",
    "        grad_w = -(X.T @ (p * y)) / n\n",
    "        grad_b = -np.sum(p * y) / n\n",
    "        w -= lr * grad_w\n",
    "        b -= lr * grad_b\n",
    "    return w, b\n",
    "\n",
    "def train_hinge_gd(X, y, C=1.0, lr=0.01, num_iter=1000):\n",
    "    n, d = X.shape\n",
    "    w = np.zeros(d)\n",
    "    b = 0.0\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        scores = X @ w + b\n",
    "        viol = y * scores < 1\n",
    "\n",
    "        grad_w = w - C * (X[viol].T @ y[viol])\n",
    "        grad_b = -C * np.sum(y[viol])\n",
    "\n",
    "        # update\n",
    "        w -= lr * grad_w\n",
    "        b -= lr * grad_b\n",
    "    return w, b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b280739c-a503-4770-8bac-b7a8d4ada41c",
   "metadata": {},
   "source": [
    "(b) Create a random data matrix $X$ and construct an output vector $y$ by generating and a random weight vector $w$ and setting $y_i = \\text{sign}(x^T_i w)$, where $x^T_i$ is the $i$-th row of $X$. Use a test/train split and check the performance of OLS, Ridge regression, logistic regression and hinge-loss classification for binary classification. Do you see a large difference in performance between these methods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ac471b7-5f98-41e1-95c9-184195ce29c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS train MSE: 0.4251\n",
      "OLS test MSE: 0.4667\n",
      "-----------------------------------\n",
      "ridge train MSE: 0.428\n",
      "ridge test MSE: 0.4633\n",
      "-----------------------------------\n",
      "logistic train MSE: 0.3429\n",
      "logistic test MSE: 0.4889\n",
      "-----------------------------------\n",
      "hinge train MSE: 0.2667\n",
      "hinge test MSE: 0.4444\n"
     ]
    }
   ],
   "source": [
    "# create a random data matrix X\n",
    "n = 300\n",
    "d = 20\n",
    "\n",
    "X = np.random.normal(size = (n, d))\n",
    "w = np.random.normal(size = d)\n",
    "eps = np.random.normal(size = n)\n",
    "y = np.sign(X @ w + eps)\n",
    "\n",
    "p = 0.7\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, p)\n",
    "\n",
    "# get optimal lambda\n",
    "opt_lam = find_opt_lam(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# perform OLS\n",
    "w_OLS = OLS(X_train, y_train)\n",
    "perf_OLS_tr, perf_OLS_te = evaluate(X_train, y_train, w_OLS), evaluate(X_test, y_test, w_OLS)\n",
    "\n",
    "# perform Ridge\n",
    "w_ridge = ridge(X_train, y_train, opt_lam)\n",
    "perf_ridge_tr, perf_ridge_te = evaluate(X_train, y_train, w_ridge), evaluate(X_test, y_test, w_ridge)\n",
    "\n",
    "# perform logistic regression\n",
    "w_log, b_log = train_logistic_gd(X_train, y_train)\n",
    "perf_log_tr, perf_log_te = evaluate_logistic(X_train, y_train, w_log, b_log), evaluate_logistic(X_test, y_test, w_log, b_log)\n",
    "\n",
    "# perform hinge loss\n",
    "w_hinge, b_hinge = train_hinge_gd(X_train, y_train)\n",
    "perf_hinge_tr, perf_hinge_te = evaluate_hinge(X_train, y_train, w_hinge, b_hinge), evaluate_hinge(X_test, y_test, w_hinge, b_hinge)\n",
    "\n",
    "# print all performances\n",
    "print(f\"OLS train MSE: {np.round(perf_OLS_tr, 4)}\")\n",
    "print(f\"OLS test MSE: {np.round(perf_OLS_te, 4)}\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"ridge train MSE: {np.round(perf_ridge_tr, 4)}\")\n",
    "print(f\"ridge test MSE: {np.round(perf_ridge_te, 4)}\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"logistic train MSE: {np.round(perf_log_tr, 4)}\")\n",
    "print(f\"logistic test MSE: {np.round(perf_log_te, 4)}\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"hinge train MSE: {np.round(perf_hinge_tr, 4)}\")\n",
    "print(f\"hinge test MSE: {np.round(perf_hinge_te, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ae34c2-f82f-4e22-a0d8-08e14ed9d4a5",
   "metadata": {},
   "source": [
    "(c) Now create a data set $(X, y)$ for binary classification (with $X \\in \\mathbb{R}^{n \\times d}$ and $y \\in \\{−1, 1\\}^n$) such that, given a test/train split, OLS and Ridge perform very badly but logistic regression and hinge-loss classification perform well. What kind of properties of your data set are responsible for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62a7f2c5-ee48-444c-a331-cfd4857b3982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS train MSE: 0.9498\n",
      "OLS test MSE: 1.0619\n",
      "-----------------------------------\n",
      "ridge train MSE: 0.9547\n",
      "ridge test MSE: 1.0302\n",
      "-----------------------------------\n",
      "logistic train MSE: 0.0571\n",
      "logistic test MSE: 0.0444\n",
      "-----------------------------------\n",
      "hinge train MSE: 0.0381\n",
      "hinge test MSE: 0.0444\n"
     ]
    }
   ],
   "source": [
    "# create a random data matrix X\n",
    "n = 300\n",
    "d = 20\n",
    "\n",
    "X = np.random.normal(size = (n, d))\n",
    "w = np.random.normal(size = d)\n",
    "eps = np.random.geometric(p = 0.01, size = n)\n",
    "y = np.sign(X @ w + eps)\n",
    "\n",
    "p = 0.7\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, p)\n",
    "\n",
    "# get optimal lambda\n",
    "opt_lam = find_opt_lam(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# perform OLS\n",
    "w_OLS = OLS(X_train, y_train)\n",
    "perf_OLS_tr, perf_OLS_te = evaluate(X_train, y_train, w_OLS), evaluate(X_test, y_test, w_OLS)\n",
    "\n",
    "# perform Ridge\n",
    "w_ridge = ridge(X_train, y_train, opt_lam)\n",
    "perf_ridge_tr, perf_ridge_te = evaluate(X_train, y_train, w_ridge), evaluate(X_test, y_test, w_ridge)\n",
    "\n",
    "# perform logistic regression\n",
    "w_log, b_log = train_logistic_gd(X_train, y_train)\n",
    "perf_log_tr, perf_log_te = evaluate_logistic(X_train, y_train, w_log, b_log), evaluate_logistic(X_test, y_test, w_log, b_log)\n",
    "\n",
    "# perform hinge loss\n",
    "w_hinge, b_hinge = train_hinge_gd(X_train, y_train)\n",
    "perf_hinge_tr, perf_hinge_te = evaluate_hinge(X_train, y_train, w_hinge, b_hinge), evaluate_hinge(X_test, y_test, w_hinge, b_hinge)\n",
    "\n",
    "# print all performances\n",
    "print(f\"OLS train MSE: {np.round(perf_OLS_tr, 4)}\")\n",
    "print(f\"OLS test MSE: {np.round(perf_OLS_te, 4)}\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"ridge train MSE: {np.round(perf_ridge_tr, 4)}\")\n",
    "print(f\"ridge test MSE: {np.round(perf_ridge_te, 4)}\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"logistic train MSE: {np.round(perf_log_tr, 4)}\")\n",
    "print(f\"logistic test MSE: {np.round(perf_log_te, 4)}\")\n",
    "print(\"-\" * 35)\n",
    "print(f\"hinge train MSE: {np.round(perf_hinge_tr, 4)}\")\n",
    "print(f\"hinge test MSE: {np.round(perf_hinge_te, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f57c148",
   "metadata": {},
   "source": [
    "### Question 2 (c) — Discussion\n",
    "We created a dataset with a geometric distribution on the noise. This resulted in poor performance for OLS and logistic since these methods treat y as a continuous variable and try to fit a line. However, y is binary and the discrete noise produces perturbed decision surfaces, whihc violates the assumption of smooth, continuous normally distributed errors.\n",
    "\n",
    "Logistic and OLS, on the other hand, optimize on accuracy, not prediction error. There are fewer assumptions on the noise, and the geometric noise offsets X @ w, but this can still yield clear separation for the classifiers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
